<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on Tiiktak&#39;s</title>
    <link>https://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on Tiiktak&#39;s</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Feb 2020 01:04:44 +0800</lastBuildDate><atom:link href="https://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>神经网络模型的学习曲线</title>
      <link>https://example.com/blog/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/</link>
      <pubDate>Fri, 07 Feb 2020 01:04:44 +0800</pubDate>
      
      <guid>https://example.com/blog/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/</guid>
      <description>学习曲线：样本数量与误差 绘制 样本数量m 与 训练误差、交叉验证误差 的关系曲线
高偏差（欠拟合）high bias 高方差（过拟合）high variance </description>
    </item>
    
    <item>
      <title>【应用机器学习】正则化与偏差、方差</title>
      <link>https://example.com/blog/%E6%AD%A3%E5%88%99%E5%8C%96%E4%B8%8E%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE/</link>
      <pubDate>Fri, 07 Feb 2020 00:56:29 +0800</pubDate>
      
      <guid>https://example.com/blog/%E6%AD%A3%E5%88%99%E5%8C%96%E4%B8%8E%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE/</guid>
      <description>在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。
但是我们可能会正则化的程度太高或太小了，即我们在选择λ的值时也需要思考与之前选择多项式模型次数类似的问题。
我们选择一系列的想要测试的λ值，比如这里选择 0-10之间的值，通常呈现2倍关系（如：0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10 共12个）。
我们同样把数据分为训练集、交叉验证集和测试集。
选择λ的方法   使用训练集训练出12个不同程度正则化的模型
  用12个模型分别对交叉验证集计算的出交叉验证误差
  选择得出交叉验证误差最小的模型
  运用步骤3中选出模型对测试集计算得出推广误差
  我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：
 当λ较小时，训练集误差较小（过拟合）而交叉验证集误差较大
  随着λ的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加
 </description>
    </item>
    
    <item>
      <title>【应用机器学习】诊断偏差与方差</title>
      <link>https://example.com/blog/%E8%AF%8A%E6%96%AD%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/</link>
      <pubDate>Fri, 07 Feb 2020 00:51:21 +0800</pubDate>
      
      <guid>https://example.com/blog/%E8%AF%8A%E6%96%AD%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/</guid>
      <description>当你运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。
我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：
  对于训练集，当 d 较小时，模型拟合程度更低，误差较大；随着d 的增长，拟合程度提高，误差减小。
  对于交叉验证集，当 d 较小时，模型拟合程度低，误差较大；但是随着 d 的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。
  判断高偏差（欠拟合）或高方差（过拟合）   训练集误差和交叉验证集误差近似时：偏差/欠拟合
  交叉验证集误差远大于训练集误差时：方差/过拟合
  解决欠拟合与过拟合 欠拟合：
 增加网络结构，如增加隐藏层数目； 训练更长时间； 寻找合适的网络架构，使用更大的NN结构；  过拟合 ：
 使用更多的数据； 正则化（ regularization）； 寻找合适的网络结构；  </description>
    </item>
    
    <item>
      <title>【应用机器学习】模型选择和训练、验证、测试集</title>
      <link>https://example.com/blog/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/</link>
      <pubDate>Fri, 07 Feb 2020 00:41:34 +0800</pubDate>
      
      <guid>https://example.com/blog/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/</guid>
      <description>1. 重新划分数据集 其中60%作为训练集，20%作为交叉验证集（cross validation），20%作为测试集
2. 可以计算出三类数据的误差函数 3. 使用交叉验证集选择模型 选出交叉验证误差最小的一个模型
4. 利用测试集计算出推广误差 </description>
    </item>
    
    <item>
      <title>【应用机器学习】评估一个假设</title>
      <link>https://example.com/blog/%E8%AF%84%E4%BC%B0%E4%B8%80%E4%B8%AA%E5%81%87%E8%AE%BE/</link>
      <pubDate>Fri, 07 Feb 2020 00:34:04 +0800</pubDate>
      
      <guid>https://example.com/blog/%E8%AF%84%E4%BC%B0%E4%B8%80%E4%B8%AA%E5%81%87%E8%AE%BE/</guid>
      <description>检验是否过拟合 将数据分成训练集和测试集 通常用70%的数据作为训练集，用剩下30%的数据作为测试集。
很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行洗牌，然后再分成训练集和测试集。
使用训练集对模型进行训练 可以得到一系列参数 theta
使用测试集对模型进行测试 使用测试集数据对模型进行测试，有两种方式计算误差
线性回归模型 利用测试集数据计算代价函数J
逻辑回归模型 除前述方法，还可使用一种 错误分类(misclassification error)(也称0/1错误分类 zero one misclassification error) 的方法</description>
    </item>
    
    <item>
      <title>训练神经网络的基本步骤</title>
      <link>https://example.com/blog/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4/</link>
      <pubDate>Fri, 07 Feb 2020 00:09:57 +0800</pubDate>
      
      <guid>https://example.com/blog/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4/</guid>
      <description>1. 选择一种网络结构 即选择神经元之间的连通模式
  输入层与输出层单元个数由具体特征决定
  隐藏层通常默认为1层；若为多层，则每个隐藏层单元个数应相等。通常隐藏层单元数越多越好
  隐藏层单元数应与输入特征数相匹配
  2. 随机初始化权重 通常把权重值初始化为接近0的很小的数
3. 执行前向传播FP算法 获得对应于每一个 xi 的 h_theta(xi)​
4. 通过代码计算出代价函数 J(theta) 5. 执行反向传播算法 获得 J(theta) 对于 theta 的偏导​，即
 步骤 3-5
   6. 进行梯度检查   比较 通过反向传播得到的偏导数 与 通过数值计算得到的估计值
  确保两种方法得到基本接近的两个值​
  注意在检查完毕后关闭梯度检查
  7. 利用最优化算法与反向传播算法最小化 J(theta) 比如，使用最小梯度法</description>
    </item>
    
    <item>
      <title>正则化 Regularization</title>
      <link>https://example.com/blog/%E6%AD%A3%E5%88%99%E5%8C%96/</link>
      <pubDate>Mon, 13 Jan 2020 17:29:56 +0800</pubDate>
      
      <guid>https://example.com/blog/%E6%AD%A3%E5%88%99%E5%8C%96/</guid>
      <description>过拟合的问题 到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到**过拟合(over-fitting)**的问题，可能会导致它们效果很差。
可以使用一种**正则化(regularization)**的技术来改善或减少过度拟合的问题
在回归问题中   第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；
  第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：
  当我们用第三个模型预测新数据，可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎是最合适的。
在分类问题中 就以多项式理解， x的次数越高，拟合的越好，但相应的预测的能力就可能变差。
处理过拟合问题
 丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA） 正则化。 保留所有的特征，但是减少参数的大小（magnitude）  代价函数 我们从之前的事例可以看出，正是那些高次项导致了过拟合的产生，所以我们可以通过让这些高次项的系数接近于0，我们就能很好的拟合。
所以正则化的基本方法就是在一定程度上减小高次项系数即参数theta的值
即在设定代价函数时，为高次项的系数设置一些惩罚，通过这样代价函数选择出的theta对预测结果的影响就比之前要小许多。
但如果我们不知道要对哪一个参数进行惩罚，我们可以对所以特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。于是得到了一个较为简单的能防止过拟合问题的假设
其中λ称为正则化参数（Regularization Parameter）。注：根据惯例，我们不对theta0进行惩罚。
经过正则化处理的模型与原模型的可能对比如图：
如果选择的正则化参数λ过大，则会把所有的参数都最小化了，导致模型变成 h(x) = theta0 ，也就是上图中红色直线所示的情况，造成欠拟合。
对于正则化，我们要取一个合理的λ的值，这样才能更好的应用正则化。 回顾一下代价函数，为了使用正则化，让我们把这些概念应用到到线性回归和逻辑回归中去，那么我们就可以让他们避免过度拟合了。
正则化线性回归 正则化线性回归的代价函数为：
如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对theta0进行正则化，所以梯度下降算法将分两种情形：
分类 L1正则化（Lasso回归） 损失函数基础上加上权重参数的绝对值
L2正则化（岭回归） 损失函数基础上加上权重参数的平方和
需要说明的是：L1 相比于 L2 会更容易获得稀疏解
WHY-&amp;gt;Click</description>
    </item>
    
    <item>
      <title>逻辑回归Logistic Regression</title>
      <link>https://example.com/blog/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Mon, 13 Jan 2020 16:07:34 +0800</pubDate>
      
      <guid>https://example.com/blog/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</guid>
      <description>分类问题 在分类问题中，我们需要预测的变量y是离散的值，我们将学习一种叫做逻辑回归 (Logistic Regression) 的算法
在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。
将因变量(dependent variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量y ∈ 0,1 ，其中 0 表示负向类，1 表示正向类。
如果我们要用线性回归算法来解决一个分类问题，对于分类，y取值为 0 或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于 1，或者远小于0，即使所有训练样本的标签y都等于 0 或 1。尽管我们知道标签应该取值0 或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。
所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到 1 之间
逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上真的是一种分类算法
假说表示 我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0和1之间。
逻辑回归模型的假设是：h_theta(x) = g(theta&#39;X) 其中:X代表特征向量，g代表逻辑函数（logistic function)是一个常用的S形函数（Sigmoid function），公式为：g(z) = 1 / (1 + exp(-z)
Python代码实现
import numpy as np def sigmoid(z): return 1 / (1 + np.exp(-z)) 该函数图像为
合起来，我们得到逻辑回归模型的假设：
对模型的理解：g(z) = 1 / (1 + exp(-z)
h_theta(x)的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性（estimated probablity）即h_theta(x) = P(y=1 | x;theta)</description>
    </item>
    
    <item>
      <title>多变量线性回归</title>
      <link>https://example.com/blog/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Tue, 07 Jan 2020 19:48:31 +0800</pubDate>
      
      <guid>https://example.com/blog/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>多变量梯度下降 与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：
其中：
我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。 多变量线性回归的批量梯度下降算法为：
我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。
Python 代码示例：
def computeCost(X, y, theta): inner = np.power(((X * theta.T) - y), 2) return np.sum(inner) / (2 * len(X)) 梯度下降法实践1-特征缩放 在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛
以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。
解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。如图：
最简单的方法是令：x_n = (x_n - miu_n) / s_n ，其中miu_n是平均值，s_n是标准差
梯度下降法实践2—学习率 梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。
也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好
梯度下降算法的每次迭代受到学习率的影响，如果学习率过小，则达到收敛所需的迭代次数会非常高；如果学习率过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。
通常可以考虑尝试这些学习率：
alpha = 0.01, 0.03, 0.1, 0.3, 1, 3, 10
特征和多项式回归 对于房价预测问题
其中，x1 = frontage(临街宽度)，x2 = depth(纵向深度)，x = frontage * depth = area，则：h(x) = theta0 + theta1*x1 + theta2*x2^2</description>
    </item>
    
    <item>
      <title>降低损失：梯度下降法</title>
      <link>https://example.com/blog/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</link>
      <pubDate>Tue, 07 Jan 2020 17:16:04 +0800</pubDate>
      
      <guid>https://example.com/blog/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</guid>
      <description>梯度下降 梯度下降是一个用来求函数最小值的算法，在这里我们将使用梯度下降算法来求出代价函数（损失函数）J(w1, w2)的最小值
假设我们有时间和计算资源来计算权重值w1的所有可能值的损失。对于回归问题，所产生的损失与w1的图形始终是碗状图，如下所示：
图中的最低点，即斜率正好为 0的位置。这个最小值就是损失函数收敛之处。
过程 开始时我们为(w1, w2)选择一个起始值（起点）。然而起点并不重要；因此很多算法就直接将它们设为0或随机选择一个值。
通过这个参数组合计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。
在这里使用梯度下降法算法计算损失曲线在起点处的梯度。梯度是偏导数的矢量；它可以让我们了解哪个方向距离目标“更近”或“更远”
梯度始终指向损失函数中增长最为迅猛的方向。梯度下降法算法会沿着负梯度的方向走一步，以便尽快降低损失。
为了确定损失函数曲线上的下一个点，梯度下降法算法会将梯度大小的一部分与起点相加：
然后，梯度下降法会重复此过程，逐渐接近最低点。
局部最小值  想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。
  这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。
 我们持续这么做直到我们得到一个局部最小值（local minimum），然而因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），如果选择不同的初始参数组合，可能会找到不同的局部最小值。
 这个问题在以前的机器学习中可能会遇到，因为机器学习中的特征比较少，所以导致很可能陷入到一个局部最优解中出不来 但是到了深度学习，动辄百万甚至上亿的特征，出现这种情况的概率几乎为0，所以我们可以不用考虑这个问题。
 批量梯度下降 批量梯度下降法是最原始的形式，它是指在每一次迭代时使用所有样本来进行梯度的更新
公式为：
其中alpha是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。
在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新theta0和theta1，当j = 0和j = 1时，会产生更新，所以你将更新J(theta0)和J(theta1)。
实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新theta0和theta1，我的意思是在这个等式中，我们要这样更新：
theta0:=theta0，并更新theta1:=theta1
实现方法是：你应该计算公式右边的部分，通过那一部分计算出theta0和theta1的值，然后同时更新theta0和theta1。
学习率 Alpha 让我们来看看如果太小或太大会出现什么情况：
  如果太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。
  如果太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果太大，它会导致无法收敛，甚至发散。
  假设你将theta1初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得theta1不再改变，也就是新的theta1等于原来的theta1，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率alpha保持不变时，梯度下降也可以收敛到局部最低点。
 在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小。
这就是梯度下降算法，你可以用它来最小化任何代价函数，不只是线性回归中的代价函数。</description>
    </item>
    
    <item>
      <title>单变量线性回归</title>
      <link>https://example.com/blog/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Tue, 07 Jan 2020 16:09:48 +0800</pubDate>
      
      <guid>https://example.com/blog/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>线性回归 线性回归是解决回归问题最基本的一个方法。其实质就是找到一条直线能尽可能多的使已知的离散值分布在其周围（二维坐标系中）
就像这样：
或者是在三维坐标中，找到一个面来逼近
在这里我们只讨论最简单的单变量线性回归
单变量线性回归 单变量线性回归问题只含有一个特征（输入变量），因此可以把目标直线表达式写为：
h(x) = y = wx + b
其中， x代表特征/输入变量，h代表目标变量/输出变量
我们需要有一个包含许多对(x, y)的训练集，之后把它喂给我们的学习算法，学习算法输出一个函数，通常表示为小写h表示，代表hypothesis(假设)，表示一个函数
因此h根据输入的x值来得出y值，y值就是我们想要根据x知道的答案。因此，h是一个从y到x的函数映射。
代价函数 又称为“损失函数”
在前面的函数h中，我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度。
模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）
我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。 即使得代价函数最小
这个代价函数可以根据最小二乘法得到
我们绘制一个等高线图，三个坐标分别w (图中theta0)、h (图中theta1)和代价函数 (图中J(theta0, theta1))
代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。
  参考资料： 吴恩达《机器学习》课程笔记
 </description>
    </item>
    
    <item>
      <title>分类(classification)与回归(regression)的区别与关系</title>
      <link>https://example.com/blog/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Mon, 06 Jan 2020 15:45:03 +0800</pubDate>
      
      <guid>https://example.com/blog/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92/</guid>
      <description>分类与回归是监督学习中的两个主要任务，它们即对应了监督学习中“学习”的部分
分类模型与回归模型的本质其实一样。分类模型可将回归模型的输出离散化，回归模型也可将分类模型的输出连续化
 例如：
Linear Recognition 线性回归 使用 y = wx + b 的形式，y就是模型的输出，是一个连续值，所以可以用于处理回归问题
Logistic Recognition 逻辑回归 一般作为分类问题的首选算法，logistic回归只是用到了回归算法，但是其输出的结果是决策边界，是不连续的，所以它其实是分类，而不是回归
二分类 将 y = wx + b 利用激活函数（常用sigmoid函数）映射到 (0,1) 中。再选定一个阈值，将输出分为两类。
多分类 先得到n组w不同的 y = wx +b ，之后进行归一化（例如使用Softmax函数），从而得到在n个类上的概率，即可解决多分类问题
 回归问题的应用场景 回归问题通常是用来预测一个值，如预测房价、未来的天气情况等等。例如一个产品的实际价格为500元，通过回归分析预测值为499元，我们认为这是一个比较好的回归分析。
一个比较常见的回归算法是线性回归算法（LR）。
另外，回归分析用在神经网络上，其最上层是不需要加上softmax函数的，而是直接对前一层累加即可。回归是对真实值的一种逼近预测。
分类问题的应用场景 分类问题是用于将事物打上一个标签，通常结果为离散值。
例如判断一幅图片上的动物是一只猫还是一只狗，分类通常是建立在回归之上，分类的最后一层通常要使用softmax函数进行判断其所属类别。
分类并没有逼近的概念，最终正确结果只有一个，错误的就是错误的，不会有相近的概念。
最常见的分类方法是逻辑回归，或者叫逻辑分类。
总结 一个小测验：假设你经营着一家公司，你想开发学习算法来处理这两个问题：
  你有一大批同样的货物，想象一下，你有上千件一模一样的货物等待出售，这时你想预测接下来的三个月能卖多少件？
  你有许多客户，这时你想写一个软件来检验每一个用户的账户。对于每一个账户，你要判断它们是否曾经被盗过？
  那这两个问题，它们属于分类问题、还是回归问题?
  问题一是一个回归问题，因为你知道，如果我有数千件货物，我会把它看成一个实数，一个连续的值。因此卖出的物品数，也是一个连续的值。
  问题二是一个分类问题，因为我会把预测的值，用 0 来表示账户未被盗，用 1 表示账户曾经被盗过。所以我们根据账号是否被盗过，把它们定为0 或 1，然后用算法推测一个账号是 0 还是 1，因为只有少数的离散值，所以我把它归为分类问题。</description>
    </item>
    
    <item>
      <title>ML学习速率</title>
      <link>https://example.com/blog/%E5%AD%A6%E4%B9%A0%E9%80%9F%E7%8E%87/</link>
      <pubDate>Thu, 26 Sep 2019 11:12:23 +0800</pubDate>
      
      <guid>https://example.com/blog/%E5%AD%A6%E4%B9%A0%E9%80%9F%E7%8E%87/</guid>
      <description>在梯度下降算法中，我们用梯度乘以一个称为学习速率（有时也称为步长）的标量，以确定下一个点的位置。例如，如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。
超参数是编程人员在机器学习算法中用于调整的旋钮。大多数机器学习编程人员会花费相当多的时间来调整学习速率。如果学习速率过小，就会花费太长的学习时间：
相同的 U 形曲线。很多点都相互非常接近，它们的轨迹朝着 U 形底部缓慢前进。
相反，如果学习速率过大，下一个点将永远在 U 形曲线的底部随意弹跳，就好像量子力学实验出现了严重错误一样：
相同的 U 形曲线。这条曲线包含的点非常少。点的轨迹会跳过 U 形底部，然后再次跳回。
每个回归问题都存在一个“恰好”的学习速率，这个值与损失函数的平坦程度有关。例如，若已知损失函数的梯度较小，则可以放心地试着采用更大的学习速率，以补偿较小的梯度并获得更大的步长。
相同的 U 形曲线。点的轨迹大约需要 8 步达到最低点。</description>
    </item>
    
  </channel>
</rss>
