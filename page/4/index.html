<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
    <title>Tiiktak&#39;s</title>
    
    <meta name="description" content="Hey You">
    <meta name="author" content="">
    
    <link href="https://konosuba.xyz/css/github-gist.min.css" rel="stylesheet">
    <link href="https://konosuba.xyz/css/style.css" rel="stylesheet">
    
    <link rel="apple-touch-icon" href="https://konosuba.xyz/img/apple-touch-icon.png">
    <link rel="icon" href="https://konosuba.xyz/img/favicon.ico">
    
    <meta name="generator" content="Hugo 0.55.6" />
    
    <link rel="alternate" type="application/atom+xml" href="https://konosuba.xyz/index.xml" title="Tiiktak&#39;s">
    
    
    
  </head>
  <body class="list home">
    <header class="header">
      <div class="wrap">
        
        <h1 class="logo"><a href="https://konosuba.xyz/">Tiiktak&#39;s</a></h1>
        
        
        <button class="menu-toggle" type="button"></button>
        
      </div>
    </header>
    
    <nav class="nav">
      <ul class="menu">
        
        <li>
          <a href="/about/">About</a>
        </li>
        
      </ul>
    </nav>
    
    <main class="main">








<article class="post-entry">
  <header class="entry-header">
    <h2>MATLAB学习_操作数据</h2>
  </header>
  <section class="entry-content">
   <p>文件操作 导入文件 当我们打开 MATLAB 时，我们通常已经在一个默认路径中，这个路径是 MATLAB 的安装位置，使用 pwd 命令可以显示出 MATLAB 当前所处路径。
使用cd命令，可以修改当前路径
使用’ls’命令，可以列出当前路劲中所有文件
要在MATLAB中导入数据文件，可以使用load命令，如：
&gt;&gt; load myData.dat % 或load(&#39;myData.dat&#39;)  之后可以直接输入myData，MATLAB便会打印文件中的数据，此时该文件名便作为一个新变量名
导出文件 退出 MATLAB 后，工作区变量不会保留。使用 save 命令保存数据以供将来使用，
save myfile.mat  通过保存，系统会使用 .mat 扩展名将工作区保存在当前工作文件夹中一个名为 MAT 文件的压缩文件中。
变量操作 “工作区”中包含了在MATLAB创建或从数据文件或其他程序导入的变量
例如先在工作区中创建变量A和B
A = eye(3) B = rand(2, 3)  使用who可以查看当前工作区中所有变量
&gt;&gt; who 您的变量为: A B  还有一个whos，能更详细的查看
&gt;&gt; whos Name Size Bytes Class Attributes A 3x3 72 double B 2x3 48 double  此外，在GUI窗口中也能查看...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.1.10</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/matlab%E5%AD%A6%E4%B9%A0_%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>MATLAB学习_矩阵与向量操作</h2>
  </header>
  <section class="entry-content">
   <p>矩阵与向量的创建在上一篇文章中已经提到，所以这里直接进行操作和运算
运算 现有一矩阵a:
&gt;&gt; a = [1 2 3; 4 5 6; 7 8 10] a = 1 2 3 4 5 6 7 8 10  矩阵与常数相加
&gt;&gt; a &#43; 10 ans = 11 12 13 14 15 16 17 18 20  &gt;&gt; sin(a) ans = 0.8415 0.9093 0.1411 -0.7568 -0.9589 -0.2794 0.6570 0.9894 -0.5440  转置矩阵 &gt;&gt;a&#39; ans = 1 4 7 2 5 8 3 6 10  逆矩阵 &gt;&gt; inv(a) ans = -0....</p>
  </section>
  <footer class="entry-footer">
    <time>2020.1.10</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/matlab%E5%AD%A6%E4%B9%A0_%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%90%91%E9%87%8F%E6%93%8D%E4%BD%9C/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>YAML与TOML</h2>
  </header>
  <section class="entry-content">
   <p>YAML YAML 是 “YAML Ain’t a Markup Language”（YAML 不是一种标记语言）的递归缩写。有趣的是，在开发的这种语言时，YAML 的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）。
YAML 的语法和其他高级语言类似，并且可以简单表达清单、散列表，标量等数据形态。它使用空白符号缩进和大量依赖外观的特色，特别适合用来表达或编辑数据结构、各种配置文件、倾印调试内容、文件大纲
YAML 的配置文件后缀为 .yml
基本语法  大小写敏感 使用缩进表示层级关系 缩进不允许使用tab，只允许空格 缩进的空格数不重要，只要相同层级的元素左对齐即可 ’#‘表示注释  数据类型  对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 纯量（scalars）：单个的、不可再分的值  对象 对象键值对使用冒号结构表示 key: value，冒号后面要加一个空格。
TOML TOML的全称是 “Tom’s Obvious, Minimal Language”，因为它的作者是 GitHub　联合创始人　Tom Preston-Werner 。
TOML 的目标是成为一个极简的配置文件格式，TOML 被设计成可以无歧义地被映射为哈希表，从而被多种语言解析。
基本语法  大小写敏感 同样使用缩进表示层级关系 缩进可以使用空格，也可以使用Tab 可以在数组中换行 ’#‘表示注释  对象 对象键值对使用等号的结构 key = value
字符串 字符串和 JSON 的定义一致，只有一点除外：　TOML 要求使用　UTF-8 编码。...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.1.9</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/yaml%E4%B8%8Etoml/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>多变量线性回归</h2>
  </header>
  <section class="entry-content">
   <p>多变量梯度下降 与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：
其中：
我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。 多变量线性回归的批量梯度下降算法为：
我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。
Python 代码示例：
def computeCost(X, y, theta): inner = np.power(((X * theta.T) - y), 2) return np.sum(inner) / (2 * len(X))  梯度下降法实践1-特征缩放 在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛
以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。
解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。如图：
最简单的方法是令：x_n = (x_n - miu_n) / s_n ，其中miu_n是平均值，s_n是标准差
梯度下降法实践2—学习率 梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。
也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好
梯度下降算法的每次迭代受到学习率的影响，如果学习率过小，则达到收敛所需的迭代次数会非常高；如果学习率过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。
通常可以考虑尝试这些学习率：
alpha = 0.01, 0.03, 0.1, 0.3, 1, 3, 10
特征和多项式回归 对于房价预测问题
其中，x1 = frontage(临街宽度)，x2 = depth(纵向深度)，x = frontage * depth = area，则：h(x) = theta0 &#43; theta1*x1 &#43; theta2*x2^2...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.1.7</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>降低损失：梯度下降法</h2>
  </header>
  <section class="entry-content">
   <p>梯度下降 梯度下降是一个用来求函数最小值的算法，在这里我们将使用梯度下降算法来求出代价函数（损失函数）J(w1, w2)的最小值
假设我们有时间和计算资源来计算权重值w1的所有可能值的损失。对于回归问题，所产生的损失与w1的图形始终是碗状图，如下所示：
图中的最低点，即斜率正好为 0的位置。这个最小值就是损失函数收敛之处。
过程 开始时我们为(w1, w2)选择一个起始值（起点）。然而起点并不重要；因此很多算法就直接将它们设为0或随机选择一个值。
通过这个参数组合计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。
在这里使用梯度下降法算法计算损失曲线在起点处的梯度。*梯度是偏导数的矢量*；它可以让我们了解哪个方向距离目标“更近”或“更远”
梯度始终指向损失函数中增长最为迅猛的方向。梯度下降法算法会沿着负梯度的方向走一步，以便尽快降低损失。
为了确定损失函数曲线上的下一个点，梯度下降法算法会将梯度大小的一部分与起点相加：
然后，梯度下降法会重复此过程，逐渐接近最低点。
局部最小值  想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。
这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。
 我们持续这么做直到我们得到一个局部最小值（local minimum），然而因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），如果选择不同的初始参数组合，可能会找到不同的局部最小值。
 这个问题在以前的机器学习中可能会遇到，因为机器学习中的特征比较少，所以导致很可能陷入到一个局部最优解中出不来 但是到了深度学习，动辄百万甚至上亿的特征，出现这种情况的概率几乎为0，所以我们可以不用考虑这个问题。
 批量梯度下降 批量梯度下降法是最原始的形式，它是指在每一次迭代时使用所有样本来进行梯度的更新
公式为：
其中alpha是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。
在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新theta0和theta1，当j = 0和j = 1时，会产生更新，所以你将更新J(theta0)和J(theta1)。
实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新theta0和theta1，我的意思是在这个等式中，我们要这样更新：
theta0:=theta0，并更新theta1:=theta1
实现方法是：你应该计算公式右边的部分，通过那一部分计算出theta0和theta1的值，然后同时更新theta0和theta1。
学习率 Alpha 让我们来看看如果太小或太大会出现什么情况：
 如果太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。
 如果太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果太大，它会导致无法收敛，甚至发散。
  假设你将theta1初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得theta1不再改变，也就是新的theta1等于原来的theta1，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率alpha保持不变时，梯度下降也可以收敛到局部最低点。
在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小。
这就是梯度下降算法，你可以用它来最小化任何代价函数，不只是线性回归中的代价函数。...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.1.7</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/%E9%99%8D%E4%BD%8E%E6%8D%9F%E5%A4%B1%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>单变量线性回归</h2>
  </header>
  <section class="entry-content">
   <p> 线性回归 线性回归是解决回归问题最基本的一个方法。其实质就是找到一条直线能尽可能多的使已知的离散值分布在其周围（二维坐标系中）
就像这样：
或者是在三维坐标中，找到一个面来逼近
在这里我们只讨论最简单的单变量线性回归
单变量线性回归 单变量线性回归问题只含有一个特征（输入变量），因此可以把目标直线表达式写为：
h(x) = y = wx &#43; b
其中， x代表特征/输入变量，h代表目标变量/输出变量
我们需要有一个包含许多对(x, y)的训练集，之后把它喂给我们的学习算法，学习算法输出一个函数，通常表示为小写h表示，代表hypothesis(假设)，表示一个函数
因此h根据输入的x值来得出y值，y值就是我们想要根据x知道的答案。因此，h是一个从y到x的函数映射。
代价函数 又称为“损失函数”
在前面的函数h中，我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度。
模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）
我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。 即使得代价函数最小
这个代价函数可以根据最小二乘法得到
我们绘制一个等高线图，三个坐标分别w (图中theta0)、h (图中theta1)和代价函数(图中J(theta0, theta1))
代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。
 参考资料： 吴恩达《机器学习》课程笔记
 ...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.1.7</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>分类(classification)与回归(regression)的区别与关系</h2>
  </header>
  <section class="entry-content">
   <p> 分类与回归是监督学习中的两个主要任务，它们即对应了监督学习中“学习”的部分
分类模型与回归模型的本质其实一样。分类模型可将回归模型的输出离散化，回归模型也可将分类模型的输出连续化
例如：
Linear Recognition 线性回归 使用 y = wx &#43; b 的形式，y就是模型的输出，是一个连续值，所以可以用于处理回归问题
Logistic Recognition 逻辑回归 一般作为分类问题的首选算法，logistic回归只是用到了回归算法，但是其输出的结果是决策边界，是不连续的，所以它其实是分类，而不是回归
二分类 将 y = wx &#43; b 利用激活函数（常用sigmoid函数）映射到 (0,1) 中。再选定一个阈值，将输出分为两类。
多分类 先得到n组w不同的 y = wx &#43;b ，之后进行归一化（例如使用Softmax函数），从而得到在n个类上的概率，即可解决多分类问题
回归问题的应用场景 回归问题通常是用来预测一个值，如预测房价、未来的天气情况等等。例如一个产品的实际价格为500元，通过回归分析预测值为499元，我们认为这是一个比较好的回归分析。
一个比较常见的回归算法是线性回归算法（LR）。
另外，回归分析用在神经网络上，其最上层是不需要加上softmax函数的，而是直接对前一层累加即可。回归是对真实值的一种逼近预测。
分类问题的应用场景 分类问题是用于将事物打上一个标签，通常结果为离散值。
例如判断一幅图片上的动物是一只猫还是一只狗，分类通常是建立在回归之上，分类的最后一层通常要使用softmax函数进行判断其所属类别。
分类并没有逼近的概念，最终正确结果只有一个，错误的就是错误的，不会有相近的概念。
最常见的分类方法是逻辑回归，或者叫逻辑分类。
总结 一个小测验：假设你经营着一家公司，你想开发学习算法来处理这两个问题：
 你有一大批同样的货物，想象一下，你有上千件一模一样的货物等待出售，这时你想预测接下来的三个月能卖多少件？
 你有许多客户，这时你想写一个软件来检验每一个用户的账户。对于每一个账户，你要判断它们是否曾经被盗过？
  那这两个问题，它们属于分类问题、还是回归问题?
 问题一是一个回归问题，因为你知道，如果我有数千件货物，我会把它看成一个实数，一个连续的值。因此卖出的物品数，也是一个连续的值。
 问题二是一个分类问题，因为我会把预测的值，用 0 来表示账户未被盗，用 1 表示账户曾经被盗过。所以我们根据账号是否被盗过，把它们定为0 或 1，然后用算法推测一个账号是 0 还是 1，因为只有少数的离散值，所以我把它归为分类问题。
  ...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.1.6</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/%E5%88%86%E7%B1%BBclassification%E4%B8%8E%E5%9B%9E%E5%BD%92regression%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E5%85%B3%E7%B3%BB/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>C&#43;&#43;解决假币问题</h2>
  </header>
  <section class="entry-content">
   <p> 题目 一个袋子里有30个银币，其中一枚是假币，并且假币和真币一模一样，肉眼很难分辨，目前只知道假币比真币重量轻一点。请问，如何区分出假币？
分析 首先为每个银币编号，然后将所有的银币等分为两份，放在天平的两边。这样就将区分30个银币的问题变为区别两堆银币的问题。
因为假币分量较轻，因此天平较轻的一侧中一定包含假币。再将较轻的一侧中银币等分为两份，重复上述做法。直到剩下两枚银币，便可用天平直接找出假银币。类似于二分法
代码 由于这个是自己做的一个练习题，没有使用OJ判题，所以自己利用随机数生成银币的重量和假币相关信息
#include &lt;iostream&gt; #include &lt;algorithm&gt; #include &lt;ctime&gt; using namespace std; void generate_seq(int coin[]) { srand(time(0)); int coin_weight = rand() % 100; int fake_weight = rand() % coin_weight; int fake_add = rand() % 30; for (int i = 1; i &lt;= 30; i&#43;&#43;) { if (i == fake_add) coin[i] = fake_weight; else coin[i] = coin_weight; } cout &lt;&lt; &#34;fake_add=&#34; &lt;&lt; fake_add &lt;&lt; endl; cout &lt;&lt; &#34;fake_weight=&#34; &lt;&lt; fake_weight &lt;&lt; endl; } void show_seq(int coin[]) { for (int i = 1; i &lt;= 30; i&#43;&#43;) { cout &lt;&lt; coin[i] &lt;&lt; &#34; &#34;; } cout &lt;&lt; endl; } int find_fake(int coin[], int begin, int end) { if (begin == end) return begin; double mid = (begin &#43; end) / 2; int weight_a = 0, weight_b = 0; if ((end - begin &#43; 1) % 2 == 0) //可等分 { for (int i = begin; i &lt;= (int)mid; i&#43;&#43;) weight_a &#43;= coin[i]; for (int i = (int)mid &#43; 1; i &lt;= end; i&#43;&#43;) weight_b &#43;= coin[i]; cout &lt;&lt; begin &lt;&lt; &#34; &#34; &lt;&lt; end &lt;&lt; &#34; &#34; &lt;&lt; mid &lt;&lt; endl; cout &lt;&lt; weight_a &lt;&lt; &#34; &#34; &lt;&lt; weight_b &lt;&lt; endl; if (weight_a &lt; weight_b) find_fake(coin, begin, (int)mid); else find_fake(coin, (int)mid&#43;1, end); }else //不可等分，中间留一个mid { for (int i = begin; i &lt; mid; i&#43;&#43;) weight_a &#43;= coin[i]; for (int i = mid &#43; 1; i &lt;= end; i&#43;&#43;) weight_b &#43;= coin[i]; cout &lt;&lt; begin &lt;&lt; &#34; &#34; &lt;&lt; end &lt;&lt; &#34; &#34; &lt;&lt; mid &lt;&lt; endl; cout &lt;&lt; weight_a &lt;&lt; &#34; &#34; &lt;&lt; weight_b &lt;&lt; endl; if (weight_a &lt; weight_b) find_fake(coin, begin, (int)mid - 1); else if (weight_a &gt; weight_b) find_fake(coin, (int)mid &#43; 1, end); else return mid; } } int main() { //产生随机数列 int coin[31]; generate_seq(coin); //打印数列 show_seq(coin); //找 int fake_add = find_fake(coin, 1, 30); cout &lt;&lt; &#34;fake_add=&#34; &lt;&lt; fake_add &lt;&lt; endl; cout &lt;&lt; &#34;fake_weight=&#34; &lt;&lt; coin[fake_add] &lt;&lt; endl; return 0; }  ...</p>
  </section>
  <footer class="entry-footer">
    <time>2019.12.30</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/c-%E8%A7%A3%E5%86%B3%E5%81%87%E5%B8%81%E9%97%AE%E9%A2%98/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>百度搜索资源平台用crul做链接主动推送</h2>
  </header>
  <section class="entry-content">
   <p>引 最近在百度站长平台加入了这个博客，由于之前在Google上都是直接提交sitemap地址，但是在百度索引sitemap实在太慢了，所以还是选择使用它推荐的crul主动推送方式，在这做个记录
在Windows上安装配置crul 进入curl的官网下载最新的Windows版的binary the curl project安装包
下载完成后解压到任意目录下
之后进入系统属性-&gt;高级系统设置-&gt;高级-&gt;环境变量-&gt;系统变量
新建一个变量，命名为curl，变量值选择之前解压的文件夹-&gt;bin文件夹-&gt;curl.exe
一路保存
之后打开cmd，敲入curl，输出如图，则配置成功
使用curl推送链接 由于使用curl推送链接需要一个只有链接地址的文件，然而sitemap很明显不符合这个条件，所以需要先利用这个在线工具将网站中的链接提取出来
如图，将图中右侧框中的链接复制到一个新建的txt文档，命名为urls.txt
然后在cmd中进入txt文件所在目录，执行百度搜索资源平台给的推送命令，例如：
如果有类似以下的输出，则说明推送成功！
{ &#34;remain&#34;:4999998, &#34;success&#34;:2, &#34;not_same_site&#34;:[], &#34;not_valid&#34;:[] }  在服务器自动推送 很明显，现在这种必须要每次手动推送，很耗费能量，所以之后会试着在网站服务器端配置自动推送，这样才是真正的自动推送嘛...</p>
  </section>
  <footer class="entry-footer">
    <time>2019.12.3</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2%E8%B5%84%E6%BA%90%E5%B9%B3%E5%8F%B0%E7%94%A8crul%E5%81%9A%E9%93%BE%E6%8E%A5%E4%B8%BB%E5%8A%A8%E6%8E%A8%E9%80%81/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Tesseract-OCR样本训练方法</h2>
  </header>
  <section class="entry-content">
   <p>我们通常使用jTessBoxEditor训练工具进行训练，由于该工具是用Java开发的，所以在安装这个软件之前要保证电脑中有Java环境，这里就不介绍了。
安装jTessBoxEditor 可以在这里下载到最新版安装包
把下载得到的压缩包解压到任意位置，双击其中的train.bat文件，等待一会，弹出窗口就可以开始训练了
制作训练样本 生成tif文件 打开软件，选择Tools-&gt;Merge TIFF，文件类型选择ALL Image Files，选择所有要训练的样本图片，打开
之后会又弹出窗口，文件名需要自己设定，注意要按照格式设置：
[lang].[fontname].exp[num].tif
其中lang为语言名称，fontname为字体名称，num为序号。这三项都可以自己定义
这里我们设置为captcha.font.exp0.tif，文件类型TIFF，保存
生成box文件 将之前生成的captcha.font.exp0.tif复制到Tesseract-OCR的安装目录
打开cmd进入安装目录，执行命令
tesseract.exe num.font.exp0.tif num.font.exp0 batch.nochop makebox  将.box文件和.tif文件放在同一文件夹
手动调整 打开jTessBoxEditor工具，点击Box Editor-&gt;Open，选择打开之前生成的.box文件
软件中便会显示Tesseract自动标记识别的字符，接下来就需手动调整每一张的字符框和识别结果
全部修改完成后，选择Save保存即可
训练 先新建一个名为font_properties的文件，注意，只是文件，没有后缀！打开后，内容输入
captcha 0 0 0 0 0  这里全取值为0，表示字体不是粗体、斜体等等
之后在命令行分别运行命令：
shapeclustering.exe -F font_properties -U unicharset captcha.font.exp0.tr mftraining.exe -F font_properties -U unicharset captcha.font.exp0.tr cntraining.exe captcha.font.exp0.tr  之后给文件 inttemp，normproto，pffmtable，shapetable，unicharset 添加前缀captcha.，也就是我们的字体名
生成语言库 命令
combine_tessdata.exe captcha.  会生成一个captcha.traineddata文件，将其复制到Tesseract-OCR安装目录中的tessdata文件夹即可
使用训练结果 在调用tesseract或pytesseract时，只需添加参数lang=“captcha”（我们的字体名），程序就会自动调用啦...</p>
  </section>
  <footer class="entry-footer">
    <time>2019.11.20</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/tesseract-ocr%E6%A0%B7%E6%9C%AC%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95/"></a>
</article>




<footer class="page-footer">
  <nav class="pagination">
    
    <a class="prev" href="/page/3/">← Prev Page</a>
    
    
    <a class="next" href="/page/5/">Next Page →</a>
    
  </nav>
</footer>


</main>
<footer class="footer">
  <span>&copy; 2020 <a href="https://konosuba.xyz/">Tiiktak&#39;s</a></span>
  <span>&middot;</span>
  <span>Powered by <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>️</span>
  <span>&middot;</span>
  <span>Theme️ <a href="https://github.com/nanxiaobei/hugo-paper" rel="noopener" target="_blank">Paper</a></span>
</footer>
<script src="https://konosuba.xyz/js/instantclick.min.js" data-no-instant></script>
<script data-no-instant>InstantClick.init();</script>
<script src="https://konosuba.xyz/js/highlight.min.js" data-no-instant></script>
<script data-no-instant>
  let body;
  function menuToggleListener() {
    body.classList.toggle('blur');
  }
  function setMenuToggleListener() {
    const menuToggle = document.querySelector('.menu-toggle');
    if (!menuToggle) return;
    body = document.querySelector('body');
    menuToggle.addEventListener('click', menuToggleListener);
  }

  hljs.initHighlightingOnLoad();
  setMenuToggleListener();

  InstantClick.on('change', function () {
    document.querySelectorAll('pre code').forEach((block) => {
      hljs.highlightBlock(block);
    });
    setMenuToggleListener();
  });
</script>
</body>
</html>

