[{"content":"1. 安装桌面 2. 安装gnome-session-flashback： sudo apt-get install gnome-session-flashback\r3. 安装VNC Server sudo apt-get install tigervnc-standalone-server tigervnc-xorg-extension\r4. VNC配置桌面环境 vim ~/.vnc/xstartup\r#!/bin/sh unset SESSION_MANAGER\r#unset DBUS_SESSION_BUS_ADDRESS #测试中发现如果去掉该行注释 桌面不会出现\rexport XKL_XMODMAP_DISABLE=1\rexport XDG_CURRENT_DESKTOP=\u0026quot;GNOME-Flashback:GNOME\u0026quot;\rexport XDG_MENU_PREFIX=\u0026quot;gnome-flashback-\u0026quot;\r[ -x /etc/vnc/xstartup ] \u0026amp;\u0026amp; exec /etc/vnc/xstartup\r[ -r $HOME/.Xresources ] \u0026amp;\u0026amp; xrdb $HOME/.Xresources\rxsetroot -solid grey #设置背景色\rvncconfig -iconic \u0026amp;\rgnome-terminal \u0026amp; #连接后会直接打开一个terminal窗口\rnautilus \u0026amp; #连接后会直接打开一个文件窗口\rgnome-session --session=gnome-flashback-metacity --disable-acceleration-check \u0026amp;\rsudo chmod +x ~/.vnc/xstartup\r5. Start vncserver :2 -localhost no #2为端口号，no表示非局域网内账户也可访问\rvncserver -kill :2 #关闭\r  参考：Ubuntu 20.04 安装gnome桌面VNC_zjkuabjt的博客-CSDN博客\n ","date":"2021-03-30T18:33:16+08:00","permalink":"https://konosuba.xyz/blog/vnc_ubuntu_server/","title":"使用vnc查看Ubuntu服务器的远程桌面"},{"content":"Install Pytorch  Raspberry Pi 4B Linux raspberrypi 4.19.75-v7l+ #1270 SMP Tue Sep 24 18:51:41 BST 2019 armv7l GNU/Linux 2G RAM 16G DISK  增加交换内存   关闭内存交换: sudo dphys-swapfile swapoff\n  修改配置文件 sudo vim /etc/dphys-swapfile，设置CONF_SWAPSIZE=4096\n 这里虽然设置为4096，但free -m 查看仍然只有2G交换内存\n   开启内存交换：sudo dphys-swapfile swapon\n  检查：free -m，若swap无变换可尝试重启\n  Pytorch依赖项 sudo apt install libopenblas-dev libblas-dev m4 cmake cython python3-yaml libatlas-base-dev\rsudo apt-get install cython3 libatlas-base-dev m4 libblas-dev cmake\rsudo apt-get install python3-dev python3-setuptools python3-wheel python3-pillow python3-numpy\rpip3 install numpy pyyaml\rFor raspberry pi 4 there may be an issue with the gcc and g++ version. Install an older version and use it\nsudo apt-get install gcc-4.9 g++-4.9\r设置环境变量 export NO_CUDA=1 export NO_DISTRIBUTED=1 export NO_MKLDNN=1 export NO_NNPACK=1 export NO_QNNPACK=1 Download Pytorch git clone --recursive https://github.com/pytorch/pytorch\rcd pytorch\r --recursive：循环克隆项目，即将该项目引用的项目同时克隆\n国内GitHub clone太慢：\n  尝试码云镜像 ，虽然下载Pytorch仓库很快，但由于依赖库仍然是GitHub地址，依然无法clone 成功\n  启动Clash代理，git config --global http.proxy socks5://127.0.0.1:7890，提速明显\n   git checkout v1.6.0\rgit submodule update --init --recursive\rgit submodule update --remote third_party/protobuf\rBuild Pytorch python3 setup.py bdist_wheel 这样将build一个wheel文件，保存在pytorch/dist中\ncd dist pip3 install ./torch-1.6.0-xxx_linux_armv71.whl Install pip3 install torch-1.6.0a0+b31f58d-cp37-cp37m-linux_armv7l.whl\r \nCheck python3\r\u0026gt;\u0026gt;\u0026gt; import torch\r\u0026gt;\u0026gt;\u0026gt; import numpy as np\r\u0026gt;\u0026gt;\u0026gt; a = torch.from_numpy(np.random.randn(1, 100))\r\u0026gt;\u0026gt;\u0026gt; print(a)\rInstall Torchvision git clone https://github.com/pytorch/vision.git\rpip3 install pillow\rcd vision\rgit checkout v0.7.0-rc4\t# pytorch 1.6 对应 torchvision 0.7\rgit submodule update --init --recursive\rpython3 setup.py bdist_wheel\r ERROR\n/home/pi/Pytorch/vision/torchvision/csrc/cpu/decoder/defs.h:12:10: fatal error: libavcodec/avcodec.h: 没有 那个文件或目录\r#include \u0026lt;libavcodec/avcodec.h\u0026gt;\r^~~~~~~~~~~~~~~~~~~~~~\rcompilation terminated.\rerror: command 'arm-linux-gnueabihf-gcc' failed with exit status 1\r将setup.py中178行if has_ffmpeg改为if False\n pip3 install torchvision-0.7.0a0+78ed10c-cp37-cp37m-linux_armv7l.whl\r \n 参考：\n https://segmentfault.com/a/1190000027079852 https://gist.github.com/akaanirban/621e63237e63bb169126b537d7a1d979    **已编译whl安装包: **\n torch v1.6.0 + torchvision v0.7.0 torch v1.7.0 + torchvision v0.8.0  务必使用对应版本！微云 code: tiktak\n ","date":"2021-02-11T12:14:03+08:00","permalink":"https://konosuba.xyz/blog/raspberripi_pytorch_install/","title":"树莓派4B安装Pytorch, torchvision"},{"content":"1. clone ncnn code git clone https://github.com/Tencent/ncnn.git cd ncnn git submodule update --init 2. build cd ncnn mkdir -p build cd build sudo apt install build-essential git cmake libprotobuf-dev protobuf-compiler libvulkan-dev vulkan-utils libopencv-dev cmake -DCMAKE_BUILD_TYPE=Release -DNCNN_VULKAN=ON -DNCNN_SYSTEM_GLSLANG=ON -DNCNN_BUILD_EXAMPLES=ON -DCMAKE_TOOLCHAIN_FILE=../toolchains/pi3.toolchain.cmake -DPI3=ON ..  遇到如下问题：\nCMake Warning at CMakeLists.txt:163 (message):\rGLSLANG_TARGET_DIR must be defined! NCNN_SYSTEM_GLSLANG will be turned off.\rCMake Error at CMakeLists.txt:188 (message):\rThe submodules were not downloaded! Please update submodules with \u0026quot;git\rsubmodule update --init\u0026quot; and try again.\r-- Configuring incomplete, errors occurred!\rSee also \u0026quot;/home/pi/ncnn/ncnn_master/ncnn/build/CMakeFiles/CMakeOutput.log\u0026quot;.\r这是因为部分依赖包不存在，再次运行 git submodule update --init即可\n make -j4  \n3. test Test1 build $ cd ../examples/\rexamples $ ../build/examples/squeezenet ../images/256-ncnn.png\rResult\nvkCreateInstance failed -9\rvkCreateInstance failed -9\r532 = 0.165951\r920 = 0.094098\r716 = 0.062193\rTest2 examples $ cd ../benchmark/\rbenchmark $ ../build/benchmark/benchncnn 10 $(nproc) 0 -1\rResult\nloop_count = 10\rnum_threads = 4\rpowersave = 0\rgpu_device = -1\rcooling_down = 1\rsqueezenet min = 59.54 max = 78.24 avg = 61.93\rsqueezenet_int8 min = 68.22 max = 136.60 avg = 75.22\rmobilenet min = 82.28 max = 103.96 avg = 86.50\rmobilenet_int8 min = 102.12 max = 127.61 avg = 105.56\rmobilenet_v2 min = 72.07 max = 78.58 avg = 73.41\rmobilenet_v3 min = 58.79 max = 62.76 avg = 59.56\rshufflenet min = 39.38 max = 39.76 avg = 39.56\rshufflenet_v2 min = 30.91 max = 62.75 avg = 34.47\rmnasnet min = 62.02 max = 63.65 avg = 63.10\rproxylessnasnet min = 63.72 max = 78.89 avg = 65.54\refficientnet_b0 min = 97.13 max = 134.88 avg = 101.45\rregnety_400m min = 78.38 max = 112.27 avg = 82.46\rblazeface min = 11.84 max = 12.11 avg = 11.98\rgooglenet min = 175.91 max = 226.33 avg = 187.03\rgooglenet_int8 min = 160.86 max = 174.87 avg = 163.83\rresnet18 min = 226.30 max = 256.77 avg = 231.41\rresnet18_int8 min = 137.44 max = 172.20 avg = 144.58\ralexnet min = 175.46 max = 187.97 avg = 178.70\rvgg16 min = 966.03 max = 1200.06 avg = 1021.94\rvgg16_int8 min = 1198.49 max = 1241.05 avg = 1216.26\rresnet50 min = 466.87 max = 511.23 avg = 483.53\rresnet50_int8 min = 332.21 max = 380.04 avg = 344.77\rsqueezenet_ssd min = 178.27 max = 232.75 avg = 187.56\rsqueezenet_ssd_int8 min = 195.93 max = 227.62 avg = 202.93\rmobilenet_ssd min = 175.19 max = 197.45 avg = 182.97\rmobilenet_ssd_int8 min = 172.96 max = 207.40 avg = 181.28\rmobilenet_yolo min = 426.78 max = 526.93 avg = 463.47\rmobilenetv2_yolov3 min = 248.95 max = 274.25 avg = 255.45\ryolov4-tiny min = 329.52 max = 369.67 avg = 342.12\r 参考：\n  ncnn wiki build-for-linux\n  树莓派安装ncnn\n   ","date":"2021-02-10T22:14:03+08:00","permalink":"https://konosuba.xyz/blog/raspberrypi_ncnn_install/","title":"树莓派4B安装ncnn"},{"content":"fpn  https://github.com/fatedier/frp\n 公网服务器配置 公网服务器运行服务端程序\n需要frps 与frps.ini两个文件即可，其中.ini为配置文件：\n[common]\rbind_port = 7000\t# 与客户端进行绑定的端口\r设置自启动 sudo vim /etc/systemd/system/frps.service\t# 服务名即为frps\r修改文件内容如下：\n[Unit]\rDescription=frps daemon\rAfter=syslog.target network.target\rWants=network.target\r[Service]\rType=simple\rExecStart={path/to/frps} -c {path/to/frps.ini}\t# 注意使用绝对路径\rRestart= always\rRestartSec=1min\r[Install]\rWantedBy=multi-user.target\r之后\n#启动frps\rsystemctl daemon-reload\rsystemctl start frps\r#设置为开机启动\rsystemctl enable frps\r内网客户端配置 实验室服务器作为客户端\n需要frpc与frpc.ini两个文件，其中.ini为配置文件：\n[common]\rserver_addr = \u0026lt;服务器公网ip\u0026gt;\rserver_port = 7000\t# 与frps.ini 文件中 bind_port 相同\r[ssh]\rtype = tcp\rlocal_ip = 127.0.0.1\rlocal_port = 22\rremote_port = 6000\t# 服务端监听该端口，并转发到客户端\r设置自启动 sudo vim /etc/systemd/system/frpc.service\r[Unit]\rDescription=frpc daemon\rAfter=syslog.target network.target\rWants=network.target\r[Service]\rType=simple\rExecStart={path/to/frpc} -c {path/to/frpc.ini}\t# 注意使用绝对路径\rRestart= always\rRestartSec=1min\r[Install]\rWantedBy=multi-user.target\r#启动frpc\rsystemctl daemon-reload\rsystemctl start frpc\r#设置为开机启动\rsystemctl enable frpc\rUsage ssh -oPort=\u0026lt;remote_port\u0026gt; user_name@\u0026lt;server_addr\u0026gt;\r Reference\n https://dengxj.blog.csdn.net/article/details/88952420?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control   ","date":"2021-01-11T19:47:20+08:00","permalink":"https://konosuba.xyz/blog/frp_ssh/","title":"使用FPN实现内网穿透，公网访问内网服务器"},{"content":"创建虚拟环境 先cd到项目文件夹\npython -m venv \u0026lt;虚拟环境名\u0026gt;\r将新建一个与虚拟环境同名文件夹\n激活虚拟环境 source \u0026lt;虚拟环境名\u0026gt;/bin/activate\r命令行前方显示(\u0026lt;虚拟环境名\u0026gt;)\n退出虚拟环境 deactivate\r","date":"2021-01-08T17:12:47+08:00","permalink":"https://konosuba.xyz/blog/python_venv/","title":"Python虚拟环境 venv"},{"content":"使用的命令：\nCUDA_VISIBLE_DEVICES=0,1,2,3 ./tools/dist_train.sh ${CONFIG_FILE} 4 --resume-from ${CHECKPOINT_FILE} 出现问题：\n 模型train 1 epoch后挂掉，报错信息：  RuntimeError: replicas_[0].size() == rebuilt_param_indices_.size() INTERNAL ASSERT FAILED at \u0026#34;/pytorch/torch/csrc/distributed/c10d/reducer.cpp\u0026#34;:1326, please report a bug to PyTorch. rebuilt parameter indices size is not same as original model parameters size.321 versus 629160  pytorch github issue:https://github.com/pytorch/pytorch/issues/47050 mmcv issue: https://github.com/open-mmlab/mmcv/issues/636#issuecomment-722436575 解决方案：安装1.6版本pytorch，并重装mmcv  pip uninstall mmcv-full pip install mmcv-full python setup.py install ","date":"2020-12-28T15:52:48+08:00","permalink":"https://konosuba.xyz/blog/mmdet_multiple_gpu_error/","title":"MMDetection单机多卡训练出现问题"},{"content":"安装  下载amd64文件：https://github.com/Dreamacro/clash/releases/ gzip -f -d linux-amd64-clash.gz 下载配置文件config.yaml到~/.config/clash 下载mmdb文件到~/.config/clash  配置（每次使用前）  ./clash启动 浏览器进入127.0.0.1:9090，Clash控制面板 选择一个节点 进入Ubuntu设置，网络设置，代理 Method设为Manual HTTP Proxy、HTTPs Proxy设置为127.0.0.1:7890 Socks Host设置为127.0.0.1:7891  wget配置代理  修改/etc/wgetrc，其中  https_proxy = http://127.0.0.1:7890/ http_proxy = http://127.0.0.1:7890/ ftp_proxy = http://127.0.0.1:7890/ 使用时，wget --proxy=on https://xxxx即可  ","date":"2020-12-28T15:49:53+08:00","image":"https://konosuba.xyz/blog/clash_linux_tutorial/111_hudf87a6e899bd8dba888e085cac1d822c_31212_120x120_fill_box_smart1_2.png","permalink":"https://konosuba.xyz/blog/clash_linux_tutorial/","title":"在Linux中使用Clash"},{"content":" Ubuntu 20.04 LTS    sudo aptitude install mpich\n  mpiexec --version\n image-20201117092421973 \n  new code\n#include \u0026#34;mpi.h\u0026#34;#include \u0026lt;stdio.h\u0026gt; int main(void) { int rankID; int sizeNum; MPI_Init(0, 0); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;sizeNum); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rankID); printf(\u0026#34;Hello world! %d of total = %d\\n\u0026#34;, rankID, sizeNum); MPI_Finalize(); return 0; }   mpicc demo_1.c -o demo_1\n  mpirun -np 8 ./demo_1\n  ","date":"2020-11-17T09:20:26+08:00","permalink":"https://konosuba.xyz/blog/mpich2_ubuntu/","title":"Mpich2_安装 Ubuntu 20.04LTS"},{"content":" Windows 10 Visual Studio 2019 MSMPI v10.1.2  step1. 安装MSMPI 前往官网下载.msi \u0026amp; .exe两个文件，按提示安装即可\n安装过程会自动添加环境变量，可在PATH中看到\nstep2. 配置 VS2019 新建一个空项目，新建一个属性表\n包含目录、库目录\n  包含目录里面添加：C:\\Program Files (x86)\\Microsoft SDKs\\MPI\\Include;\n  库目录的里面添加：C:\\Program Files (x86)\\Microsoft SDKs\\MPI\\Lib\\x64;\n  【C/C+ 附加包含目录】：添加$(MSMPI_INC);$(MSMPI_INC)\\x64\n  【链接器-常规-附加库目录】：添加$(MSMPI_LIB64)\n  【链接器-输入-附加依赖项】：添加msmpi.lib\n  step3. 测试 #include \u0026lt;iostream\u0026gt; #include \u0026lt;mpi.h\u0026gt;  int main(int argc, char* argv[]) { MPI_Init(\u0026amp;argc, \u0026amp;argv); int RankID; MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;RankID); if (0 == RankID) { int SendNum = 16; MPI_Send(\u0026amp;SendNum, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); } else if (1 == RankID) { int RecvNum = 0; MPI_Recv(\u0026amp;RecvNum, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); std::cout \u0026lt;\u0026lt; \u0026#34;Receive from rank 0: \u0026#34; \u0026lt;\u0026lt; RecvNum \u0026lt;\u0026lt; std::endl; } MPI_Finalize(); return 0; }  image-20201116223527189 \nstep4. 配置VS调试指令和参数 VS【工程属性】\n 调试 - 命令：$(MSMPI_BIN)\\mpiexec.exe 调试 - 命令参数：-n 2 $(TargetPath)   image-20201116224322302 \n 通过这种方法运行MPI多进程程序时，无法调试，如果需要调试，就需要将配置到工程里的指令删去才可。\n  Reference：https://blog.csdn.net/u014516143/article/details/89316258\n","date":"2020-11-16T22:14:03+08:00","permalink":"https://konosuba.xyz/blog/msmpi_install/","title":"MSMPI Visual Studio 2019 配置"},{"content":"这是我的《软件过程与项目管理》 的期末作业，我们小组设计了一款校内出行APP，其中软件原型设计部分由我负责，使用PS和XD制作，在这里做个展示:laughing:\n主视觉 各页面 HOME HOME-弹窗 HOME-Tips MORE MORE-包车 ME ","date":"2020-10-08T13:58:14+08:00","image":"https://konosuba.xyz/blog/project_manage_course_prototype_design/title_hu07c02ab2cdb630130b1382d2e9238068_4201951_120x120_fill_box_smart1_2.png","permalink":"https://konosuba.xyz/blog/project_manage_course_prototype_design/","title":"【课程作业】项目管理课程原型设计"},{"content":"1. Convert label to COCO format 使用官方提供的工具bdd100k2coco.py\n 注意：使用bdd100k2coco分支下的文件，master中的该文件无法正常使用\n 在使用前，还需要对该文件进行部分修改：\n# 将69行修改为\t image[\u0026#34;file_name\u0026#34;] = frame[\u0026#34;name\u0026#34;]+\u0026#34;.jpg\u0026#34; # 在73行之后增加 frame = frame[\u0026#34;frames\u0026#34;][0] 之后按如下方式运行\npython bdd100k2coco.py -i {JSON文件夹路径} -o {输出一个coco json文件} -m {转换方式det or track，使用det即可} 调用两次分别将train、val数据集的label转换\n2. Set COCO-like directory tree 按如下目录结构保存我们的数据集\ndata ├── annotations │ ├── instances_train2017.json # 训练集json │ ├── instances_val2017.json\t# 验证集json ├── train2017 │ └── abcdefg-1234567.jpg │ └── ... ├── test2017 │ └── abcdefg-1234567.jpg │ └── ... ├── val2017 │ └── abcdefg-1234567.jpg │ └── ...   接下来进行数据集的定义，我们这里通过直接修改coco数据集定义文件进行操作\n 3. Modify relevant documents ./mmdet/datasets/coco.py 在class CocoDataset(CustomDataset):中，将CLASSES修改为你自己的数据集类别，如我们修改为BDD100K中的类别：\nCLASSES = (\u0026#34;person\u0026#34;, \u0026#34;rider\u0026#34;, \u0026#34;car\u0026#34;, \u0026#34;bus\u0026#34;, \u0026#34;truck\u0026#34;, \u0026#34;bike\u0026#34;, \u0026#34;motor\u0026#34;, \u0026#34;traffic light\u0026#34;, \u0026#34;traffic sign\u0026#34;, \u0026#34;train\u0026#34;) ./mmdet/core/evaluation/class_names.py 在def coco_classes():中，同样修改数据集类别\nreturn [ \u0026#34;pedestrian\u0026#34;, \u0026#34;rider\u0026#34;, \u0026#34;car\u0026#34;, \u0026#34;bus\u0026#34;, \u0026#34;truck\u0026#34;, \u0026#34;bicycle\u0026#34;, \u0026#34;motorcycle\u0026#34;, \u0026#34;traffic light\u0026#34;, \u0026#34;traffic sign\u0026#34;, \u0026#34;train\u0026#34; ] 4. Set Config file 在这一步，我们可以从./configs文件夹中选取预训练的模型。\n我选择的是mask_rcnn_r50_fpn_1x_coco.py，可以看到该文件内容为：\n_base_ = [ \u0026#39;../_base_/models/mask_rcnn_r50_fpn.py\u0026#39;, \u0026#39;../_base_/datasets/coco_instance.py\u0026#39;, \u0026#39;../_base_/schedules/schedule_1x.py\u0026#39;, \u0026#39;../_base_/default_runtime.py\u0026#39; ] 为了便于修改参数，我将其中引用的各文件内容均复制到了一个新建的config文件bdd100_mask_rcnn_r50_fpn_1x_coco.py中\n Config文件中各参数含义可参考：mmdetection的configs中的各项参数具体解释和官方文档\n 接下来开始修改参数\n# data path dataset_type = \u0026#39;CocoDataset\u0026#39; data_root = \u0026#39;./data/\u0026#39;\t# 即数据集的根目录位置 # model model.roi_head.bbox_head.num_classes = 10 # 即数据集中分类数量 # set up working dir to save files and logs work_dir = \u0026#39;./tutorial_exps\u0026#39; # LR optimizer.lr = 0.02 / 8 # 默认值0.02对应8块GPU，若使用一块则为0.02/8 # Epoches total_epochs = 12 # default:12 # Multiple GPUs gpu_ids = (1, 2, 3)\t# GPU id # Batch Size data.sample_per_gpu = 5\t# batch size of a single GPU data.workers_per_gpu = 2 # Worker to pre-fetch data for each single GPU # Evaluation Metric evaluation.metric = \u0026#39;mAP\u0026#39;\t# 由于使用了自定义的数据集，因此修改评价指标 evaluation.interval = 12\t# 通过修改评价区间减少评价用时 # Checpoint checkpoint_config.interval = 12\t# 通过修改检查点保存间隔降低存储成本 5. Train Preference mmdet\\datasets\\builder.py 第131行，默认为pin_memory=False\n修改为pin_memory=True\n参考https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723\n Single GPU 使用./tools/train.py即可，如\npython ./tools/train.py ./configs/bdd100_mask_rcnn_r50_fpn_1x_coco.py --gpus 1 --validate --work_dir work_dirs Multiple GPUs 使用./tools/dist_train.sh即可进行多卡训练，如下：\n./tools/dist_train.sh {config path} {gpu nums} \u0026gt; ./tools/dist_train.sh ./configs/bdd100_mask_rcnn_r50_fpn_1x_coco.py 3  仍有问题待解决：\n 虽然设置的是第1，2，3块GPU，但是实际运行后程序却尝试使用第0，1，2块GPU GPU内存占满，但是训练过程中GPU利用率（Volatile GPU-Util）较低，一直维持在40%左右- 只训练了一个epoch就自动结束，尝试使用训练结果进行测试，也测试失败    参考：\n https://blog.csdn.net/gaoyi135/article/details/90613895 https://blog.csdn.net/xiangxianghehe/article/details/89812058#commentsedit https://blog.csdn.net/jy1023408440/article/details/104700435   ","date":"2020-10-08T13:40:10+08:00","permalink":"https://konosuba.xyz/blog/bdd100k_mmdet_mask-rcnn/","title":"MMDetection中使用Mask-RCNN训练BDD100K数据集"},{"content":"记录自本人安装过程，环境建议：\n Linux or macOS (Windows is not currently officially supported) Python 3.6+ PyTorch 1.3+ CUDA 9.2+ (If you build PyTorch from source, CUDA 9.0 is also compatible) GCC 5+  1. torch \u0026amp; torchvision 我使用的是 torch 1.5.1 + torchvision 0.6.1\npip install torch==1.5.1 torchvision==0.6.1 [-i https://pypi.douban.com/simple]\n https://pytorch.org/get-started/previous-versions/\n 2. mmcv pip install mmcv-full\n3. mmdetection git clone https://github.com/open-mmlab/mmdetection.git cd mmdetection pip install -r requirements/build.txt pip install -v -e . # or \u0026quot;python setup.py develop\u0026quot; 4. test 下载数据\nmkdir checkpoints wget -c https://open-mmlab.s3.ap-northeast-2.amazonaws.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\ -O checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth 此时查看文件目录树如下\n\u0026gt; tree checkpoints checkpoints └── mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth 运行image_demo.py测试mmdet是否安装成功\npython demo/image_demo.py demo/demo.jpg configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco.py checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth 若安装成功，会显示如下图像：\n image-20200925142629606 \nSome ERROR libcudart.so.10.1: cannot open shared object file: No such file or directory 先卸载原有cudatoolkit：conda uninstall cudatoolkit\n再安装10.1版本：conda install cudatoolkit=10.1\n","date":"2020-10-05T13:37:51+08:00","permalink":"https://konosuba.xyz/blog/mmdet_install/","title":"MMDetection安装过程记录"},{"content":"如题，代码如下：\nimport sys python_path = sys.executable print(python_path) 如图：\n","date":"2020-09-25T19:22:57+08:00","permalink":"https://konosuba.xyz/blog/show_python_installation_path/","title":"查看当前使用的Python的安装路径"},{"content":"通常我们在Python中安装OpenCV都是直接用pip install opencv-python\n今天想用Anaconda Navigator安装的时候，在面板中搜索到有libopencv, opencv, py-opencv共三个包，而且三者的描述都是同样的’Computer vision and machine learning software library‘，瞬间迷惑:laughing:\n找到介绍如下：\n OpenCV is computer vision a library written using highly optimized C/C++ code. It makes use of multiprocessing in the background. It has a collection of a large number of algorithms tested and verifiend by the developers. The best thing about this is it\u0026rsquo;s FREE under the BSD license. libopencv is only a metapackage. These packages do not contain actual software, they simply depend on other packages to be installed. So libopencv is a metapackage which simply references one or more related packages which are loosely grouped together. It is dedicated for installing OpenCV in Ubuntu and Debian OS. Python-OpenCV is the OpenCV library available as a wrapper with bindings for python. The link also shows how to install OpenCV in Ubuntu OS.   来源：https://stackoverflow.com/questions/45450706/whats-the-difference-with-opencv-python-opencv-and-libopencv#\n ","date":"2020-07-07T23:52:11+08:00","permalink":"https://konosuba.xyz/blog/difference_between_opencv_pyopencv_libopencv/","title":"python库opencv,py-opencv,libopencv的区别"},{"content":" 更新于2020/4/27 更新：换了个树莓派4B，安装opencv的时候遇到了一些之前没碰到的问题，在这里记录一下\n 主要参考opencv官网文档和博客树莓派+Opencv（一）图像处理\n树莓派4B上安装参考：树莓派4B 安装opencv完整教程基于python3（各种错误解决）\n下载安装依赖项 sudo apt-get install build-essential sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev 在4B上安装时遇到libgtk2.0-dev安装失败的问题：\n这是因为依赖项版本太高了，需要降级安装。所以可以使用命令sudo aptitude install libgtk2.0-dev来进行安装\n在安装过程中，首先会给出一个方案提示是否接受，第一个给出的方案是保留原依赖项，我们要输入n否定它，之后给出第二个方案是降级安装，输入Y使用该方案\n 其中aptitude是一个类似apt-get的包管理工具，但是它能更好处理依赖问题，支持降级安装\n 下载源码 从GitHub下载：\nopencv\nopencv_contrib\n两个都下载.zip压缩包即可\n解压源码并进入文件夹 unzip opencv-4.3.0.zip unzip opencv_contrib-4.3.0.zip cd opencv-4.3.0 创建一个build文件夹用于编译 mkdir build cd build 运行cmake-gui  这一步其实也可以直接使用cmake配合各类参数，不过我觉得图形化界面方便一点\n cmake-gui 选择源码路径和编译路径后点击Configure\n之后在中间的选择框中找到项目BUILD_TESTS，把它的复选框取消\n 这一步是因为后面编译过程中，总是由于opencv_test_xxx这类项目导致编译失败，因此我在这里将它取消\n 之后点击Generate生成，最后输出如图所示则可以进行下一步\n编译 在build目录执行make开始编译，-j表示使用多少线程进行编译，不加数字代表不限制（很容易出问题，不推荐）\n之前使用树莓派3B我选择的-j1，用时约3小时；现在4B我选的是-j4，用时约半个小时\nsudo make -j4 问题 我的4B在这一步就遇到了一个问题，如图\n（这个图我是找的其他人的，不过错误都是一样的）\n这是一个包丢失的问题，解决方案：\n 可以在一个大佬的百度云盘里下载\n将所有带i结尾的文件全部都拷贝到opencv_contrib/modules/xfeatures2d/src/ 路径下即可 树莓派安装opencv时丢失的文件： 链接：https://pan.baidu.com/s/1xi6_5NuTFiP4SD649FgIJw 提取码：mbsj 原文链接：https://blog.csdn.net/weixin_43308627/article/details/97814927\n 之后重新make就可以再次开始\n安装库 在build目录执行\nsudo make install 完成后opencv就已经配好了\n测试 Python运行 使用这里提供的测试程序测试opencv是否正常\n# -*- coding:utf-8 -*- import cv2 import numpy as np cv2.namedWindow(\u0026#34;gray\u0026#34;) img = np.zeros((512,512),np.uint8)#生成一张空的灰度图像 cv2.line(img,(0,0),(511,511),255,5)#绘制一条白色直线 cv2.imshow(\u0026#34;gray\u0026#34;,img)#显示图像 #循环等待，按q键退出 while True: key=cv2.waitKey(1) if key==ord(\u0026#34;q\u0026#34;): break cv2.destoryWindow(\u0026#34;gray\u0026#34;) 最后运行正常，如图\nC++运行 先使用cmake编译，再使用make编译\n编写cpp代码 #include \u0026lt;iostream\u0026gt;#include \u0026lt;opencv2/opencv.hpp\u0026gt;using namespace std; using namespace cv; int main(int argc, char const *argv[]) { Mat img = imread(\u0026#34;image.jpg\u0026#34;); if (img.empty()) { cout \u0026lt;\u0026lt; \u0026#34;error!\u0026#34; \u0026lt;\u0026lt; endl; exit(0) } namedWindow(\u0026#34;image1\u0026#34;, WINDOW_NORMAL); namedWindow(\u0026#34;image2\u0026#34;, WINDOW_NORMAL); imshow(\u0026#34;image1\u0026#34;, img); cvtColor(img, img, COLOR_BGR2GRAY); blur(img, img, Size(7, 7)); Mat edges; Canny(img, edges, 3, 9, 3); imshow(\u0026#34;image2\u0026#34;, edges); waitKey(0); return 0; } 在同目录创建CMakeLists.txt文件 内容：\ncmake_minimum_required(VERSION 2.6) project(test_opencv) #项目名 可改 find_package(OpenCV REQUIRED) add_executable(test_opencv test_opencv.cpp) #项目名和cpp文件名 target_link_libraries(test_opencv ${OpenCV_LIBS}) #项目名 之后就能用cmake编译啦 cmake . make 运行 编译完成后，使ls查看目录下文件\n绿色的就是编译生成的文件\n运行试试\n./opencvtest 于是树莓派的opencv终于安装完成啦，接下来就要调用树莓派摄像头啦\n","date":"2020-04-27T11:25:47+08:00","permalink":"https://konosuba.xyz/blog/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%AE%89%E8%A3%85opencv/","title":"树莓派4B安装opencv以及错误解决"},{"content":"这个notebook也同时发表在Kaggle上\nFashion MNIST数据集    Label Class     0 T-shirt/top   1 Trouser   2 Pullover   3 Dress   4 Coat   5 Sandal   6 Shirt   7 Sneaker   8 Bag   9 Ankle boot    准备工作 import os import torch import torch.nn.functional as F import torch.nn as nn import torch.optim as optim import numpy as np import pandas as pd from PIL import Image import matplotlib.pyplot as plt from torchvision import transforms, datasets from torch.utils.data import Dataset, DataLoader EPOCHS = 20 BATCH_SIZE = 512 DEVICE = (\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) class_names = [\u0026#39;T-shirt/top\u0026#39;, \u0026#39;Trouser\u0026#39;, \u0026#39;Pullover\u0026#39;, \u0026#39;Dress\u0026#39;, \u0026#39;Coat\u0026#39;, \u0026#39;Sandal\u0026#39;, \u0026#39;Shirt\u0026#39;, \u0026#39;Sneaker\u0026#39;, \u0026#39;Bag\u0026#39;, \u0026#39;Ankle boot\u0026#39;] print(torch.__version__) print(DEVICE) 1.4.0 cuda  加载数据 有两种方式来加载 Fashion-MNIST dataset:\n 使用官方在 datasets.FashionMNIST给出的数据集 使用下载的原始csv数据集  在这里我们选择第二种，因此需要建立我们自己的 dataset\n首先 ，用pd.read_csv导入'.csv' 文件\ntrain_csv = pd.read_csv(\u0026#39;/content/fashion-mnist_train.csv\u0026#39;) test_csv = pd.read_csv(\u0026#39;/content/fashion-mnist_test.csv\u0026#39;) print(train_csv.shape) print(test_csv.shape) (60000, 785) (10000, 785)  print(train_csv.info()) print(train_csv.head()) \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; RangeIndex: 60000 entries, 0 to 59999 Columns: 785 entries, label to pixel784 dtypes: int64(785) memory usage: 359.3 MB None label pixel1 pixel2 pixel3 ... pixel781 pixel782 pixel783 pixel784 0 2 0 0 0 ... 0 0 0 0 1 9 0 0 0 ... 0 0 0 0 2 6 0 0 0 ... 0 0 0 0 3 0 0 0 0 ... 0 0 0 0 4 3 0 0 0 ... 0 0 0 0 [5 rows x 785 columns]  根据输出可知，第一列是每个图像的label，而每个图像由784个像素组成\n建立Dataset 关于Dataset的有关内容在这里提到过\n我们需要建立一个继承自Dataset的类，其中必须定义函数get_item() \u0026amp; len()\n get_item() 返回指定图像和label len() 返回数据集中数据数量  # 创建自己的Dataset class FashionDataset(Dataset): def __init__(self, data, transform=None): self.fashion_MNIST = list(data.values) self.transform = transform label, image = [], [] for i in self.fashion_MNIST: label.append(i[0]) image.append(i[1:]) self.labels = np.asarray(label) self.images = np.asarray(image).reshape(-1, 28, 28).astype(\u0026#39;float32\u0026#39;) def __len__(self): return len(self.images) def __getitem__(self, idx): # 返回指定行数据 label = self.labels[idx] image = self.images[idx] if self.transform is not None: # 转换成PIL pil_image = Image.fromarray(np.uint8(image)) image = self.transform(pil_image) return image, label Transform Transform有关的内容也在之前的blog中介绍过：blog:PYTORCH_TORCHVISION\n我们打算使用AlexNet进行训练，AlexNet输入size为227*227，而Fashion-MNIST默认为28*28，故我们需要在transform中对image进行resize\nAlexTransform = transforms.Compose([ transforms.Resize((227, 227)), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ]) DataLoader train_loader = DataLoader( FashionDataset(train_csv, transform=AlexTransform), batch_size=BATCH_SIZE, shuffle=True) test_loader = DataLoader( FashionDataset(test_csv, transform=AlexTransform), batch_size=BATCH_SIZE, shuffle=True) 查看图像 这一步阔以略过，只是看看我们数据集中的图像罢了\ndef matplotlib_imshow(img): img = img.mean(dim=0) img = img / 2 + 0.5 # unnormalize npimg = img.numpy() plt.imshow(npimg, cmap=\u0026#34;Greys\u0026#34;) dataiter = iter(train_loader) images, labels = dataiter.next() img_grid = torchvision.utils.make_grid(images[0]) matplotlib_imshow(img_grid) print(class_names[labels[0]]) T-shirt/top 定义Net AlexNet网络的相关介绍可以在这篇文章：卷积神经网络CNN以及几种经典模型中找到\nclass fasion_mnist_alexnet(nn.Module): # 选用AlexNet网络 def __init__(self): super().__init__() self.conv1 = nn.Sequential( nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2) ) self.conv2 = nn.Sequential( nn.Conv2d(96, 256, 5, 1, 2), nn.ReLU(), nn.MaxPool2d(3, 2) ) self.conv3 = nn.Sequential( nn.Conv2d(256, 384, 3, 1, 1), nn.ReLU() ) self.conv4 = nn.Sequential( nn.Conv2d(384, 384, 3, 1, 1), nn.ReLU() ) self.conv5 = nn.Sequential( nn.Conv2d(384, 256, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(3, 2) ) self.fc1 = nn.Linear(256 * 6 * 6, 4096) self.fc2 = nn.Linear(4096, 4096) self.fc3 = nn.Linear(4096, 10) def forward(self, x): out = self.conv1(x) out = self.conv2(out) out = self.conv3(out) out = self.conv4(out) out = self.conv5(out) out = out.view(out.size(0), -1) out = F.relu(self.fc1(out)) # 256*6*6 -\u0026gt; 4096 out = F.dropout(out, 0.5) out = F.relu(self.fc2(out)) out = F.dropout(out, 0.5) out = self.fc3(out) out = F.log_softmax(out, dim=1) return out 实例化Model model = fasion_mnist_alexnet().to(DEVICE) criterion = F.nll_loss optimizer = optim.Adam(model.parameters()) 训练函数 def train(model, device, train_loader, optimer, epoch): model.train() for batch_idx, (data, target) in enumerate(train_loader): target = target.type(torch.LongTensor) data, target = data.to(device), target.to(device) optimizer.zero_grad() output = model(data) loss = criterion(output, target) loss.backward() optimizer.step() if (batch_idx + 1) % 30 == 0: print(\u0026#34;Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\u0026#34;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) 测试函数 def test(model, device, test_loader): model.eval() test_loss = 0 correct = 0 with torch.no_grad(): for data, target in test_loader: data, target = data.to(device), target.to(device) output = model(data) test_loss += criterion(output, target, reduction=\u0026#39;sum\u0026#39;).item() pred = output.max(1, keepdim=True)[1] correct += pred.eq(target.view_as(pred)).sum().item() test_loss /= len(test_loader.dataset) # loss之和除以data数量 -\u0026gt; mean print(\u0026#34;\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\u0026#34;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) print(\u0026#39;=\u0026#39;*50) 开始训练 for epoch in range(1, EPOCHS+1): train(model, DEVICE, train_loader, optimizer, epoch) test(model, DEVICE, test_loader) Train Epoch:1 [14848/60000 (25%)]\tLoss: 0.877214 Train Epoch:1 [30208/60000 (50%)]\tLoss: 0.644841 Train Epoch:1 [45568/60000 (75%)]\tLoss: 0.532848 Test set: Average loss: 0.4413, Accuracy: 8316/10000 (83%) ================================================== Train Epoch:2 [14848/60000 (25%)]\tLoss: 0.433440 Train Epoch:2 [30208/60000 (50%)]\tLoss: 0.360927 Train Epoch:2 [45568/60000 (75%)]\tLoss: 0.368575 Test set: Average loss: 0.3194, Accuracy: 8838/10000 (88%) ================================================== Train Epoch:3 [14848/60000 (25%)]\tLoss: 0.308415 Train Epoch:3 [30208/60000 (50%)]\tLoss: 0.224128 Train Epoch:3 [45568/60000 (75%)]\tLoss: 0.245119 Test set: Average loss: 0.2992, Accuracy: 8995/10000 (90%) ================================================== Train Epoch:4 [14848/60000 (25%)]\tLoss: 0.272408 Train Epoch:4 [30208/60000 (50%)]\tLoss: 0.226366 Train Epoch:4 [45568/60000 (75%)]\tLoss: 0.274030 Test set: Average loss: 0.2753, Accuracy: 8973/10000 (90%) ================================================== Train Epoch:5 [14848/60000 (25%)]\tLoss: 0.224429 Train Epoch:5 [30208/60000 (50%)]\tLoss: 0.237268 Train Epoch:5 [45568/60000 (75%)]\tLoss: 0.280958 Test set: Average loss: 0.2686, Accuracy: 9082/10000 (91%) ================================================== Train Epoch:6 [14848/60000 (25%)]\tLoss: 0.217329 Train Epoch:6 [30208/60000 (50%)]\tLoss: 0.258806 Train Epoch:6 [45568/60000 (75%)]\tLoss: 0.179489 Test set: Average loss: 0.2273, Accuracy: 9180/10000 (92%) ================================================== Train Epoch:7 [14848/60000 (25%)]\tLoss: 0.232198 Train Epoch:7 [30208/60000 (50%)]\tLoss: 0.193284 Train Epoch:7 [45568/60000 (75%)]\tLoss: 0.180621 Test set: Average loss: 0.2556, Accuracy: 9073/10000 (91%) ================================================== Train Epoch:8 [14848/60000 (25%)]\tLoss: 0.202838 Train Epoch:8 [30208/60000 (50%)]\tLoss: 0.177613 Train Epoch:8 [45568/60000 (75%)]\tLoss: 0.166227 Test set: Average loss: 0.2537, Accuracy: 9090/10000 (91%) ================================================== Train Epoch:9 [14848/60000 (25%)]\tLoss: 0.191794 Train Epoch:9 [30208/60000 (50%)]\tLoss: 0.179932 Train Epoch:9 [45568/60000 (75%)]\tLoss: 0.157028 Test set: Average loss: 0.2236, Accuracy: 9181/10000 (92%) ================================================== Train Epoch:10 [14848/60000 (25%)]\tLoss: 0.201635 Train Epoch:10 [30208/60000 (50%)]\tLoss: 0.193036 Train Epoch:10 [45568/60000 (75%)]\tLoss: 0.133806 Test set: Average loss: 0.2228, Accuracy: 9207/10000 (92%) ================================================== Train Epoch:11 [14848/60000 (25%)]\tLoss: 0.140554 Train Epoch:11 [30208/60000 (50%)]\tLoss: 0.195291 Train Epoch:11 [45568/60000 (75%)]\tLoss: 0.167740 Test set: Average loss: 0.2298, Accuracy: 9169/10000 (92%) ================================================== Train Epoch:12 [14848/60000 (25%)]\tLoss: 0.145187 Train Epoch:12 [30208/60000 (50%)]\tLoss: 0.136410 Train Epoch:12 [45568/60000 (75%)]\tLoss: 0.148455 Test set: Average loss: 0.2208, Accuracy: 9244/10000 (92%) ================================================== Train Epoch:13 [14848/60000 (25%)]\tLoss: 0.102129 Train Epoch:13 [30208/60000 (50%)]\tLoss: 0.119473 Train Epoch:13 [45568/60000 (75%)]\tLoss: 0.151384 Test set: Average loss: 0.2176, Accuracy: 9245/10000 (92%) ================================================== Train Epoch:14 [14848/60000 (25%)]\tLoss: 0.085864 Train Epoch:14 [30208/60000 (50%)]\tLoss: 0.161960 Train Epoch:14 [45568/60000 (75%)]\tLoss: 0.173307 Test set: Average loss: 0.2276, Accuracy: 9210/10000 (92%) ================================================== Train Epoch:15 [14848/60000 (25%)]\tLoss: 0.158055 Train Epoch:15 [30208/60000 (50%)]\tLoss: 0.164117 Train Epoch:15 [45568/60000 (75%)]\tLoss: 0.119916 Test set: Average loss: 0.2236, Accuracy: 9236/10000 (92%) ================================================== Train Epoch:16 [14848/60000 (25%)]\tLoss: 0.120705 Train Epoch:16 [30208/60000 (50%)]\tLoss: 0.138526 Train Epoch:16 [45568/60000 (75%)]\tLoss: 0.132989 Test set: Average loss: 0.2330, Accuracy: 9241/10000 (92%) ================================================== Train Epoch:17 [14848/60000 (25%)]\tLoss: 0.082980 Train Epoch:17 [30208/60000 (50%)]\tLoss: 0.142380 Train Epoch:17 [45568/60000 (75%)]\tLoss: 0.088001 Test set: Average loss: 0.2495, Accuracy: 9213/10000 (92%) ================================================== Train Epoch:18 [14848/60000 (25%)]\tLoss: 0.106110 Train Epoch:18 [30208/60000 (50%)]\tLoss: 0.121420 Train Epoch:18 [45568/60000 (75%)]\tLoss: 0.102312 Test set: Average loss: 0.2547, Accuracy: 9251/10000 (93%) ================================================== Train Epoch:19 [14848/60000 (25%)]\tLoss: 0.118317 Train Epoch:19 [30208/60000 (50%)]\tLoss: 0.113046 Train Epoch:19 [45568/60000 (75%)]\tLoss: 0.085053 Test set: Average loss: 0.2661, Accuracy: 9213/10000 (92%) ================================================== Train Epoch:20 [14848/60000 (25%)]\tLoss: 0.103729 Train Epoch:20 [30208/60000 (50%)]\tLoss: 0.049429 Train Epoch:20 [45568/60000 (75%)]\tLoss: 0.109371 Test set: Average loss: 0.2729, Accuracy: 9230/10000 (92%) ==================================================  可见当进行10次训练后，我们模型的准确率就稳定在了92%，所以想要继续提升准确率就需要对模型进行改进\n","date":"2020-03-08T23:03:09+08:00","permalink":"https://konosuba.xyz/blog/fashion_mnist_alexnet/","title":"AlexNet分类Fashion-MNIST(Pytorch实现)"},{"content":"RNN简介 现实世界中，很多元素都是相互连接的，比如室外的温度是随着气候的变化而周期性的变化的、我们的语言也需要通过上下文的关系来确认所表达的含义。但是机器要做到这一步就相当得难了。因此，就有了现在的循环神经网络，他的本质是：拥有记忆的能力，并且会根据这些记忆的内容来进行推断。因此，他的输出就依赖于当前的输入和记忆。\n网络结构及原理 循环神经网络的基本结构特别简单，就是将网络的输出保存在一个记忆单元中，这个记忆单元和下一次的输入一起进入神经网络中。\n一个最简单的循环神经网络在输入时的结构示意图：\nRNN 可以被看做是同一神经网络的多次赋值，每个神经网络模块会把消息传递给下一个，我们将这个图的结构展开:\n根据循环神经网络的结构也可以看出它在处理序列类型的数据上具有天然的优势。因为网络本身就是 一个序列结构，这也是所有循环神经网络最本质的结构。\n我们可以用下面的公式来表示循环神经网络的计算方法：\n总结图：\nPytorch中 pytorch 中使用 nn.RNN 类来搭建基于序列的循环神经网络，它的构造函数有以下几个参数：\n input_size：输入数据X的特征值的数目。 hidden_size：隐藏层的神经元数量，也就是隐藏层的特征数量。 num_layers：循环神经网络的层数，默认值是 1。 bias：默认为 True，如果为 false 则表示神经元不使用 bias 偏移参数。 batch_first：如果设置为 True，则输入数据的维度中第一个维度就是 batch 值，默认为 False。默认情况下第一个维度是序列的长度， 第二个维度才是batch，第三个维度是特征数目。 dropout：如果不为空，则表示最后跟一个 dropout 层抛弃部分数据，抛弃数据的比例由该参数指定  RNN 中最主要的参数是 input_size 和 hidden_size，这两个参数务必要搞清楚。其余的参数通常不用设置，采用默认值就可以了。\nrnn = torch.nn.RNN(20,50,2) input = torch.randn(100 , 32 , 20) h_0 =torch.randn(2 , 32 , 50) output,hn=rnn(input ,h_0) print(output.size(),hn.size()) \u0026#39;\u0026#39;\u0026#39; torch.Size([100, 32, 50]) torch.Size([2, 32, 50]) \u0026#39;\u0026#39;\u0026#39;  一文搞懂RNN（循环神经网络）基础篇\n  RNN\n  详解循环神经网络(Recurrent Neural Network)\n LSTM  Long Short Term Memory Networks 长短期记忆网络\n 它解决了短期依赖的问题，并且它通过刻意的设计来避免长期依赖问题\n思路 原始 RNN 的隐藏层只有一个状态，即h，它对于短期的输入非常敏感。\n再增加一个状态，即c，让它来保存长期的状态，称为单元状态(cell state)。\n把上图按照时间维度展开：\n在 t 时刻，LSTM 的输入有三个：\n 当前时刻网络的输入值 x_t 上一时刻 LSTM 的输出值 h_t-1 上一时刻的单元状态 c_t-1  LSTM 的输出有两个：\n 当前时刻 LSTM 输出值 h_t 当前时刻的单元状态 c_t  控制长期状态c LSTM中使用三个控制开关来控制\n结构 标准的循环神经网络内部只有一个简单的层结构，而 LSTM 内部有 4 个层结构：\n  忘记层：决定状态中丢弃什么信息\n  tanh层：用来产生更新值的候选项，说明状态在某些维度上需要加强，在某些维度上需要减弱\n  sigmoid层(输入门层): 它的输出值要乘到tanh层的输出上，起到一个缩放的作用，极端情况下sigmoid输出0说明相应维度上的状态不需要更新\n  最后一层决定输出什么，输出值跟状态有关。候选项中的哪些部分最终会被输出由一个sigmoid层来决定。\n  Pytorch中 pytorch 中使用 nn.LSTM 类来搭建基于序列的循环神经网络，他的参数基本与RNN类似\nlstm = torch.nn.LSTM(10, 20,2) input = torch.randn(5, 3, 10) h0 =torch.randn(2, 3, 20) c0 = torch.randn(2, 3, 20) output, hn = lstm(input, (h0, c0)) print(output.size(),hn[0].size(),hn[1].size()) \u0026#39;\u0026#39;\u0026#39; torch.Size([5, 3, 20]) torch.Size([2, 3, 20]) torch.Size([2, 3, 20]) \u0026#39;\u0026#39;\u0026#39;  详解LSTM\n GRU  Gated Recurrent Units\n GRU 和 LSTM 最大的不同在于 GRU 将遗忘门和输入门合成了一个\u0026quot;更新门\u0026quot;，同时网络不再额外给出记忆状态，而是将输出结果作为记忆状态不断向后循环传递，网络的输人和输出都变得特别简单。\nPytorch中 rnn = torch.nn.GRU(10, 20, 2) input = torch.randn(5, 3, 10) h_0= torch.randn(2, 3, 20) output, hn = rnn(input, h0) print(output.size(),h0.size()) \u0026#39;\u0026#39;\u0026#39; torch.Size([5, 3, 20]) torch.Size([2, 3, 20]) \u0026#39;\u0026#39;\u0026#39; 循环网络的向后传播 BPTT 在向前传播的情况下，RNN的输入随着每一个时间步前进。在反向传播的情况下，我们“回到过去”改变权重，因此我们叫它通过时间的反向传播（BPTT）\n我们通常把整个序列（单词）看作一个训练样本，所以总的误差是每个时间步（字符）中误差的和。权重在每一个时间步长是相同的（所以可以计算总误差后一起更新）。\n 使用预输出和实际输出计算交叉熵误差 网络按照时间步完全展开 对于展开的网络，对于每一个时间步计算权重的梯度 因为对于所有时间步来说，权重都一样，所以对于所有的时间步，可以一起得到梯度（而不是像神经网络一样对不同的隐藏层得到不同的梯度） 随后对循环神经元的权重进行升级  RNN展开的网络看起来像一个普通的神经网络。反向传播也类似于普通的神经网络，只不过我们一次得到所有时间步的梯度。如果有100个时间步，那么网络展开后将变得非常巨大，所以为了解决这个问题才会出现LSTM和GRU这样的结构。\nRNN用于NLP时的储备知识 词嵌入 word embedding 为了让计算机能够能更好地理解我们的语言，建立更好的语言模型，我们需要将词汇进行表征。\n在图像分类问题会使用 one-hot 编码。比如LeNet中一共有10个数字0-9，如果这个数字是2的话，它的编码就是 (0，0，1，0， 0，0 ，0，0，0，0)，对于分类问题这样表示十分的清楚。\n但是在自然语言处理中，因为单词的数目过多比如有 10000 个不同的词，那么使用 one-hot 这样的方式来定义，效率就特别低，并且占用内存，也不能体现单词的词性， one-hot 没办法体现这个特点，所以 必须使用另外一种方式定义每一个单词。\n用不同的特征来对各个词汇进行表征，相对于不同的特征，不同的单词均有不同的值，这就是词嵌入\n词嵌入不仅对不同单词实现了特征化的表示，还能通过计算词与词之间的相似度\n实际上是在多维空间中，寻找词向量之间各个维度的距离相似度，我们就可以实现类比推理，比如说夏天和热，冬天和冷，都是有关联关系的。\n在 PyTorch 中我们用 nn.Embedding 层来做嵌入词袋模型，Embedding层第一个输入表示我们有多少个词，第二个输入表示每一个词使用多少维度的向量表示。\n# an Embedding module containing 10 tensors of size 3 embedding = torch.nn.Embedding(10, 3) # a batch of 2 samples of 4 indices each input = torch.LongTensor([[1,2,4,5],[4,3,2,9]]) output=embedding(input) print(output.size()) \u0026#39;\u0026#39;\u0026#39; torch.Size([2, 4, 3]) \u0026#39;\u0026#39;\u0026#39; Beam Search 在生成第一个词的分布后，可以使用贪心搜索会根据我们的条件语言模型挑选出最有可能输出的第一个词语，但是对于贪心搜索算法来说，我们的单词库中有成百到千万的词汇，去计算每一种单词的组合的可能性是不可行的。所以我们使用近似的搜索办法，使得条件概率最大化或者近似最大化的句子，而不是通过单词去实现。\nBeam Search（集束搜索）是一种启发式图搜索算法，通常用在图的解空间比较大的情况下，为了减少搜索所占用的空间和时间，在每一步深度扩展的时候，剪掉一些质量比较差的结点，保留下一些质量较高的结点。虽然Beam Search算法是不完全的，但是用于了解空间较大的系统中，可以减少空间占用和时间。\nBeam search可以看做是做了约束优化的广度优先搜索，首先使用广度优先策略建立搜索树，树的每层，按照启发代价对节点进行排序，然后仅留下预先确定的个数（Beam width-集束宽度）的节点，仅这些节点在下一层次继续扩展，其他节点被剪切掉。\n 将初始节点插入到list中 将给节点出堆，如果该节点是目标节点，则算法结束； 否则扩展该节点，取集束宽度的节点入堆。然后到第二步继续循环。 算法结束的条件是找到最优解或者堆为空。  在使用上，集束宽度可以是预先约定的，也可以是变化的，具体可以根据实际场景调整设定。\n Beam Search\n 注意力模型 对于使用编码和解码的RNN模型，我们能够实现较为准确度机器翻译结果。对于短句子来说，其性能是十分良好的，但是如果是很长的句子，翻译的结果就会变差。 我们人类进行人工翻译的时候，都是一部分一部分地进行翻译，引入的注意力机制，和人类的翻译过程非常相似，其也是一部分一部分地进行长句子的翻译。\n","date":"2020-02-19T22:47:20+08:00","permalink":"https://konosuba.xyz/blog/rnn/","title":"循环神经网络RNN以及几种经典模型"},{"content":"简介  CNN -\u0026gt; Convolutional Neural Network\n 卷积神经网络是由一个或多个卷积层和顶端的全连通层（也可以使用1x1的卷积层作为最终的输出）组成的一种前馈神经网络\n基本概念 局部感受野(Local Receptive Fields) 一般的神经网络往往会把图像的每一个像素点连接到全连接的每一个神经元中，而卷积神经网络则是把每一个隐藏节点只连接到图像的某个局部区域，从而减少参数训练的数量。\n例如，一张1024×720的图像，使用9×9的感受野，则只需要81个权值参数。对于一般的视觉也是如此，当观看一张图像时，更多的时候关注的是局部。\n共享权值(Shared Weights) 在卷积神经网络的卷积层中，神经元对应的权值是相同的，由于权值相同，因此可以减少训练的参数量。共享的权值和偏置也被称作卷积核或滤波器\n池化(Pooling) 由于待处理的图像往往都较大，而实际处理时没必要直接对原图进行分析，最主要的是要能够有效获得图像的特征。因此可以采用类似图像压缩的思想，对图像进行卷积之后，通过一个下采样过程来调整图像的大小\n 什么是下采样？ 上采样、下采样到底是个啥\n 结构组成 我们通过卷积的计算操作来提取图像局部的特征，每一层都会计算出一些局部特征，这些局部特征再汇总到下一层，这样一层一层的传递下去，特征由小变大，最后在通过这些局部的特征对图片进行处理，这样大大提高了计算效率，也提高了准确度。\n卷积层 提取特征\n卷积计算  动图来源于：stanford.edu, Feature extraction using convolution\n  NOTE: 深度学习中的卷积与信号处理中的卷积略有不同，深度学习中的卷积略去了翻转的步骤（因为起初卷积核是随机生成的，没有方向）\n  输入矩阵大小 n 卷积核大小 f 边界填充 (p)adding，指在原矩阵周围填充的层数 步长 (s)tride  计算公式\n卷积结果大小：(n - f + 2p) / s + 1向下取整\n多个卷积核 在每一个卷积层我们会设置多个卷积核，代表多个不同的特征，这些特征就是需要传递到下一层的输出，训练的过程就是训练不同的核\n激活函数 引入非线性关系\n由于卷积的操作是线性的，所以需要使用进行激活，通常使用Relu\n池化层 减少参数数量\n通过减少卷积层之间的连接，降低运算复杂程度。\n池化层一般放在卷积层后面，所以池化层池化的是卷积层的输出\n一般使用的有最大池化max-pooling和平均池化mean-pooling\n操作与卷积类似，即过滤器在矩阵上滑动\ndropout层 dropout是2014年 Hinton 提出防止过拟合而采用的trick，增强了模型的泛化能力 Dropout（随机失活）是指在深度学习网络的训练过程中，按照一定的概率将一部分神经网络单元暂时从网络中丢弃，相当于从原始的网络中找到一个更瘦的网络，说的通俗一点，就是随机将一部分网络的传播掐断，听起来好像不靠谱，但是通过实际测试效果非常好。\n全连接层 一般作为最后的输出层使用\n我们的特征都是使用矩阵表示的，所以再传入全连接层之前还需要对特征进行压扁，将他这些特征变成一维的向量，如果要进行分类的话，就是用sofmax作为输出，如果要是回归的话就直接使用linear即可\n经典模型 LeNet-5  用卷积提取空间特征； 由空间平均得到子样本； 用 tanh 或 sigmoid 得到非线性； 用 multi-layer neural network（MLP）作为最终分类器； 层层之间用稀疏的连接矩阵，以避免大的计算成本。  示例可见-\u0026gt;Pytorch官方教程_训练一个分类器\n详细解析-\u0026gt;深度学习 \u0026mdash; 卷积神经网络CNN（LeNet-5网络详解）\nAlexNet 论文：《ImageNet Classification with Deep Convolutional Neural Networks》\n可以看作LeNet的更深更广的版本，可用于学习更复杂的对象，更丰富更高维的图像特征。AlexNet的特点：\n 更深的网络结构 用ReLu替换之前的Sigmoid作为激活函数 使用Dropout抑制过拟合 使用数据增强Data Augmentation抑制过拟合 使用层叠的卷积层，即卷积层+卷积层+池化层来提取图像的特征 重叠最大池，避免平均池的平均效果； 使用 GPU NVIDIA GTX 580 可以减少训练时间，这比用CPU处理快了 10 倍，所以可以被用于更大的数据集和图像上。  图中分为上下两个部分的网络，论文中提到这两部分网络分别对应两个GPU，只有到了特定的网络层后才需要两块GPU进行交互，这种设置完全是利用两块GPU来提高运算的效率，其实在网络结构上差异不是很大\n在这里稍微简化，看作只有一个部分。AlexNet有8层，5层卷积，3层全连接层。\nAlexNet有一个特殊的计算层：LRN(Local Response Normalized层)，这一层用于对当前层的输出结果做平滑处理\nAlexnet的每一阶段（含一次卷积主要计算的算作一层）可以分为8层：\n 卷积层1 Conv-Relu-Pooling-LRN  输入为 224×224×3的图像，卷积核的数量为96，论文中两片GPU分别计算48个核\n卷积核的大小为 11×11×3,stride = 4, padding = 0. 卷积后为 54x54，dimention = 96\n池化，pool_size = (3, 3), stride = 2, padding = 0\n最终获得第一层卷积的feature map，size为27x27x96\n卷积层2 Conv-Relu-Pooling-LRN  输入为上一层卷积的feature map，卷积的个数为256个，论文中两片GPU分别有128个卷积核\n卷积核大小：5x5x48，stride = 1, padding = 2\n池化为max_pooling, pool_size = (3, 3), stride = 2\n卷积层3 Conv-Relu  卷积核个数为384，大小3x3x256, padding = 1\n卷积层4 Conv-Relu  卷积核个数为384，大小3x3, padding = 1\n卷积层5 Conv-Relu-Pooling  卷积核个数为256，大小3x3, padding = 1\n进行max_pooling, pool_size = (3, 3), stride = 2\n全连接层1 fc-Relu-Dropout  Dropout层：在训练中以50%的概率使得隐藏层的某些neuron的输出为0，这样就都丢掉了一半节点的输出，BP的时候也不会更新这些节点，防止过拟合\n 全连接层2 fc-Relu-Dropout\n  全连接层3 fc-softmax\n  三个全连接层每一层的神经元的个数为4096，最终输出softmax为1000,因为ImageNet这个比赛的分类个数为1000。全连接层中使用了RELU和Dropout。\nPytorch的torchvision包中包含AlexNet的官方实现\nimport torcvision model = torchvision.models.alexnet(pretrained=False) print(model) \u0026#39;\u0026#39;\u0026#39; AlexNet( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)) (1): ReLU(inplace=True) (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) (4): ReLU(inplace=True) (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (7): ReLU(inplace=True) (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (9): ReLU(inplace=True) (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace=True) (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) ) (avgpool): AdaptiveAvgPool2d(output_size=(6, 6)) (classifier): Sequential( (0): Dropout(p=0.5, inplace=False) (1): Linear(in_features=9216, out_features=4096, bias=True) (2): ReLU(inplace=True) (3): Dropout(p=0.5, inplace=False) (4): Linear(in_features=4096, out_features=4096, bias=True) (5): ReLU(inplace=True) (6): Linear(in_features=4096, out_features=1000, bias=True) ) ) \u0026#39;\u0026#39;\u0026#39; 深入理解AlexNet\nVGG 论文：Very deep convolutional networks for large-scale image recognition\n论文中提出了多个版本的VGG结构，其中D就是著名的VGG16\n 每个卷积层中使用更小的 3×3 filters，并将它们组合成卷积序列 多个3×3卷积序列可以模拟更大的接收场的效果 每次的图像像素缩小一倍，卷积核的数量增加一倍  VGG由5层卷积层、3层全连接层、softmax输出层构成，层与层之间为max-pooling，所有隐层的激活函数均为ReLu\n 小卷积核  VGG采用多个小卷积核(3x3)的卷积层代替一个卷积核较大的卷积层。这样一方面可以减少卷积层的参数，另一方面相当于进行了更多的非线性映射，可以增加网络的拟合/表达能力\nVGG的作者认为，当input为8x8，经过三层Conv 3x3后，output为2x2，这等同于1层Conv 7x7的结果；当input为8x8，经过2层Conv 3x3后，output为2x2，等同于1层Conv 5x5的结果。这样可以增加非线性映射，也能很好地减少参数\n小池化核  相比于AlexNet的3x3的池化核， VGG全部采用2x2的池化核\n通道数多  VGG网络第一层的通道数为64，后面每层都进行了翻倍，最多到512个通道，通道数的增加，使得更多的信息可以被提取出来\n层数更深、特征图更宽  由于卷积核专注于扩大通道数、池化专注于缩小宽和高，使得模型架构上更深更宽的同时，控制了计算量的增加规模。\n同样，torchvision包中有官方实现\nimport torchvision model = torchvision.models.vgg16(pretrained=False) print(model) \u0026#39;\u0026#39;\u0026#39; VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU(inplace) (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU(inplace) (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=1000, bias=True) ) ) \u0026#39;\u0026#39;\u0026#39; 简化图如下：\n 深度解析：大话CNN经典模型：VGGNet\n GoogLeNet 论文：Rethinking the Inception Architecture for Computer Vision\nGoogLeNet团队提出了Inception网络结构，就是构造一种“基础神经元”结构，来搭建一个稀疏性、高计算性能的网络结构。\nInception V1 通过设计一个稀疏网络结构，但是能够产生稠密的数据，既能增加神经网络的表现，又能保证计算资源的使用效率。谷歌题出了最原始的Inception的基本结构\n该结构将CNN中常用的卷积（1x1，3x3，5x5）、池化操作（3x3）堆叠在一起（卷积、池化后的尺寸相同，将通道相加），一方面增加了网络的宽度，另一方面也增加了网络对尺度的适应性。\n网络中的卷积层能够提取输入的每一个细节信息，同时5x5的滤波器也能够覆盖大部分接受层的输入。还可以进行一个池化操作，以减少空间大小，降低过度拟合。在这些层之上，每个层后都要做一个ReLu操作，以增加网络的非线性特性\n然而这个Inception原始版本，所有的卷积核都在上一层的所有输出上来做，而那个5x5的卷积核所需的计算量就太大了，造成了特征图的厚度很大，为了避免这种情况，在3x3前、5x5前、max pooling后分别加上了1x1的卷积核，以起到了降低特征图厚度的作用，这也就形成了Inception v1的网络结构，如下图所示：\n1x1卷积的主要目的是为了减少维度，还用于修正线性激活（ReLU）。\nGoogLeNet  使用1x1的卷积块(NIN)来减少特征数量，这通常被称为“瓶颈”，可以减少深层神经网络的计算负担 每个池化层之前，增加feature maps， 增加每一层的宽度来增多特征的组合性  GoogLeNet最大的特点就是包含若干个Inception模块，所以有时候也称作 Inception Net。\nGoogLeNet虽然层数要比VGG多很多，但是由于Inception的设计，计算速度方面要快很多。\n网络结构如下（共22层）：\nInception架构的主要思想是找出如何让已有的稠密组件接近与覆盖卷积视觉网络中的最佳局部稀疏结构。\n现在需要找出最优的局部构造，并且重复几次。之前的一篇文献提出一个层与层的结构，在最后一层进行相关性统计，将高相关性的聚集到一起。这些聚类构成下一层的单元，且与上一层单元连接。假设前面层的每个单元对应于输入图像的某些区域，这些单元被分为滤波器组。在接近输入层的低层中，相关单元集中在某些局部区域，最终得到在单个区域中的大量聚类，在最后一层通过1x1的卷积覆盖\n上面的话听起来很生硬，其实解释起来很简单：每一模块我们都是用若干个不同的特征提取方式，例如 3x3卷积，5x5卷积，1x1的卷积，pooling等，都计算一下，最后再把这些结果通过Filter Concat来进行连接，找到这里面作用最大的。而网络里面包含了许多这样的模块，这样不用我们人为去判断哪个特征提取方式好，网络会自己解决（是不是有点像AUTO ML），在Pytorch中实现了InceptionA-E，还有InceptionAUX 模块。\n# inception_v3需要scipy import torchvision model = torchvision.models.inception_v3(pretrained=False) #我们不下载预训练权重 print(model) \u0026#39;\u0026#39;\u0026#39; 太多了，这里就不贴了 \u0026#39;\u0026#39;\u0026#39;  详解：大话CNN经典模型：GoogLeNet（从Inception v1到v4的演进）\n ResNet 刚才的googlenet已经很深了，ResNet可以做到更深，通过残差计算，可以训练超过1000层的网络，俗称跳连接\n退化问题 网络层数增加，但是在训练集上的准确率却饱和甚至下降了。这个不能解释为overfitting，因为overfit应该表现为在训练集上表现更好才对。\n这个就是网络退化的问题，退化问题说明了深度网络不能很简单地被很好地优化\n残差网络的解决办法 深层网络的后面那些层是恒等映射，那么模型就退化为一个浅层网络。那现在要解决的就是学习恒等映射函数了。让一些层去拟合一个潜在的恒等映射函数H(x) = x比较困难。如果把网络设计为H(x) = F(x) + x。我们可以转换为学习一个残差函数F(x) = H(x) - x。 只要F(x)=0，就构成了一个恒等映射H(x) = x. 而且，拟合残差肯定更加容易。\n我们在激活函数前将上一层（或几层）的输出与本层计算的输出相加，将求和的结果输入到激活函数中做为本层的输出，引入残差后的映射对输出的变化更敏感，其实就是看本层相对前几层是否有大的变化，相当于是一个差分放大器的作用。\n图中的曲线就是残差中的shoutcut，他将前一层的结果直接连接到了本层，也就是俗称的跳连接。\n网络结构 以经典的resnet18来看一下网络结构\nimport torchvision model = torchvision.models.resnet18(pretrained=False) #我们不下载预训练权重 print(model) 选择模型 以上表格可以清楚的看到准确率和计算量之间的对比。\n小型图片分类任务，resnet18基本上已经可以了，如果真对准确度要求比较高，再选其他更好的网络架构。\n","date":"2020-02-18T18:43:39+08:00","permalink":"https://konosuba.xyz/blog/cnn/","title":"卷积神经网络CNN以及几种经典模型"},{"content":"介绍神经网络的时候已经说到，神经元会对化学物质的刺激进行，当达到一定程度的时候，神经元才会兴奋，并向其他神经元发送信息。神经网络中的激活函数就是用来判断我们所计算的信息是否达到了往后面传输的条件。\n为什么激活函数都是非线性的 因为如果使用线性的激活函数，那么input跟output之间的关系始终为线性的，这样完全可以不使用网络结构，直接使用线性组合即可。\n所以需要激活函数来引入非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中，增加了神经网络模型泛化的特性。\n一般只有在输出层有极小的可能性使用线性激活函数，在隐含层都使用非线性激活函数.\n常见的激活函数 # 初始化一些信息 import torch import torch.nn.functional as F import matplotlib.pyplot as plt import numpy as np x= torch.linspace(-10,10,60) Sigmoid 函数 g(z) = a = 1 / (1 + e^(-z)) g\u0026#39;(z) = a\u0026#39; = a (1 - a) 在sigmod函数中我们可以看到，其输出是在(0,1)这个开区间，它能够把输入的连续实值变换为0和1之间的输出，如果是非常大的负数，那么输出就是0；如果是非常大的正数输出就是1，起到了抑制的作用。\nax = plt.gca() ax.spines[\u0026#39;right\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.spines[\u0026#39;top\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.xaxis.set_ticks_position(\u0026#39;bottom\u0026#39;) ax.spines[\u0026#39;bottom\u0026#39;].set_position((\u0026#39;data\u0026#39;, 0)) ax.yaxis.set_ticks_position(\u0026#39;left\u0026#39;) ax.spines[\u0026#39;left\u0026#39;].set_position((\u0026#39;data\u0026#39;, 0)) plt.ylim((0, 1)) sigmod=torch.sigmoid(x) plt.plot(x.numpy(),sigmod.numpy()) 但是sigmod由于需要进行指数运算（这个对于计算机来说是比较慢，相比relu），再加上函数输出不是以0为中心的（这样会使权重更新效率降低），当输入稍微远离了坐标原点，函数的梯度就变得很小了（几乎为零）。\n在神经网络反向传播的过程中不利于权重的优化，这个问题叫做梯度饱和，也可以叫梯度弥散。这些不足，所以现在使用到sigmod基本很少了，基本上只有在做二元分类（0，1）时的输出层才会使用。\nTanh 函数 tanh是双曲正切函数，输出区间是在(-1,1)之间，而且整个函数是以0为中心的\nax = plt.gca() ax.spines[\u0026#39;right\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.spines[\u0026#39;top\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.xaxis.set_ticks_position(\u0026#39;bottom\u0026#39;) ax.spines[\u0026#39;bottom\u0026#39;].set_position((\u0026#39;data\u0026#39;, 0)) ax.yaxis.set_ticks_position(\u0026#39;left\u0026#39;) ax.spines[\u0026#39;left\u0026#39;].set_position((\u0026#39;data\u0026#39;, 0)) plt.ylim((-1, 1)) tanh=torch.tanh(x) plt.plot(x.numpy(),tanh.numpy()) 与sigmoid函数类似，当输入稍微远离了坐标原点，梯度还是会很小，但是好在tanh是以0为中心点，如果使用tanh作为激活函数，还能起到归一化（均值为0）的效果。\n一般二分类问题中，隐藏层用tanh函数，输出层用sigmod函数，但是随着Relu的出现所有的隐藏层基本上都使用relu来作为激活函数了\nReLu 函数  Relu(Rectified Linear Units) 修正线性单元\n a = max(0, z)  当 z \u0026gt; 0 时，梯度始终为1，从而提高神经网络基于梯度算法的运算速度。 当 z \u0026lt; 0 时，梯度始终为0  ReLu函数只有线性关系（只需要判断输入是否大于0），不管是前向传播还是反向传播，都比Simoid和Tanh要快很多\nax = plt.gca() ax.spines[\u0026#39;rights\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.spines[\u0026#39;top\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.xaxis.set_ticks_position(\u0026#39;bottom\u0026#39;) ax.spines[\u0026#39;bottom\u0026#39;].set_position((\u0026#39;data\u0026#39;, 0)) ax.yaxis.set_ticks_position((\u0026#39;data\u0026#39;, 0)) plt.ylim((-3, 10)) relu = F.relu(x) plt.plot(x.numpy(), relu.numpy()) 当输入是负数的时候，ReLU是完全不被激活的；但是到了反向传播过程中，输入负数，梯度就会完全到0，这个和sigmod函数、tanh函数有一样的问题。 实际的运用中，该缺陷的影响不是很大。\nLeaky Relu 函数 为了解决relu函数z\u0026lt;0时的问题出现了 Leaky ReLU函数，该函数保证在z\u0026lt;0的时候，梯度仍然不为0。\nReLU的前半段设为αz而非0，通常α=0.01\na = max(𝛼z, z) ax = plt.gca() ax.spines[\u0026#39;right\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.spines[\u0026#39;top\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.xaxis.set_ticks_position(\u0026#39;bottom\u0026#39;) ax.spines[\u0026#39;bottom\u0026#39;].set_position((\u0026#39;data\u0026#39;, 0)) ax.yaxis.set_ticks_position(\u0026#39;left\u0026#39;) ax.spines[\u0026#39;left\u0026#39;].set_position((\u0026#39;data\u0026#39;, 0)) plt.ylim((-3, 10)) l_relu=F.leaky_relu(x,0.1) # 这里的0.1是为了方便展示，理论上应为0.01甚至更小的值 plt.plot(x.numpy(),l_relu.numpy()) 理论上来讲，Leaky ReLU有ReLU的所有优点，但是在实际操作当中，并没有完全证明Leaky ReLU总是好于ReLU。\nReLU目前仍是最常用的activation function，在隐藏层中推荐优先尝试！\n","date":"2020-02-15T18:43:29+08:00","permalink":"https://konosuba.xyz/blog/pytorch_activation_function/","title":"Pytorch中的激活函数"},{"content":"在PyTorch中使用Mini-batch这种方法进行训练\nMini-batch的梯度下降法 对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候处理速度会很慢，而且也不可能一次的载入到内存或者显存中\n所以我们会把大数据集分成小数据集，一部分一部分的训练，这个训练子集即称为Mini-batch。\n对于普通的梯度下降法，一个epoch只能进行一次梯度下降；而对于Mini-batch梯度下降法，一个epoch可以进行Mini-batch的个数次梯度下降。\n普通的batch梯度下降法和Mini-batch梯度下降法代价函数的变化趋势，如下图所示：\n 如果训练样本的大小比较小时，能够一次性的读取到内存中，那我们就不需要使用Mini-batch 如果训练样本的大小比较大时，一次读入不到内存或者现存中，那我们必须要使用 Mini-batch来分批的计算 Mini-batch size的计算规则如下，在内存允许的最大情况下使用2的N次方个size  torch.optim torch.optim是一个实现了各种优化算法的库。大部分常用优化算法都有实现\ntorch.optim.SGD  Stochastic Gradient Descent\n 随机梯度下降算法，带有动量(momentum)的算法作为一个可选参数可以进行设置\n 可以把动量看作惯性：当你跑起来，由于惯性的存在你跑起来会比刚起步加速的时候更轻松，当你跑过头，想调头往回跑，惯性会让你拖着你。 在普通的梯度下降法的方向相同，则会加速。反之，则会减速。 加了动量的优势：\n 加速收敛 提高精度（减少收敛过程中的振荡）   SGD(params, lr=\u0026lt;required parameter\u0026gt;, momentum=0, dampening=0, weight_decay=0, nesterov=False) torch.optim.RMSprop  Root Mean Square Prop\n 均方根传递。也是一种可以加快梯度下降的算法，利用RMSprop算法，可以减小某些维度梯度更新波动较大的情况，使其梯度下降的速度变得更快\n相较于gradient descent with momentum，RMSprop的思想是:\n 对于梯度震动较大的项，在下降时，减小其下降速度； 对于震动幅度小的项，在下降时，加速其下降速度。  torch.optim.Adam Adam 优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法\n它能基于训练数据迭代地更新神经网络权重\n详细介绍\ne.d.\n# 这里的lr，betas，还有eps都是用默认值即可，所以Adam是一个使用起来最简单的优化方法 optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08) ","date":"2020-02-15T17:46:54+08:00","permalink":"https://konosuba.xyz/blog/pytorch_gradient_descent/","title":"Pytorch中的梯度下降及优化"},{"content":"由于Pytorch中使用mini-batch进行计算，因此其损失函数的计算结果会对mini-batch取平均\n常见的Pytorch中内置的损失函数有：\nnn.L1Loss 计算input与output的差的绝对值，input与output应该是同一维度，得到的loss也是相应维度\nnn.NLLLoss  Negative Log Likelihood\n class torch.nn.NLLLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction=\u0026#39;mean\u0026#39;) 常用于多分类任务。在NLLLoss输入input之前，我们需要对input进行log_softmax处理(即将input转换成概率分布的形式，并且取对数，底数为e)\n计算公式\nloss(input, class) = -input[class] NLLLoss中如果传递了weight参数，会对损失进行加权，公式就变成了\nloss(input, class) = -weight[class] * input[class] nn.MSELoss  Mean Square Error\n 计算input与ouput之间的均方差\nnn.CrossEntropyLoss 多分类用的交叉熵损失合函数，将LogSoftMax和nn.NLLLoss集成到一个类中，nn.CrossEntropyLoss可以自动对input进行logSoftMax操作，可以理解为CrossEntropyLoss()=log_softmax() + NLLLoss()\n传入weight参数后\n一般多分类的情况会使用这个损失函数\nnn.BCELoss  Binary Cross Entropy\n 计算input与output之间的二进制交叉熵\n添加weight后\n用的时候需要在该层前面加上 Sigmoid 函数\n","date":"2020-02-15T15:33:34+08:00","permalink":"https://konosuba.xyz/blog/pytorch_loss_function/","title":"Pytorch中的损失函数Loss Function"},{"content":"PyTorch通过torch.utils.data对一般常用的数据加载进行了封装，可以很容易地实现多线程数据预读和批量加载。\n可以通过dataset定义数据集，并使用Datalorder载入和遍历数据集\nDataset Dataset是一个抽象类，为了能够方便的读取，需要将要使用的数据包装为Dataset类。\n自定义的Dataset需要继承它并且实现两个成员方法：\n __getitem__() 该方法定义用索引(0 到 len(self))获取一条数据或一个样本 __len__() 该方法返回数据集的总长度  下面使用kaggle上的一个竞赛bluebook for bulldozers自定义一个数据集，用里面的数据字典来做说明（因为条数少）\nfrom torch.utils.data import Dataset import pandas as pd #定义一个数据集 class BulldozerDataset(Dataset): # 实现初始化方法，在初始化的时候将数据读载入 def __init__(self, csv_file): self.df=pd.read_csv(csv_file) # 返回df的长度 def __len__(self): return len(self.df) # 根据 idx 返回一行数据 def __getitem__(self, idx): return self.df.iloc[idx].SalePrice 至此，我们的数据集已经定义完成了，我们可以实例话一个对象访问他\nds_demo = BulldozerDataset(\u0026#39;median_benchhmark.csv\u0026#39;) print(len(ds_demo)) # 11573 print(ds_demo[0]) # 24000.0 Dataloader DataLoader为我们提供了对Dataset的读取操作，常用参数有：batch_size(每个batch的大小)、 shuffle(是否进行shuffle操作)、 num_workers(加载数据的时候使用几个子进程)。下面做一个简单的操作\ndl = torch.utils.data.DataLoader(ds_demo, batch_size=10, shuffle=True, num_workers=0) DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据\nidata=iter(dl) print(next(idata)) # Output: # tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.]) 常见的用法是使用for循环对其进行遍历\nfor i, data in enumerate(dl): print(i,data) break ","date":"2020-02-15T01:08:09+08:00","permalink":"https://konosuba.xyz/blog/pytorch_dataset_dataloader/","title":"Pytorch_数据集的创建和加载"},{"content":"torchvision.models torchvision不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用，或者在进行迁移学习 torchvision.models模块的 子模块中包含以下模型结构。\n AlexNet VGG ResNet SqueezeNet DenseNet  torchvision.datasets 这其中所有的数据集都是torch.utils.data.Dataset的子类，它们都具有__getitem__和__len__实现的方法。因此，它们都可以传递给torch.utils.data.DataLoader，它使用torch.multiprocessing并行加载多个样本。\ntorchvision.transforms 提供了一般的图像转换操作类，用作数据处理和数据增强\n其中都是常见的图像转换，可以通过Compose将他们链接在一起\nfrom torchvision import transforms as transforms transform = transforms.Compose([ transforms.RandomCrop(32, padding=4), #先四周填充0，在把图像随机裁剪成32*32 transforms.RandomHorizontalFlip(), #图像一半的概率翻转，一半的概率不翻转 transforms.RandomRotation((-45,45)), #随机旋转 transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.229, 0.224, 0.225)), #R,G,B每层的归一化用到的均值和方差 ]) 此外还有torchvision.transforms.functional 模块，可对转换进行细粒度控制，这对于要构建一个更复杂的 transformation pipeline（例如在segmentation tasks分段任务中）很有帮助\ntorchvision.transforms.Normalize(mean, std, inplace=False) 用均值和标准差对张量图像进行归一化。\n给定n个通道的均值: (M1,...,Mn) 和标准差: (S1,..,Sn), 这个转换将归一化输入torch.*Tensor的每个通道。例如: input[channel] = (input[channel] - mean[channel]) / std[channel]\n Note: 这种变换的作用不适当，即它不会改变输入张量\n torchvision.utils torchvision.utils.make_grid(tensor, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0) 创建图像网格，即将若干幅图像拼成一幅图像\n  tensor (Tensor or list) – 四维 mini-batch Tensor 尺寸为 (B x C x H x W) 或一个所有图像大小相同的list\n  nrow (python:int, optional) – 网格中每行展示图像的数量。最后一行size为 (B / nrow, nrow)\n  padding (python:int, optional) – 填充量（多幅图像间距）\n  normalize (bool, optional) – 若为True, 根据由range范围指定的最大最小值，将图像归一化到(0, 1)\n  range (tuple, optional) – tuple (min, max) 用于归一化图像. min和max默认通过tensor计算\n  scale_each (bool, optional) – 若为True, 分别缩放该批图像中的每个图像，而不是缩放所有图像的(min, max)\n  pad_value (python:float, optional) – 填充值\n  ","date":"2020-02-14T00:19:28+08:00","permalink":"https://konosuba.xyz/blog/pytorch_torchvision/","title":"Pytorch_torchvision"},{"content":"关于数据 一般来说，对于图像、文本、音频或视频数据，可以使用标准的Python包来将这些数据加载为numpy array，之后可以将这些array转换为torch.*Tensor\n 对于图像，Pillow、OpenCV包 音频，scipy、librosa包 文本，可以使用原始Python和Cython加载，或NLKT和SpaCy  特别的，对于视觉任务，有一个包torchvision，其中包含了处理类似Imagnet, CIFAR10, MNIST等常见数据集的方法，以及图像转换器，如torchvision.datasets和torch.utils.data.DataLoader\ntorchvision包不仅提供了巨大的便利，也避免了代码的重复。\n在这里使用CIFAR10数据集，它有如下10个类别 ：‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。\nCIFAR-10的图像都是 3x32x32 大小的，即，3颜色通道，32x32像素。\n训练一个图像分类器  使用torchvision加载和归一化CIFAR10训练集和测试集 定义一个卷积神经网络 定义损失函数 用训练集训练网络 用测试集测试网络  1.读取和归一化 CIFAR10 使用torchvision可以非常容易得加载CIFAR10\nimport torch import torchvision import torchvision.transforms as transforms torchvision的输出是 [0,1]的PILImage图像，把它转化为归一化范围为[-1, 1]的张量\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 下载数据并加载到loader中 trainset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) classes = (\u0026#39;plane\u0026#39;, \u0026#39;car\u0026#39;, \u0026#39;bird\u0026#39;, \u0026#39;cat\u0026#39;, \u0026#39;deer\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;frog\u0026#39;, \u0026#39;horse\u0026#39;, \u0026#39;ship\u0026#39;, \u0026#39;truck\u0026#39;) \u0026#39;\u0026#39;\u0026#39; Output: Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz Extracting ./data/cifar-10-python.tar.gz to ./data Files already downloaded and verified \u0026#39;\u0026#39;\u0026#39; 我们展示一些训练图像\nimport matplotlib.pyplot as plt import numpy def imshow(img): img = img / 2 + 0.5 # 未归一化 npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2,0))) # 将数据转换为迭代器 dataiter = iter(trainloader) images, labels = dataiter.next() # 展示图象 imshow(torchvision.utils.make_grid(images)) # 展示图像标签 print(\u0026#39;\u0026#39;.join(\u0026#39;%5s\u0026#39; % classes[labels[j]] for j in range(4))) 2.定义一个卷积神经网络 从之前的神经网络一节复制神经网络代码，并修改为输入3通道图像。\nimport torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() 3.定义损失函数和优化器 使用交叉熵作为损失函数，使用带动量的随机梯度下降优化\nimport torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9) 4.训练网络 我们只需要在数据迭代器上循环，将数据输入给网络，并优化\nfor epoch in range(2): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data # 梯度置零 optimizer.zero_grad() # 获得输出-\u0026gt;计算损失-\u0026gt;反向传播-\u0026gt;优化 outputs = net(input) loss = critertion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() if i % 2000 == 1999: print(\u0026#39;[%d, %5d] loss: %.3f\u0026#39; % (epoch+1, i+1, running_loss / 2000)) running_loss = 0.0 print(\u0026#39;Finished Training\u0026#39;) \u0026#39;\u0026#39;\u0026#39; Output: [1, 2000] loss: 2.216 [1, 4000] loss: 1.863 [1, 6000] loss: 1.669 [1, 8000] loss: 1.565 [1, 10000] loss: 1.524 [1, 12000] loss: 1.440 [2, 2000] loss: 1.396 [2, 4000] loss: 1.350 [2, 6000] loss: 1.349 [2, 8000] loss: 1.293 [2, 10000] loss: 1.312 [2, 12000] loss: 1.270 Finished Training \u0026#39;\u0026#39;\u0026#39;  快速保存我们训练的模型:\nPATH = \u0026#39;./cifar_net.pth\u0026#39; torch.save(net.state_dict(), PATH)  5.用测试集测试网络 我们在整个训练集上进行了2次训练，但是我们需要检查网络是否从数据集中学习到有用的东西。 通过预测神经网络输出的类别标签与实际情况标签进行对比来进行检测。 如果预测正确，我们把该样本添加到正确预测列表。\n第一步，显示测试集中的图片并熟悉图片内容。\ndataiter = iter(testloader) images, labels = dataiter.next() # 显示图片 imshow(torchvision.utils.make_grid(images)) print(\u0026#39;GroundTruth: \u0026#39;, \u0026#39; \u0026#39;.join(\u0026#39;%5s\u0026#39; % classes[labels[j]] for j in range(4))) 再来看看神经网络预测的结果\nouputs = net(images) # 输出是10个标签的概率，选取概率最高的那个标签 _, predicted = torch.max(outputs, 1) # 返回每一行中最大值的元素 _ 及其索引 predicted print(\u0026#39;Predicted: \u0026#39;, \u0026#39; \u0026#39;.join(\u0026#39;%5s\u0026#39; % classes[predicted[j]] for j in range(4))) \u0026#39;\u0026#39;\u0026#39; Output: Predicted: cat car car ship \u0026#39;\u0026#39;\u0026#39; 再看看网络在测试集上的结果：\ncorrect = 0 total = 0 with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(\u0026#39;Accuracy of the network on the 10000 test images: %d%%\u0026#39; % ( 100 * correct / total)) \u0026#39;\u0026#39;\u0026#39; Output: Accuracy of the network on the 10000 test images: 54 % \u0026#39;\u0026#39;\u0026#39; 再分别看看不同标签的学习情况：\nclass_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(10): print(\u0026#39;Accuracy of %5s: %2d%%\u0026#39; % ( classes[i], 100 * class_correct[i] / class_total[i])) \u0026#39;\u0026#39;\u0026#39; Output: Accuracy of plane : 56 % Accuracy of car : 73 % Accuracy of bird : 42 % Accuracy of cat : 33 % Accuracy of deer : 34 % Accuracy of dog : 62 % Accuracy of frog : 57 % Accuracy of horse : 62 % Accuracy of ship : 52 % Accuracy of truck : 73 % \u0026#39;\u0026#39;\u0026#39; 在GPU上训练 把一个神经网络移动到GPU上训练就像把一个Tensor转换GPU上一样简单。并且这个操作会递归遍历有所模块，并将其参数和缓冲区转换为CUDA张量。\ndevice = torch.device(\u0026#34;cuda:0\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) # 确认我们的电脑支持CUDA，然后显示CUDA信息： print(device) # Output: # cuda:0 假定device是CUDA设备。\n然后这些方法将递归遍历所有模块并将模块的参数和缓冲区 转换成CUDA张量：\nnet.to(device) 记住：inputs, targets 和 images 也要转换。\ninputs, labels = inputs.to(device), labels.to(device) 为什么我们没注意到GPU的速度提升很多？那是因为网络非常的小。\n实践: 尝试增加你的网络的宽度（第一个nn.Conv2d的第2个参数，第二个nn.Conv2d的第一个参数，它们需要是相同的数字），看看你得到了什么样的加速。\n","date":"2020-02-13T18:37:46+08:00","permalink":"https://konosuba.xyz/blog/pytorch_4/","title":"Pytorch学习笔记_4_训练一个分类器"},{"content":"Linear 对输入数据应用线性变换：y = xA^T + b\ntorch.nn.Linear(in_features, out_features, bias=True) 参数  in_features 每个输入样本的大小 out_features 每个输出样本的大小 bias 若为False，layer不会学习附加偏差b  shape   输入: (N, ∗, H_in)，其中 ∗ 代表任意数量的附加维度，H_in = in_features\n  输出: (N, *, H_out)，除了最后一个维度，其余都与输入相同，H_out = out_features\n  ","date":"2020-02-12T23:13:53+08:00","permalink":"https://konosuba.xyz/blog/pytorch_linear/","title":"Pytorch_linear"},{"content":"Conv2d torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode=\u0026#39;zeros\u0026#39;)  in_channels 输入数据通道数 out_channels 输出数据通道数 kennel_size 卷积核大小，int或tuple stride 步长 padding 每个维度零填充的数量 dilation 内核点之间的距离，也称à trous algorithm groups 控制inputs与outputs间的连接    groups=1，所有输入都卷积到输出 groups=2，并排设置两个conv层，每个层查看一半的输入通道，并生成一半的输出通道，然后将两者连接起来 groups=in_channels，每个输入通道都有它自己的filter，size为[out_channels/in_channels]   ","date":"2020-02-12T22:22:18+08:00","permalink":"https://konosuba.xyz/blog/pytorch_conv2d/","title":"Pytorch_nn.Conv2d"},{"content":"super() super()是用于**调用父类（超类）**的一个方法\n用于解决多重继承问题：直接用类名调用父类方法在使用单继承时没有问题，但若使用多继承，会涉及到查找顺序（MRO）、重复调用（钻石继承）等问题\n MRO 就是类的方法解析顺序表, 其实也就是继承父类方法时的顺序表。\n 语法 super(type[, object-or-type]) 参数   type 类\n  object-or-type 类，一般是self\n  在 Python3 中：super().xxx\n在 Python2 中：super(Class, self).xxx\n两者等价\n示例 class Bird: def __init__(self): self.hungry = True def eat(self): if self.hungry: print(\u0026#39;Ahahahah\u0026#39;) else: print(\u0026#39;No thanks!\u0026#39;) class SongBird(Bird): def __init__(self): self.sound = \u0026#39;Squawk\u0026#39; def sing(self): print(self.sound) sb = SongBird() sb.sing() # 能正常输出\u0026#39;Squawk\u0026#39; sb.eat() # 报错，因为 SongBird 中没有 hungry 特性 使用super解决：\nclass SongBird(Bird): def __init__(self): super().__init__() self.sound = \u0026#39;squawk\u0026#39; def sing(self): print(self.sound) 它会查找所有的超类，以及超类的超类，直到找到所需的特性为止\n","date":"2020-02-12T17:12:47+08:00","permalink":"https://konosuba.xyz/blog/python_super/","title":"Python面向对象_super()函数"},{"content":"Neural Networks   神经网络可以通过使用torch.nn包来创建\n  nn依赖于autograd来定义模型并求导。\n  一个nn.Module类包含各个层和一个forward(input)前向传播方法，该方法返回output\n  例如这个分类数字图像的网络：\n这是个简单的前馈神经网络，它接受一个输入，然后一层接一层的传递，最后输出计算结果\n一个神经网络的典型训练过程：\n 定义包含一些可学习的参数（或权重）的神经网络 在数据集上迭代 通过神经网络处理输入 计算损失函数（预测值与实际值的差值大小） 将梯度反向传播回网络的参数 更新网络参数，主要使用一个简单的更新法则：weight = weight - learning_rate * gradient   另参见：konosuba.xyz/blog/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4\n 定义网络 import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): # 构造方法 super().__init__() # 复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数 # 卷积层 self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) # fc(full_connect)全连接函数，均为线性函数 y = Wx + b self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # 前向传播函数 # 将 x 放入卷积层 conv # 经过激励函数 ReLu # 使用2x2窗口进行最大池化 Max_poolinhg x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) x = F.max_pool2d(F.relu(self.conv2(x)), 2) # (2, 2)也可直接换作 2 # view 将 x 展开成一维的向量，总特征数并不改变，为接下来的全连接作准备。 # view 的作用类似于Numpy中的reshape x = x.view(-1, self.num_flat_features(x)) # 输入x经过 full_connect，再经过ReLU激活函数，然后更新x x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) # 输入x经过 full_connect 然后更新x x = self.fc3(x) return x def num_flat_features(self, x): # 计算x的总特征量(把每个数字都看作是一个特征) # 比如 x 是4*2*2的张量，那么它的特征总量就是16。 # Pytorch 仅接受批输入（一次性输入多张图片） size = x.size()[1:] # 考虑除了第一个维度以外的所有维度 num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) \u0026#39;\u0026#39;\u0026#39; Output: Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) \u0026#39;\u0026#39;\u0026#39;  super()函数使用参考：super() linear()函数使用参考：linear() relu\n 在模型中必须要定义 forward 函数，backward 函数（用来计算梯度）会被autograd自动创建。\n可以在 forward 函数中使用任何针对 Tensor 的操作。\nnet.parameters()返回可被学习的参数（权重）列表和值:\nparams = list(net.parameters()) print(len(params)) print(params[0].size()) # conv1\u0026#39;s .weight # Output: # 10 # torch.Size([6, 1, 5, 5]) 测试网络 测试随机输入32×32。 注：这个网络（LeNet）期望的输入大小是32×32，如果使用MNIST数据集来训练这个网络，请把图片大小重新调整到32×32\ninput = torch.randn(1, 1, 32, 32) out = net(input) print(out) # Output: # tensor([[-0.1102, 0.0936, -0.0787, -0.0155, -0.0480, 0.0496, -0.0683, -0.0112, # -0.0889, 0.0134]], grad_fn=\u0026lt;AddmmBackward\u0026gt;) 反向传播 将所有参数的梯度缓存清零，然后进行随机梯度的的反向传播：\nnet.zero_grad() out.backward(torch.randn(1, 10))  Note\n  torch.nn 只支持小批量输入。整个 torch.nn 包都只支持小批量样本，而不支持单个样本。\n  例如，nn.Conv2d 接受一个4维的张量，\n  每一维分别是sSamples * nChannels * Height * Width（样本数*通道数*高*宽）。\n  如果你有单个样本，只需使用 input.unsqueeze(0) 来添加其它的维数\n 损失函数 损失函数接受一对 (output, target) 作为输入来计算一个值以估计网络的输出和目标值相差多少。\n output为网络的输出，target为实际值\n nn包中有很多不同的损失函数。\nnn.MSELoss是一个比较简单的损失函数，它计算输出和目标间的均方误差:\noutput = net(input) target = torch.randn(10) # 随机值作为样例 target = target.view(1, -1) # 使target和output的shape相同 criterion = nn.MSELoss() loss = criterion(output, target) print(loss) # Output: # tensor(1.1103, grad_fn=\u0026lt;MseLossBackward\u0026gt;) 现在，如果在反向过程中跟随loss ， 使用它的 .grad_fn 属性，将看到如下所示的计算图。\ninput -\u0026gt; conv2d -\u0026gt; relu -\u0026gt; maxpool2d -\u0026gt; conv2d -\u0026gt; relu -\u0026gt; maxpool2d -\u0026gt; view -\u0026gt; linear -\u0026gt; relu -\u0026gt; linear -\u0026gt; relu -\u0026gt; linear -\u0026gt; MSELoss -\u0026gt; loss 所以，当我们调用 loss.backward()时,整张计算图都会根据loss进行微分，而且图中所有设置为requires_grad=True的张量将会拥有一个随着梯度累积的.grad张量。\n为了说明，让我们向后退几步:\nprint(loss.grad_fn) # MSELoss print(loss.grad_fn.next_functions[0][0]) # Linear print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU # Output: # \u0026lt;MseLossBackward object at 0x0000021C605F3B08\u0026gt; # \u0026lt;AddmmBackward object at 0x0000021C605F3208\u0026gt; # \u0026lt;AccumulateGrad object at 0x0000021C605F3B08\u0026gt; 反向传播 调用loss.backward()获得反向传播的误差。\n但是在调用前需要清除已存在的梯度，否则梯度将被累加到已存在的梯度。\n现在，我们将调用loss.backward()，并查看conv1层的偏差（bias）项在反向传播前后的梯度。\nnet.zero_grad() # 清除梯度 print(\u0026#39;conv1.bias.grad before backward\u0026#39;) print(net.conv1.bias.grad) loss.backward() print(\u0026#39;conv1.bias.grad after backward\u0026#39;) print(net.conv1.bias.grad) \u0026#39;\u0026#39;\u0026#39; Output: conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([ 0.0242, 0.0145, -0.0015, 0.0144, 0.0084, 0.0309]) \u0026#39;\u0026#39;\u0026#39; 更新权重 在实践中最简单的权重更新规则是随机梯度下降（SGD）：\n ``weight = weight - learning_rate * gradient``  我们可以使用简单的Python代码实现这个规则：\nlearning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) 但是当使用神经网络是想要使用各种不同的更新规则时，比如SGD、Nesterov-SGD、Adam、RMSPROP等，PyTorch中构建了一个包torch.optim实现了所有的这些规则：\nimport torch.optim as optim # 创建优化器 optimizer = optim.SGD(net.parameters(), lr=0.01) # learning rate设为0.01 # 在训练循环中 optimizer.zero_grad() # zero the gradient buffers output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() # Does the update ","date":"2020-02-12T11:13:23+08:00","permalink":"https://konosuba.xyz/blog/pytorch_3/","title":"Pytorch学习笔记_3_构建一个神经网络"},{"content":"Autograd 自动求导机制 PyTorch 中所有神经网络的核心是 autograd 包。\nautograd 包为张量上的所有操作提供了自动求导。它是一个在运行时定义的框架，可以通过代码的运行来决定反向传播的过程，并且每次迭代可以是不同的。\n通过一些示例来了解\nTensor 张量 torch.tensor是这个包的核心类。\n 设置.requires_grad为True，会追踪所有对于该张量的操作。计算完成后调用.backward()，可以自动计算所有的梯度，并自动累计到.grad属性中   事实上即使.requires_grad为True并不意味着.grad一定不为None\n   可以调用.detach()将该张量与计算历史记录分离，并禁止跟踪它将来的计算记录\n  为防止跟踪历史记录（和使用内存），可以将代码块包装在with torch.no_grad(): 中。这在评估模型时特别有用，因为模型可能具有requires_grad = True的可训练参数，但是我们不需要梯度计算。\n  Function类 Tensor 和 Function 互相连接并生成一个非循环图，它表示和存储了完整的计算历史。\n每个张量都有一个.grad_fn属性，对张量进行操作后，grad_fn会引用一个创建了这个Tensor类的Function对象（除非这个张量是用户手动创建的，此时，这个张量的 grad_fn 是 None）\n leaf Tensors 叶张量\n  Tensor中有一属性is_leaf，当它为True有两种情况：\n   按照惯例，requires_grad = False 的 Tensor    requires_grad = True 且由用户创建的 Tensor。这意味着它们不是操作的结果且grad_fn = None    只有leaf Tensors叶张量在反向传播时才会将本身的grad传入backward()的运算中。要想得到non-leaf Tensors非叶张量在反向传播时的grad，可以使用retain_grad()\n 如果需要计算导数，可以在Tensor上调用.backward()：若Tensor是一个标量（即包含一个元素数据）则不需要为backward()指定任何参数， 但是如果它有更多的元素，需要指定一个gradient 参数来匹配张量的形状。\nx = torch.ones(2, 2, requires_grad=True) print(x) # Output: # tensor([[1., 1.], # [1., 1.]], requires_grad=True) y = x + 2 print(y) # Output: # tensor([[3., 3.], # [3., 3.]], grad_fn=\u0026lt;AddBackward0\u0026gt;) 此时，y已经被计算出来，grad_fn已经自动生成了\n\u0026gt;\u0026gt;\u0026gt; print(y.grad_fn) \u0026lt;AddBackward0 object at 0x0000013D6C2AB848\u0026gt; 对y进行操作\nz = y * y * 3 out = z.mean() print(z, out) # Output: # tensor([[27., 27.], # [27., 27.]], grad_fn=\u0026lt;MulBackward0\u0026gt;) # tensor(27., grad_fn=\u0026lt;MeanBackward0\u0026gt;) .requires_grad_( ... ) 可以改变现有张量的 requires_grad属性。 如果没有指定的话，默认输入的flag是 False\nGradients 梯度 现在开始反向传播\n因为out是一个标量，因此不需要为backward()指定任何参数：\nout.backward() print(x.grad) # Output: # tensor([[4.5000, 4.5000], # [4.5000, 4.5000]]) 现在让我们来看一个vector-Jacobian product的例子\nx = torch.randn(3, requires_grad=True) y = x * 2 while y.data.norm() \u0026lt; 1000: y = y * 2 print(y) # Output: # tensor([ 293.4463, 50.6356, 1031.2501], grad_fn=\u0026lt;MulBackward0\u0026gt;)  此处y.data.norm()指y的范数，即(y_1^2 + \u0026hellip; + y_n^2)^(1/2)\n 在这个情形中，y不再是个标量。torch.autograd无法直接计算出完整的雅可比行列，但是如果我们只想要vector-Jacobian product，只需将向量作为参数传入backward：\nv = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float) y.backward(v) print(x.grad) # Output: # tensor([5.1200e+01, 5.1200e+02, 5.1200e-02]) 如果.requires_grad=True但是你又不希望进行autograd的计算， 那么可以将变量包裹在 with torch.no_grad()中:\nprint(x.requires_grad) # True print((x ** 2).requires_grad) # True with torch.no_grad(): print((x ** 2).requires_grad) # False Autograd 过程 推导 grad_fn中有一属性next_functions，例如\nx = torch.rand(5, 5, requires_grad=True) y = torch.rand(5, 5, requires_grad=True) z = x**2 + y**3 print(z.grad_fn) # \u0026lt;AddBackward0 at 0x1426dca72c8\u0026gt; print(z.grad_fn.next_functions) # ((\u0026lt;PowBackward0 at 0x1426dc923c8\u0026gt;, 0), (\u0026lt;PowBackward0 at 0x1426dc92b48\u0026gt;, 0)) 此处的next_functions是一个“tuple of tuple of PowBackward0 and int”\n内层第一个tuple就是x相关的操作记录，继续深入\nxg = z.grad_fn.next_functions[0][0] x_leaf = xg.next_functions[0][0] print(type(x_leaf)) # AccumulateGrad 在Pytorch的反向图计算中，AccumulateGrad类型代表的就是叶子节点类型，也就是计算图的终止节点。\nAccumulateGrad中有一个.variable指向叶子节点\nx_leaf.variable 这个.variable的属性就是我们的生成的变量x\n流程  当我们执行z.backward()时。这个操作将调用z里面的grad_fn属性，执行求导操作。 这个操作将遍历grad_fn的next_functions，然后分别取出里面的Function(AccumulateGrad)，执行求导操作。这部分是一个递归的过程直到最后类型为叶子节点。 计算出结果以后，将结果保存到他们对应的variable 变量所引用的对象（x和y）的grad属性中 求导结束。所有的叶节点的grad变量都得到了相应的更新  最终当我们执行完c.backward()之后，a和b里面的grad值就得到了更新。\n拓展Autograd 如果需要自定义autograd扩展新的功能，就需要扩展Function类。因为Function使用autograd来计算结果和梯度，并对操作历史进行编码。\n在Function类中最主要的方法就是forward()和backward()他们分别代表了前向传播和反向传播。\n一个自定义的Function需要一下三个方法：\n  __init__ (optional)：如果这个操作需要额外的参数则需要定义这个Function的构造函数，不需要的话可以忽略。\n  forward()：执行前向传播的计算代码\n  backward()：反向传播时梯度计算的代码。 参数的个数和forward返回值的个数一样，每个参数代表传回到此操作的梯度。\n  ","date":"2020-02-11T17:25:19+08:00","permalink":"https://konosuba.xyz/blog/pytorch_2/","title":"Pytorch学习笔记_2_Autograd自动求导机制"},{"content":"Tensors Tensors与Numpy中的ndarrays类似\ntorch.new_* 与 torch.*_like 前者创建的对象会保持原有的属性（如dtype），但shape不同\n\u0026gt;\u0026gt;\u0026gt; x = torch.zeros(5, 3, dtype=torch.double) \u0026gt;\u0026gt;\u0026gt; x.new_ones(2, 3) tensor([[1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) \u0026gt;\u0026gt;\u0026gt; x.new_ones(2, 3, dtype=torch.long) tensor([[1, 1, 1], [1, 1, 1]]) 后者可以创建shape相同，属性不同的对象\n\u0026gt;\u0026gt;\u0026gt; x = torch.zeros(5, 3, dtype=torch.double) \u0026gt;\u0026gt;\u0026gt; torch.ones_like(x) tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) \u0026gt;\u0026gt;\u0026gt; torch.ones_like(x, dtype=torch.long) tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]) 获得size 使用size方法与Numpy的shape属性返回的相同，张量也支持shape属性\n\u0026gt;\u0026gt;\u0026gt; x = torch.zeros(5, 3, dtype=torch.double) \u0026gt;\u0026gt;\u0026gt; x.size() torch.Size([5, 3]) torch.Size实际上是一个tuple元组，因此它支持所有元组操作。\n操作 加法 有多种操作方式：\n x + y torch.add(x, y) 提供输出tensor作为参数  result = torch.empty(5, 3) torch.add(x, y, out=result) y.add_(x) 将x加到y中   任何 以 _ 结尾的操作都会用结果替换原变量. 例如: x.copy_(y), x.t_(), 都会改变 x.\n 索引 可以使用与NumPy索引方式相同的操作来进行对张量的操作，如x[:, 1]得到x的第1列\ntorch.view 可以改变张量的维度和大小，与Numpy的reshape类似\nx = torch.randn(4, 4) y = x.view(16) z = x.view(-1, 8) # size -1 从其他维度推断 print(x.size(), y.size(), z.size()) # Output: # torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) .item() 如果你有只有一个元素的张量，使用.item()来得到Python数据类型的数值\nx = torch.randn(1) print(x) print(x.item()) # Output: # tensor([-0.2368]) # -0.23680149018764496 NumPy转换 Torch Tensor与NumPy数组共享底层内存地址，修改一个会导致另一个的变化。\nTensor -\u0026gt; NumPy a = torch.ones(5) b = a.numpy() print(b) # [1. 1. 1. 1. 1.] a.add_(1) print(a) # tensor([2., 2., 2., 2., 2.]) print(b) # [2., 2., 2., 2., 2.] NumPy -\u0026gt; Tensor a = np.ones(5) b = torch.from_numpy(a) np.add(a, 1, out=a) print(a) # [2. 2. 2. 2. 2.] print(b) # tensor([2., 2., 2., 2., 2.], dtype=torch.float64) 所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换.\nCUDA 张量 使用.to 方法 可以将Tensor移动到任何设备中\n# is_available 函数判断是否有cuda可以使用 # ``torch.device``将张量移动到指定的设备中 if torch.cuda.is_available(): device = torch.device(\u0026#34;cuda\u0026#34;) # a CUDA 设备对象 y = torch.ones_like(x, device=device) # 直接从GPU创建张量 x = x.to(device) # 或者直接使用``.to(\u0026#34;cuda\u0026#34;)``将张量移动到cuda中 z = x + y print(z) print(z.to(\u0026#34;cpu\u0026#34;, torch.double)) # ``.to`` 也会对变量的类型做更改 ","date":"2020-02-11T14:46:14+08:00","permalink":"https://konosuba.xyz/blog/pytorch_1/","title":"Pytorch学习笔记_1_tensor张量"},{"content":"学习曲线：样本数量与误差 绘制 样本数量m 与 训练误差、交叉验证误差 的关系曲线\n高偏差（欠拟合）high bias 高方差（过拟合）high variance ","date":"2020-02-07T01:04:44+08:00","permalink":"https://konosuba.xyz/blog/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/","title":"神经网络模型的学习曲线"},{"content":"在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。\n但是我们可能会正则化的程度太高或太小了，即我们在选择λ的值时也需要思考与之前选择多项式模型次数类似的问题。\n我们选择一系列的想要测试的λ值，比如这里选择 0-10之间的值，通常呈现2倍关系（如：0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10 共12个）。\n我们同样把数据分为训练集、交叉验证集和测试集。\n选择λ的方法   使用训练集训练出12个不同程度正则化的模型\n  用12个模型分别对交叉验证集计算的出交叉验证误差\n  选择得出交叉验证误差最小的模型\n  运用步骤3中选出模型对测试集计算得出推广误差\n  我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：\n 当λ较小时，训练集误差较小（过拟合）而交叉验证集误差较大\n  随着λ的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加\n ","date":"2020-02-07T00:56:29+08:00","permalink":"https://konosuba.xyz/blog/%E6%AD%A3%E5%88%99%E5%8C%96%E4%B8%8E%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE/","title":"【应用机器学习】正则化与偏差、方差"},{"content":"当你运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。\n我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：\n  对于训练集，当 d 较小时，模型拟合程度更低，误差较大；随着d 的增长，拟合程度提高，误差减小。\n  对于交叉验证集，当 d 较小时，模型拟合程度低，误差较大；但是随着 d 的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。\n  判断高偏差（欠拟合）或高方差（过拟合）   训练集误差和交叉验证集误差近似时：偏差/欠拟合\n  交叉验证集误差远大于训练集误差时：方差/过拟合\n  解决欠拟合与过拟合 欠拟合：\n 增加网络结构，如增加隐藏层数目； 训练更长时间； 寻找合适的网络架构，使用更大的NN结构；  过拟合 ：\n 使用更多的数据； 正则化（ regularization）； 寻找合适的网络结构；  ","date":"2020-02-07T00:51:21+08:00","permalink":"https://konosuba.xyz/blog/%E8%AF%8A%E6%96%AD%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/","title":"【应用机器学习】诊断偏差与方差"},{"content":"1. 重新划分数据集 其中60%作为训练集，20%作为交叉验证集（cross validation），20%作为测试集\n2. 可以计算出三类数据的误差函数 3. 使用交叉验证集选择模型 选出交叉验证误差最小的一个模型\n4. 利用测试集计算出推广误差 ","date":"2020-02-07T00:41:34+08:00","permalink":"https://konosuba.xyz/blog/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/","title":"【应用机器学习】模型选择和训练、验证、测试集"},{"content":"检验是否过拟合 将数据分成训练集和测试集 通常用70%的数据作为训练集，用剩下30%的数据作为测试集。\n很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行洗牌，然后再分成训练集和测试集。\n使用训练集对模型进行训练 可以得到一系列参数 theta\n使用测试集对模型进行测试 使用测试集数据对模型进行测试，有两种方式计算误差\n线性回归模型 利用测试集数据计算代价函数J\n逻辑回归模型 除前述方法，还可使用一种 错误分类(misclassification error)(也称0/1错误分类 zero one misclassification error) 的方法\n","date":"2020-02-07T00:34:04+08:00","permalink":"https://konosuba.xyz/blog/%E8%AF%84%E4%BC%B0%E4%B8%80%E4%B8%AA%E5%81%87%E8%AE%BE/","title":"【应用机器学习】评估一个假设"},{"content":"1. 选择一种网络结构 即选择神经元之间的连通模式\n  输入层与输出层单元个数由具体特征决定\n  隐藏层通常默认为1层；若为多层，则每个隐藏层单元个数应相等。通常隐藏层单元数越多越好\n  隐藏层单元数应与输入特征数相匹配\n  2. 随机初始化权重 通常把权重值初始化为接近0的很小的数\n3. 执行前向传播FP算法 获得对应于每一个 xi 的 h_theta(xi)​\n4. 通过代码计算出代价函数 J(theta) 5. 执行反向传播算法 获得 J(theta) 对于 theta 的偏导​，即\n 步骤 3-5\n   6. 进行梯度检查   比较 通过反向传播得到的偏导数 与 通过数值计算得到的估计值\n  确保两种方法得到基本接近的两个值​\n  注意在检查完毕后关闭梯度检查\n  7. 利用最优化算法与反向传播算法最小化 J(theta) 比如，使用最小梯度法\n","date":"2020-02-07T00:09:57+08:00","permalink":"https://konosuba.xyz/blog/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4/","title":"训练神经网络的基本步骤"},{"content":"过拟合的问题 到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到**过拟合(over-fitting)**的问题，可能会导致它们效果很差。\n可以使用一种**正则化(regularization)**的技术来改善或减少过度拟合的问题\n在回归问题中   第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；\n  第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：\n  当我们用第三个模型预测新数据，可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎是最合适的。\n在分类问题中 就以多项式理解， x的次数越高，拟合的越好，但相应的预测的能力就可能变差。\n处理过拟合问题\n 丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA） 正则化。 保留所有的特征，但是减少参数的大小（magnitude）  代价函数 我们从之前的事例可以看出，正是那些高次项导致了过拟合的产生，所以我们可以通过让这些高次项的系数接近于0，我们就能很好的拟合。\n所以正则化的基本方法就是在一定程度上减小高次项系数即参数theta的值\n即在设定代价函数时，为高次项的系数设置一些惩罚，通过这样代价函数选择出的theta对预测结果的影响就比之前要小许多。\n但如果我们不知道要对哪一个参数进行惩罚，我们可以对所以特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。于是得到了一个较为简单的能防止过拟合问题的假设\n其中λ称为正则化参数（Regularization Parameter）。注：根据惯例，我们不对theta0进行惩罚。\n经过正则化处理的模型与原模型的可能对比如图：\n如果选择的正则化参数λ过大，则会把所有的参数都最小化了，导致模型变成 h(x) = theta0 ，也就是上图中红色直线所示的情况，造成欠拟合。\n对于正则化，我们要取一个合理的λ的值，这样才能更好的应用正则化。 回顾一下代价函数，为了使用正则化，让我们把这些概念应用到到线性回归和逻辑回归中去，那么我们就可以让他们避免过度拟合了。\n正则化线性回归 正则化线性回归的代价函数为：\n如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对theta0进行正则化，所以梯度下降算法将分两种情形：\n分类 L1正则化（Lasso回归） 损失函数基础上加上权重参数的绝对值\nL2正则化（岭回归） 损失函数基础上加上权重参数的平方和\n需要说明的是：L1 相比于 L2 会更容易获得稀疏解\nWHY-\u0026gt;Click\n","date":"2020-01-13T17:29:56+08:00","permalink":"https://konosuba.xyz/blog/%E6%AD%A3%E5%88%99%E5%8C%96/","title":"正则化 Regularization"},{"content":"分类问题 在分类问题中，我们需要预测的变量y是离散的值，我们将学习一种叫做逻辑回归 (Logistic Regression) 的算法\n在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。\n将因变量(dependent variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量y ∈ 0,1 ，其中 0 表示负向类，1 表示正向类。\n如果我们要用线性回归算法来解决一个分类问题，对于分类，y取值为 0 或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于 1，或者远小于0，即使所有训练样本的标签y都等于 0 或 1。尽管我们知道标签应该取值0 或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。\n所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到 1 之间\n逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上真的是一种分类算法\n假说表示 我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0和1之间。\n逻辑回归模型的假设是：h_theta(x) = g(theta'X) 其中:X代表特征向量，g代表逻辑函数（logistic function)是一个常用的S形函数（Sigmoid function），公式为：g(z) = 1 / (1 + exp(-z)\nPython代码实现\nimport numpy as np def sigmoid(z): return 1 / (1 + np.exp(-z)) 该函数图像为\n合起来，我们得到逻辑回归模型的假设：\n对模型的理解：g(z) = 1 / (1 + exp(-z)\nh_theta(x)的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性（estimated probablity）即h_theta(x) = P(y=1 | x;theta)\n例如，如果对于给定的x，通过已经确定的参数计算得出h_theta(x) = 0.7，则表示有70%的几率为正向类，相应地为负向类的几率为1-0.7=0.3。\n判定边界 决策边界(decision boundary)这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么。\n逻辑回归中，我们预测：\n 当h(x) \u0026gt;= 0.5时，预测y = 1 当h(x) \u0026lt; 0.5时，预测y = 0  根据上面绘制出的S形函数图像，我们知道当\n z = 0时g(z) = 0.5 z \u0026gt; 0时g(z) \u0026gt; 0.5 z \u0026lt; 0时g(z) \u0026lt; 0.5  又 z = theta'x，即：theta'x \u0026gt;= 0时，预测y = 1；theta'x \u0026lt; 0时，预测y =0\n现在假设我们有一个模型：\n并且参数theta是向量[-3 1 1]，则当-3+x1+x2\u0026gt;-0，即x1+x2\u0026gt;=3时，模型将预测y = 1。我们可以绘制直线x1 + x2 = 3，这条线时我们模型的分界线，将预测为1的区域和预测为0的区域分隔开\n假使我们的数据呈现这样的分布情况，怎样的模型才能适合呢？\n因为需要用曲线才能分隔y = 0的区域和y = 1的区域，我们需要二次方特征：\nh_theta(x) = g(theta0 + theta1x1 + theta2x2 + theta3x1^2 + theta4x2^2)\n则我们得到的判定边界恰好是圆点在原点且半径为1的圆形。\n我们可以用非常复杂的模型来适应非常复杂形状的判定边界。\n代价函数 我们要介绍如何拟合逻辑回归模型的参数theta。具体来说，要定义用来拟合参数的优化目标或者叫代价函数，这便是监督学习问题中的逻辑回归模型的拟合问题。\n对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将h_theta(x)带入到这样定义了的代价函数中时，我们得到的代价函数将是一个非凸函数（non-convexfunction）（左图）。\n这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。\n在线性回归中，代价函数为\n重新定义逻辑回归的代价函数为\nh(x)与Cost(h(x), y)之间的关系如图所示\n这样构建的函数的特点是：\n 当实际的y=1且h(x)也为 1 时误差为 0 当y=1但h(x)不为1时误差随着h(x)变小而变大； 当实际的y=0且h(x)也为 0 时代价为 0 当y=0但h(x)不为 0 时误差随着h(x)的变大而变大。  将构建的Cost(h(x), y)简化如下\nCost(h(x),y) = -y*log(h(x)) - (1-y)*log(1-h(x))\n带入代价函数得\nPython实现\nimport numpy as np def cost(theta, X, y): theta = np.matrix(theta) X = np.matrix(X) y = np.matrix(y) first = np.multiply(-y, np.log(sigmoid(X* theta.T))) second = np.multiply((1 - y), np.log(1 - sigmoid(X* theta.T))) return np.sum(first - second) / (len(X)) 在得到这样一个代价函数以后，我们便可以用梯度下降算法来求得能使代价函数最小的参数了。算法为：\n我们定义了单训练样本的代价函数，凸性分析的内容是超出这门课的范围的，但是可以证明我们所选的代价值函数会给我们一个凸优化问题。代价函数J(theta)会是一个凸函数，并且没有局部最优值。\n 推导过程如下:\n    注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的h_theta(x) = g(theta'X)与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。\n 一些梯度下降算法之外的选择： 除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：共轭梯度（Conjugate Gradient），局部优化法(Broyden fletcher goldfarb shann,BFGS)和有限内存局部优化法(LBFGS)，fminunc是 matlab中的一个最小值优化函数，使用时我们需要提供代价函数和每个参数的求导，下面是 matlab 中使用 fminunc 函数的代码示例：\nfunction[jVal, gradient] =costFunction(theta)​ jVal = [...code to compute J(theta)...]; gradient = [...code to compute derivative of J(theta)...]; end options = optimset(\u0026#39;GradObj\u0026#39;, \u0026#39;on\u0026#39;, \u0026#39;MaxIter\u0026#39;, \u0026#39;100\u0026#39;); initialTheta = zeros(2,1); [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options); 简化的成本函数和梯度下降 我们将会找出一种稍微简单一点的方法来写代价函数，来替换我们现在用的方法。同时我们还要弄清楚如何运用梯度下降法，来拟合出逻辑回归的参数。\n根据这个代价函数，为了拟合出参数，我们需要找到能使J(theta)尽量小的参数theta，\n如果我们给出一个新的样本，假如某个特征x，我们可以用拟合训练样本的参数theta，来输出对假设的预测。们假设的输出，实际上就是这个概率值：p(y = 1|x;theta)，即关于x以theta为参数，y=1的概率，可以认为我们的假设就是估计y=1的概率\n最小化代价函数的方法，是使用梯度下降法(gradient descent)。这是我们的代价函数：\n如果我们要最小化这个关于theta的函数值，这就是我们通常用的梯度下降法的模板。\n我们要反复更新每个参数，用这个式子来更新，就是用它自己减去学习率alpha乘以后面的微分项。求导后得到：\n如果我们有n个特征，也就是theta = [theta0, theta1, theta2 ... thetan]'，参数向量theta包括theta0一直到theta n，那么我们旧需要用这个实在来同时更新所有theta值\n我们之前在谈线性回归时讲到的特征缩放，我们看到了特征缩放是如何提高梯度下降的收敛速度的，这个特征缩放的方法，也适用于逻辑回归。如果你的特征范围差距很大的话，那么应用特征缩放的方法，同样也可以让逻辑回归中，梯度下降收敛更快。\n高级优化 这一节，我们学习一些高级优化算法和一些高级的优化概念，利用这些方法，我们就能够使通过梯度下降，进行逻辑回归的速度大大提高，而这也将使算法更加适合解决大型的机器学习问题\n比如共轭梯度法，BFGS (变尺度法) 和 L-BFGS (限制变尺度法)\n如何使用这些算法：\n假如我们有一个含两个参数得问题，这两个参数是theta0和theta1，通过这个代价函数，我们可以得到theta0和theta1的值，如果我们不知道J(theta)的最小值，可以使用这样一个MATLAB函数\nfunction[jVal, gradient]=costFunction(theta)jVal=(theta(1)-5)^2+(theta(2)-5)^2; gradient=zeros(2,1); gradient(1)=2*(theta(1)-5); gradient(2)=2*(theta(2)-5); end 这样就计算出这个代价函数，函数返回的第二个值是梯度值，梯度值应该是一个2×1的向量，梯度向量的两个元素对应这里的两个偏导数项，运行这个costFunction 函数后，你就可以调用高级的优化函数，这个函数叫 fminunc，它表示 MATLAB 里无约束最小化函数。调用它的方式如下：\noptions=optimset(\u0026#39;GradObj\u0026#39;,\u0026#39;on\u0026#39;,\u0026#39;MaxIter\u0026#39;,100); ​ initialTheta=zeros(2,1); [optTheta, functionVal, exitFlag]=fminunc(@costFunction, initialTheta, options); 要设置几个options，这个 options 变量作为一个数据结构可以存储你想要的options，所以 GradObj 和On，这里设置梯度目标参数为打开(on)，这意味着你现在确实要给这个算法提供一个梯度，然后设置最大迭代次数，比方说100，我们给出一个theta的猜测初始值，它是一个2×1的向量，那么这个命令就调用fminunc，这个@符号表示指向我们刚刚定义的costFunction 函数的指针。如果你调用它，它就会使用众多高级优化算法中的一个，当然你也可以把它当成梯度下降，只不过它能自动选择学习速率alpha，你不需要自己来做。然后它会尝试使用这些高级的优化算法，就像加强版的梯度下降法，为你找到最佳的theta值。\n这个关于theta的 costFunction 函数，它计算出代价函数 jval 以及梯度 gradient，gradient 有两个元素，是代价函数对于 theta(1) 和 theta(2)这两个参数的偏导数。\n多类别分类：一对多 对于一个二元分类问题，我们的数据看起来可能是像这样\n对于一个多类分类问题，我们的数据集或许看起来像这样：\n我们现在已经知道如何进行二元分类，可以使用逻辑回归，对于直线或许你也知道，可以将数据集一分为二为正类和负类。用一对多的分类思想，我们可以将其用在多类分类问题上。\n下面将介绍如何进行一对多的分类工作，有时这个方法也被称为\u0026quot;一对余\u0026quot;方法。\n现在我们有一个训练集，好比上图表示的有3个类别，我们用三角形表示 y=1 ，方框表示 y=2，叉叉表示 y=3。我们下面要做的就是使用一个训练集，将其分成3个二元分类问题。\n我们创建一个新的训练集，如下图所示的那样，我们要拟合出一个合适的分类器。\n这里的三角形是正样本，而圆形代表负样本。可以这样想，设置三角形的值为1，圆形的值为0，下面我们来训练一个标准的逻辑回归分类器，这样我们就得到一个正边界。\n为了能实现这样的转变，我们将多个类中的一个类标记为正向类(y=1)，然后将其他所有类都标记为负向类，这个模型记作h1(x)。接着，类似地第我们选择另一个类标记为正向类(y=2)，再将其它类都标记为负向类，将这个模型记作h2(x),依此类推。 最后我们得到一系列的模型简记为：hi(x) = p(y=i|x;theta) 其中：i = (1, 2, 3... k)\n最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。\n我们要做的就是在我们三个分类器里面输入x，然后我们选择一个让hi(x)最大的i\n选择出哪一个分类器是可信度最高效果最好的，那么就可认为得到一个正确的分类，无论i值是多少，我们都有最高的概率值，我们预测y就是那个值。这就是多类别分类问题，以及一对多的方法，通过这个小方法，你现在也可以将逻辑回归分类器用在多类分类的问题上。\n  转自ai-start.com/ml2014/html/week3\n ","date":"2020-01-13T16:07:34+08:00","permalink":"https://konosuba.xyz/blog/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/","title":"逻辑回归Logistic Regression"},{"content":"Java 开发环境配置 首先我们需要下载java开发工具包JDK，下载地址\n下载对应版本\n之后安装一路下一步即可\n安装成功后配置环境变量\n参照这个即可\n配置完成后，在cmd输入java -version、java、javac，没有报错，则配置成功\n基础语法 Java是一门面向对象的语言，因此它就有类与对象、方法、实例变量\n 对象：对象是类的一个实例，有状态和行为。例如，一条狗是一个对象，它的状态有：颜色、名字、品种；行为有：摇尾巴、叫、吃等。 类：类是一个模板，它描述一类对象的行为和状态。 方法：方法就是行为，一个类可以有很多方法。逻辑运算、数据修改以及所有动作都是在方法中完成的。 实例变量：每个对象都有独特的实例变量，对象的状态由这些实例变量的值决定。  基本语法  大小写敏感 类名首字母大写，\u0026ldquo;驼峰式\u0026quot;命名 源文件名必须与类名相同 所有的 Java 程序由 public static void main(String []args) 方法开始执行  Hello World public class HelloWorld { public static void main(String []args) { System.out.println(\u0026#34;Hello World\u0026#34;); //自动换行  } } 标识符  所有的标识符都应该以字母（A-Z 或者 a-z）,美元符（$）、或者下划线（_）开始 非法标识符举例：123abc、-salary  变量 主要有以下几种变量\n 局部变量 类变量（静态变量） 成员变量（非静态变量）  常量 定义变量的时候，如果加上final修饰符，这个变量就变成了常量\n常量在定义时进行初始化后就不可再次赋值，再次赋值会导致编译错误。\nJava 源程序与编译型运行区别 ","date":"2020-01-12T21:00:17+08:00","permalink":"https://konosuba.xyz/blog/java%E5%85%A5%E9%97%A8/","title":"Java入门"},{"content":"自定义函数 MATLAB可以在单独的.m文件中定义函数\n比如有一文件myadd.m，文件中内容为\nfunctiony =myadd(a, b)% 这里可以写函数的使用说明，前面以%开头 % 在工作区中，help myadd将显示此处的说明 y = a + b; end %可以略去 第一行function y = myadd(a, b) 告诉 MATLAB，这个函数将返回一个值，并且返回的这个值将被存放于变量y里。\n另外，还可以得知这个函数有两个参数a和b，以及定义的函数体，即 y = a + b\n myadd是函数名。以m文件定义的函数必须保存为函数名的形式\n  要使用 myadd函数，该函数必须在 Matlab 的搜索路径中。\n 调用方式 只需在MATLAB中直接使用函数名调用，MATLAB会自动在其搜索路径中找到对应.m文件，例如\n\u0026gt;\u0026gt; c = myadd(1, 2) c = 3 MORE MATLAB中允许定义的函数返回值是多个值或多个参数，只需在定义函数时写为\n[y1, y2...] = function_name(x1, x2...)\n","date":"2020-01-11T15:35:44+08:00","permalink":"https://konosuba.xyz/blog/matlab%E5%87%BD%E6%95%B0/","title":"MATLAB学习_函数"},{"content":"for循环 首先我们定义一个向量v = zeros(10, 1)\n接着我们写一个 “for\u0026quot; 循环，让v等于 1 到 10。设v(i)等于 2 的i次方，循环最后写上“end”。\n\u0026gt;\u0026gt; for i = 1:10 v(i) = 2^i; end \u0026gt;\u0026gt; v v = 2 4 8 16 32 64 128 256 512 1024 同样也可以使用break，continue语句\nwhile \u0026gt;\u0026gt; i = 1 \u0026gt;\u0026gt; while true, v(i) = 999; i = i+1; if i == 6, break; end; end; \u0026gt;\u0026gt; i i = 6 if-else \u0026gt;\u0026gt; if i == 5, disp(\u0026#34;hello\u0026#34;); elseif i == 4, disp(\u0026#34;world\u0026#34;); else disp(\u0026#34;hello, world\u0026#34;); end; hello, world \u0026gt;\u0026gt; ","date":"2020-01-11T15:02:35+08:00","permalink":"https://konosuba.xyz/blog/matlab%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5/","title":"MATLAB学习_控制语句:for,while,if"},{"content":"当开发学习算法时，往往几个简单的图，可以让你更好地理解算法的内容，并且可以完整地检查下算法是否正常运行，是否达到了算法的目的。\n二维绘图 我们先来快速生成一些数据用来绘图。\n\u0026gt;\u0026gt; t = [0:0.01:0.98]; \u0026gt;\u0026gt; y1 = sin(2*pi*4*t); 如果我们想要绘制正弦函数，只需输入plot(t, y1)，如图\n横轴是变量t，纵轴是y1，也就是我们刚刚所输出的正弦函数。\n让我们设置y2\n\u0026gt;\u0026gt; y2 = cos(2*pi*4*t); \u0026gt;\u0026gt; plot(t, y2) 如果要同时表示正弦和余弦曲线。\n我们要做的就是，输入：plot(t, y1)，得到正弦函数，之后使用函数hold on，它的功能是将新的图像绘制在旧的之上\n再输入：plot(t, y2)，MATLAB会自动用不同颜色绘制新的曲线，我们也可以指定颜色，比如plot(t, y2, 'r')，r表示使用红色绘制y2\n \u0026lsquo;r\u0026rsquo; 为线条设定。每个设定可包含表示线条颜色、样式和标记的字符。标记是在绘制的每个数据点上显示的符号，例如，+、o 或 * ；\n  例如，\u0026lsquo;g:*\u0026rsquo; 请求绘制使用 * 标记的绿色点线。\u0026lsquo;r\u0026ndash;\u0026lsquo;请求红色虚线\n 还可以使用命令xlabel('time')标记X轴，输入ylabel('value')标记Y轴的值。\n同时我们也可以标记这两条函数曲线，用命令 legend('sin','cos')将这个图例放在右上方，表示这两条曲线表示的内容。最后输入title('myplot')，在图像的顶部显示这幅图的标题。\n使用close命令可以关掉图像\n 可以为图像标号\n   使用figure(1); plot(t, y1);将显示第一张图，绘制了y1-t     使用figure(2); plot(t, y2);将显示第一张图，绘制了y2-t   subplot命令，我们使用subplot(1,2,1)，它将图像分为一个1*2的格子，也就是前两个参数，然后它使用第一个格子，也就是最后一个参数1的意思。\n之后键入plot(t, y1)，y1-t图显示在第一个格子；\n使用subplot(1, 2, 2); plot(t, y2)，y2-t图显示在第二个格子\n还有一个命令，可以改变轴的刻度，比如改成[0.5 1 -1 1]，输入命令：axis([0.5 1 -1 1])也就是设置了右边图的轴和轴的范围。具体而言，它将右图中的横轴的范围调整至0.5到1，竖轴的范围为-1到1。\nclf命令可以清除当前的Figure\nimagesc 首先我们设置A等于一个5×5的magic方阵：\n\u0026gt;\u0026gt; A = magic(5) A = 17 24 1 8 15 23 5 7 14 16 4 6 13 20 22 10 12 19 21 3 11 18 25 2 9 可以通过imagesc(A)来可视化矩阵，它将会绘制一个5 * 5的矩阵，一个5 * 5的彩色格图，不同的颜色对应A矩阵中的不同值\n还可以使用函数colorbar：使用一个更复杂的命令 imagesc(A),colorbar,colormap gray。这实际上是在同一时间运行三个命令：运行imagesc，然后运行colorbar，然后运行colormap gray。\n它生成了一个颜色图像，一个灰度分布图，并在右边也加入一个颜色条。所以这个颜色条显示不同深浅的颜色所对应的值。\n可以看到在不同的方格，它对应于一个不同的灰度。\n输入imagesc(magic(15)),colorbar,colormap gray，获得一幅15*15的magic方阵值图\n三维绘图 三维图通常显示一个由带两个变量的函数（即 z = f (x,y)）定义的曲面图。\n要计算 z，首先使用 meshgrid 在此函数的域中创建一组 (x,y) 点。\n\u0026gt;\u0026gt; [X,Y] = meshgrid(-2:.2:2); \u0026gt;\u0026gt; Z = X .* exp(-X.^2 - Y.^2);  meshgrid函数生成的X，Y是大小相等的矩阵\n 然后创建曲面图\nsurf(X, Y, Z)\nsurf 函数及其伴随函数 mesh 以三维形式显示曲面图。surf 使用颜色显示曲面图的连接线和面。mesh 生成仅以颜色标记连接定义点的线条的线框曲面图。\n","date":"2020-01-11T10:28:08+08:00","permalink":"https://konosuba.xyz/blog/matlab%E7%BB%98%E5%9B%BE/","title":"MATLAB学习_数据绘图"},{"content":"字符串 创建 t = \u0026#34;Hello, world\u0026#34;; 如果文本包含双引号，请在定义中使用两个双引号。\nq = \u0026#34;Something \u0026#34;\u0026#34;quoted\u0026#34;\u0026#34; and something else.\u0026#34; t 和 q 为数组。它们的数据类型是 string。\n\u0026gt;\u0026gt; whos t Name Size Bytes Class Attributes t 1x1 166 string  注意: 使用双引号创建字符串数组是在 R2017a 中引入的。\n 行末添加 使用+运算符\n\u0026gt;\u0026gt; t + \u0026#34;!\u0026#34; ans = \u0026#34;Hello, world!\u0026#34; 求长度 与数值数组类似，字符串数组可以有多个元素。\n\u0026gt;\u0026gt; A = [\u0026#34;a\u0026#34;,\u0026#34;bb\u0026#34;,\u0026#34;ccc\u0026#34;; \u0026#34;dddd\u0026#34;,\u0026#34;eeeeee\u0026#34;,\u0026#34;fffffff\u0026#34;] A = 2×3 string 数组 \u0026#34;a\u0026#34; \u0026#34;bb\u0026#34; \u0026#34;ccc\u0026#34; \u0026#34;dddd\u0026#34; \u0026#34;eeeeee\u0026#34; \u0026#34;fffffff\u0026#34; 使用 strlength 函数求数组中每个字符串的长度。\n\u0026gt;\u0026gt; strlength(A) ans = 1 2 3 4 6 7 字符 有时，字符表示的数据并不对应到文本，您可以将此类数据存储在数据类型为char 的字符数组中。字符数组使用单引号。\n\u0026gt;\u0026gt; seq = \u0026#39;ABCDEFG\u0026#39; seq = \u0026#39;ABCDEFG\u0026#39; \u0026gt;\u0026gt; whos seq Name Size Bytes Class Attributes seq 1x7 14 char 数组的每个元素都包含单个字符。\n\u0026gt;\u0026gt; seq(4) ans = \u0026#39;D\u0026#39; 使用方括号串联字符数组，就像串联数值数组一样。\n\u0026gt;\u0026gt; seq2 = [seq, \u0026#39;HIJKLMN\u0026#39;] seq2 = \u0026#39;ABCDEFGHIJKLMN\u0026#39; 接受 string 数据的所有 MATLAB 函数都能接受 char 数据，反之亦然\n","date":"2020-01-11T10:13:09+08:00","permalink":"https://konosuba.xyz/blog/matlab%E5%AD%97%E7%AC%A6%E4%B8%B2/","title":"MATLAB学习_字符与字符串"},{"content":"文件操作 导入文件 当我们打开 MATLAB 时，我们通常已经在一个默认路径中，这个路径是 MATLAB 的安装位置，使用 pwd 命令可以显示出 MATLAB 当前所处路径。\n使用cd命令，可以修改当前路径\n使用\u0026rsquo;ls\u0026rsquo;命令，可以列出当前路劲中所有文件\n要在MATLAB中导入数据文件，可以使用load命令，如：\n\u0026gt;\u0026gt; load myData.dat % 或load(\u0026#39;myData.dat\u0026#39;) 之后可以直接输入myData，MATLAB便会打印文件中的数据，此时该文件名便作为一个新变量名\n导出文件 退出 MATLAB 后，工作区变量不会保留。使用 save 命令保存数据以供将来使用，\nsave myfile.mat 通过保存，系统会使用 .mat 扩展名将工作区保存在当前工作文件夹中一个名为 MAT 文件的压缩文件中。\n变量操作 “工作区”中包含了在MATLAB创建或从数据文件或其他程序导入的变量\n例如先在工作区中创建变量A和B\nA = eye(3) B = rand(2, 3) 使用who可以查看当前工作区中所有变量\n\u0026gt;\u0026gt; who 您的变量为: A B 还有一个whos，能更详细的查看\n\u0026gt;\u0026gt; whos Name Size Bytes Class Attributes A 3x3 72 double B 2x3 48 double 此外，在GUI窗口中也能查看\n可以使用clear命令清除工作区中所有变量\n数据操作 此时矩阵 A = [1 2; 3 4; 5 6] 是一个 3×2 的矩阵\n我可以键入 A(2,:) 来返回第二行的所有元素，冒号表示该行或该列的所有元素。\nA([1 3],:)，这个命令意思是取A矩阵第一个索引值为1或3的元素，也就是说我取的是A矩阵的第一行和第三行的每一列，冒号表示的是取这两行的每一列元素，即：\n\u0026gt;\u0026gt; A([1 3],:) ans = 1 2 5 6 我可以取A矩阵的第二列，然后将它赋值为10 11 12，我实际上是取出了 的第二列，然后把一个列向量[10;11;12]赋给了它，因此现在A矩阵的第一列还是 1 3 5，第二列就被替换为 10 11 12。\n\u0026gt;\u0026gt; A(:,2) = [10;11;12] A = 1 10 3 11 5 12 还有一个小技巧，如果你就输入 A(:)，这是一个很特别的语法结构，意思是把A 中的所有元素放入一个单独的列向量，这样我们就得到了一个 9×1 的向量，这些元素都是A中的元素排列起来的。\n\u0026gt;\u0026gt; A(:) ans = 1 3 5 10 11 12 ","date":"2020-01-10T17:55:20+08:00","permalink":"https://konosuba.xyz/blog/matlab%E6%93%8D%E4%BD%9C/","title":"MATLAB学习_操作数据"},{"content":"矩阵与向量的创建在上一篇文章中已经提到，所以这里直接进行操作和运算\n运算 现有一矩阵a:\n\u0026gt;\u0026gt; a = [1 2 3; 4 5 6; 7 8 10] a = 1 2 3 4 5 6 7 8 10 矩阵与常数相加\n\u0026gt;\u0026gt; a + 10 ans = 11 12 13 14 15 16 17 18 20 \u0026gt;\u0026gt; sin(a) ans = 0.8415 0.9093 0.1411 -0.7568 -0.9589 -0.2794 0.6570 0.9894 -0.5440 转置矩阵 \u0026gt;\u0026gt;a\u0026#39; ans = 1 4 7 2 5 8 3 6 10 逆矩阵 \u0026gt;\u0026gt; inv(a) ans = -0.6667 -1.3333 1.0000 -0.6667 3.6667 -2.0000 1.0000 -2.0000 1.0000 标准矩阵乘法 \u0026gt;\u0026gt; p = a*inv(a) p = 1.0000 0 0 0.0000 1.0000 0 0.0000 -0.0000 1.0000 请注意，p 不是整数值矩阵。MATLAB 将数字存储为浮点值，算术运算可以区分实际值与其浮点表示之间的细微差别。使用 format 命令可以显示更多小数位数：\n\u0026gt;\u0026gt; format long \u0026gt;\u0026gt; p = a*inv(a) p = 1.000000000000000 0 0 0.000000000000002 1.000000000000000 0 0.000000000000002 -0.000000000000004 1.000000000000000 format 仅影响数字显示，而不影响 MATLAB 对数字的计算或保存方式。\n元素级乘法 使用.*运算符\n\u0026gt;\u0026gt; a .* 3 ans = 3 6 9 12 15 18 21 24 30 \u0026gt;\u0026gt; a .* a ans = 1 4 9 16 25 36 49 64 100 乘法、除法和幂的矩阵运算符分别具有执行元素级运算的对应数组运算符。例如，计算 a 的各个元素的三次方：\n\u0026gt;\u0026gt; a .^ 3 ans = 1 8 27 64 125 216 343 512 1000 复数 复数包含实部和虚部，虚数单位是 -1 的平方根。\n\u0026gt;\u0026gt; sqrt(-1) ans = 0.0000 + 1.0000i 要表示复数的虚部，请使用 i 或 j，例如：\n\u0026gt;\u0026gt; c = [3+4i, 4+3j; -i, 10j] c = 3.0000 + 4.0000i 4.0000 + 3.0000i 0.0000 - 1.0000i 0.0000 +10.0000i 操作 获取尺寸 \u0026gt;\u0026gt; size(a) ans = 3 3 实际上，size()命令返回的是一个 1×2 的矩阵，我们可以用sz来存放。\n设置 sz = size(a)\n因此 就是一个1×2的矩阵，第一个元素是3，第二个元素是3。\n也可以使用length()，它将返回最大维度的大小：\n\u0026gt;\u0026gt; v = [1 2 3 4]; \u0026gt;\u0026gt; length(v) ans = 4 \u0026gt;\u0026gt; length(a) ans = 3 数组索引 引用数组中的特定元素有两种方法。最常见的方法是指定行和列下标，例如\n\u0026gt;\u0026gt; a(2, 3) ans = 6 另一种方法不太常用，但有时非常有用，即使用单一下标按顺序向下遍历每一列，称为线性索引\n\u0026gt;\u0026gt; a(8) ans = 6 如果尝试在赋值语句右侧引用数组外部元素，MATLAB 会引发错误。\n\u0026gt;\u0026gt; a(5,5) 位置 1 处的索引超出数组边界(不能超出 3)。 不过，您可以在赋值语句左侧指定当前维外部的元素。数组大小会增大以便容纳新元素。\n\u0026gt;\u0026gt; a(5, 5) = 33 a = 1 2 3 0 0 4 5 6 0 0 7 8 10 0 0 0 0 0 0 0 0 0 0 0 33 \u0026gt;\u0026gt; size(a) ans = 5 5 要引用多个数组元素，请使用冒号运算符，这使您可以指定一个格式为 start:end 的范围。\n\u0026gt;\u0026gt; a(1:3, 2:3) ans = 2 3 5 6 8 10 单独的冒号（没有起始值或结束值）指定该维中的所有元素。\n串联 串联是连接数组以便形成更大数组的过程。\n实际上，第一个数组是通过将其各个元素串联起来而构成的。成对的方括号 [] 即为串联运算符。\n\u0026gt;\u0026gt; A = [a, a] A = 1 2 3 1 2 3 4 5 6 4 5 6 7 8 10 7 8 10 \u0026gt;\u0026gt; A = [a; a] A = 1 2 3 4 5 6 7 8 10 1 2 3 4 5 6 7 8 10  参考MATLAB快速入门\n ","date":"2020-01-10T15:35:53+08:00","permalink":"https://konosuba.xyz/blog/matlab%E7%9F%A9%E9%98%B5/","title":"MATLAB学习_矩阵与向量操作"},{"content":"YAML YAML 是 \u0026ldquo;YAML Ain\u0026rsquo;t a Markup Language\u0026rdquo;（YAML 不是一种标记语言）的递归缩写。有趣的是，在开发的这种语言时，YAML 的意思其实是：\u0026ldquo;Yet Another Markup Language\u0026rdquo;（仍是一种标记语言）。\nYAML 的语法和其他高级语言类似，并且可以简单表达清单、散列表，标量等数据形态。它使用空白符号缩进和大量依赖外观的特色，特别适合用来表达或编辑数据结构、各种配置文件、倾印调试内容、文件大纲\nYAML 的配置文件后缀为 .yml\n基本语法  大小写敏感 使用缩进表示层级关系 缩进不允许使用tab，只允许空格 缩进的空格数不重要，只要相同层级的元素左对齐即可 \u0026lsquo;#\u0026lsquo;表示注释  数据类型  对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 纯量（scalars）：单个的、不可再分的值  对象 对象键值对使用冒号结构表示 key: value，冒号后面要加一个空格。\nTOML TOML的全称是 \u0026ldquo;Tom\u0026rsquo;s Obvious, Minimal Language\u0026rdquo;，因为它的作者是 GitHub　联合创始人　Tom Preston-Werner 。\nTOML 的目标是成为一个极简的配置文件格式，TOML 被设计成可以无歧义地被映射为哈希表，从而被多种语言解析。\n基本语法  大小写敏感 同样使用缩进表示层级关系 缩进可以使用空格，也可以使用Tab 可以在数组中换行 \u0026lsquo;#\u0026lsquo;表示注释  对象 对象键值对使用等号的结构 key = value\n字符串 字符串和 JSON 的定义一致，只有一点除外：　TOML 要求使用　UTF-8 编码。\n数组 数组使用方括号包裹。空格会被忽略。元素使用逗号分隔。注意，不允许混用数据类型。\n[ 1, 2, 3 ] [ \u0026#34;red\u0026#34;, \u0026#34;yellow\u0026#34;, \u0026#34;green\u0026#34; ] [ [ 1, 2 ], [3, 4, 5] ] [ [ 1, 2 ], [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;] ] # 这是可以的。 [ 1, 2.0 ] # 注意：这是不行的。 数组可以多行。也就是说，除了空格之外，方括号间的换行也会被忽略。在关闭方括号前的最终项后的逗号是允许的。\n如果内容文件在两行---之间设置了前题变量，则该文件为YAML格式。否则，内容文件将在两行+++之间设置优先事项变量，表明它是TOML格式的。\n  参考 Segment Fault\n  参考菜鸟教程\n ","date":"2020-01-09T20:34:31+08:00","permalink":"https://konosuba.xyz/blog/yaml_and_toml/","title":"YAML与TOML"},{"content":"多变量梯度下降 与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：\n其中：\n我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。 多变量线性回归的批量梯度下降算法为：\n我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。\nPython 代码示例：\ndef computeCost(X, y, theta): inner = np.power(((X * theta.T) - y), 2) return np.sum(inner) / (2 * len(X)) 梯度下降法实践1-特征缩放 在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛\n以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。\n解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。如图：\n最简单的方法是令：x_n = (x_n - miu_n) / s_n ，其中miu_n是平均值，s_n是标准差\n梯度下降法实践2—学习率 梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。\n也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好\n梯度下降算法的每次迭代受到学习率的影响，如果学习率过小，则达到收敛所需的迭代次数会非常高；如果学习率过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。\n通常可以考虑尝试这些学习率：\nalpha = 0.01, 0.03, 0.1, 0.3, 1, 3, 10\n特征和多项式回归 对于房价预测问题\n其中，x1 = frontage(临街宽度)，x2 = depth(纵向深度)，x = frontage * depth = area，则：h(x) = theta0 + theta1*x1 + theta2*x2^2\n线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：h(x) = theta0 + theta1*x1 + theta2*x2^2 或者三次方模型：h(x) = theta0 + theta1*x1 + theta2*x2^2 + theta3*x3^3\n通常我们需要先观察数据然后再决定准备尝试怎样的模型。 另外，我们可以令：x2 = x2^2, x3 = x3^3，从而将模型转化为线性回归模型。\n根据函数图形特性，我们还可以使：\n 注：如果我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要。\n 正规方程 对于某些线性回归问题，正规方程方法是更好的解决方案。如\n正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：\n即对J(theta)进行求导。\n假设我们的训练集特征矩阵为X(包含了x0=1)，并且我们的训练集结果为向量y，则利用正规方程解出向量\n 对于某些不可逆的矩阵（通常是因为特征之间不独立，如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征，也有可能是特征数量大于训练集的数量），则无法使用正规方程方法\n 以下表数据为例：\n梯度下降与正规方程的比较：\n   梯度下降 正规方程     需要选择学习率Alpha 不需要   需要多次迭代 一次运算得出   当特征数量n大时也能较好适用 需要计算A的逆如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为O(n^3)，通常来说当n小于10000时还是可以接受的   适用于各种类型的模型 只适用于线性模型，不适合逻辑回归模型等其他模型    只要特征变量的数目并不大，正规方程是一个很好的计算参数theta的替代方法。具体地说，只要特征变量数量小于一万，通常使用正规方程法，而不使用梯度下降法。\n对于那些更复杂的学习算法，我们将不得不仍然使用梯度下降法。因此，梯度下降法是一个非常有用的算法，可以用在有大量特征变量的线性回归问题。\n但对于这个特定的线性回归模型，标准方程法是一个比梯度下降法更快的替代算法。所以，根据具体的问题，以及你的特征变量的数量，这两种算法都是值得学习的。\n正规方程的Python实现:\nimport numpy as np def normalEqn(X, y): theta = np.linalg.inv(X.T@X)@X.T@y #X.T@X等价于X.T.dot(X) return theta ","date":"2020-01-07T19:48:31+08:00","permalink":"https://konosuba.xyz/blog/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","title":"多变量线性回归"},{"content":"梯度下降 梯度下降是一个用来求函数最小值的算法，在这里我们将使用梯度下降算法来求出代价函数（损失函数）J(w1, w2)的最小值\n假设我们有时间和计算资源来计算权重值w1的所有可能值的损失。对于回归问题，所产生的损失与w1的图形始终是碗状图，如下所示：\n图中的最低点，即斜率正好为 0的位置。这个最小值就是损失函数收敛之处。\n过程 开始时我们为(w1, w2)选择一个起始值（起点）。然而起点并不重要；因此很多算法就直接将它们设为0或随机选择一个值。\n通过这个参数组合计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。\n在这里使用梯度下降法算法计算损失曲线在起点处的梯度。梯度是偏导数的矢量；它可以让我们了解哪个方向距离目标“更近”或“更远”\n梯度始终指向损失函数中增长最为迅猛的方向。梯度下降法算法会沿着负梯度的方向走一步，以便尽快降低损失。\n为了确定损失函数曲线上的下一个点，梯度下降法算法会将梯度大小的一部分与起点相加：\n然后，梯度下降法会重复此过程，逐渐接近最低点。\n局部最小值  想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。\n  这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。\n 我们持续这么做直到我们得到一个局部最小值（local minimum），然而因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），如果选择不同的初始参数组合，可能会找到不同的局部最小值。\n 这个问题在以前的机器学习中可能会遇到，因为机器学习中的特征比较少，所以导致很可能陷入到一个局部最优解中出不来 但是到了深度学习，动辄百万甚至上亿的特征，出现这种情况的概率几乎为0，所以我们可以不用考虑这个问题。\n 批量梯度下降 批量梯度下降法是最原始的形式，它是指在每一次迭代时使用所有样本来进行梯度的更新\n公式为：\n其中alpha是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。\n在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新theta0和theta1，当j = 0和j = 1时，会产生更新，所以你将更新J(theta0)和J(theta1)。\n实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新theta0和theta1，我的意思是在这个等式中，我们要这样更新：\ntheta0:=theta0，并更新theta1:=theta1\n实现方法是：你应该计算公式右边的部分，通过那一部分计算出theta0和theta1的值，然后同时更新theta0和theta1。\n学习率 Alpha 让我们来看看如果太小或太大会出现什么情况：\n  如果太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。\n  如果太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果太大，它会导致无法收敛，甚至发散。\n  假设你将theta1初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得theta1不再改变，也就是新的theta1等于原来的theta1，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率alpha保持不变时，梯度下降也可以收敛到局部最低点。\n 在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小。\n这就是梯度下降算法，你可以用它来最小化任何代价函数，不只是线性回归中的代价函数。\n","date":"2020-01-07T17:16:04+08:00","permalink":"https://konosuba.xyz/blog/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/","title":"降低损失：梯度下降法"},{"content":"线性回归 线性回归是解决回归问题最基本的一个方法。其实质就是找到一条直线能尽可能多的使已知的离散值分布在其周围（二维坐标系中）\n就像这样：\n或者是在三维坐标中，找到一个面来逼近\n在这里我们只讨论最简单的单变量线性回归\n单变量线性回归 单变量线性回归问题只含有一个特征（输入变量），因此可以把目标直线表达式写为：\nh(x) = y = wx + b\n其中， x代表特征/输入变量，h代表目标变量/输出变量\n我们需要有一个包含许多对(x, y)的训练集，之后把它喂给我们的学习算法，学习算法输出一个函数，通常表示为小写h表示，代表hypothesis(假设)，表示一个函数\n因此h根据输入的x值来得出y值，y值就是我们想要根据x知道的答案。因此，h是一个从y到x的函数映射。\n代价函数 又称为“损失函数”\n在前面的函数h中，我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度。\n模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）\n我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。 即使得代价函数最小\n这个代价函数可以根据最小二乘法得到\n我们绘制一个等高线图，三个坐标分别w (图中theta0)、h (图中theta1)和代价函数 (图中J(theta0, theta1))\n代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。\n  参考资料： 吴恩达《机器学习》课程笔记\n ","date":"2020-01-07T16:09:48+08:00","permalink":"https://konosuba.xyz/blog/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","title":"单变量线性回归"},{"content":"分类与回归是监督学习中的两个主要任务，它们即对应了监督学习中“学习”的部分\n分类模型与回归模型的本质其实一样。分类模型可将回归模型的输出离散化，回归模型也可将分类模型的输出连续化\n 例如：\nLinear Recognition 线性回归 使用 y = wx + b 的形式，y就是模型的输出，是一个连续值，所以可以用于处理回归问题\nLogistic Recognition 逻辑回归 一般作为分类问题的首选算法，logistic回归只是用到了回归算法，但是其输出的结果是决策边界，是不连续的，所以它其实是分类，而不是回归\n二分类 将 y = wx + b 利用激活函数（常用sigmoid函数）映射到 (0,1) 中。再选定一个阈值，将输出分为两类。\n多分类 先得到n组w不同的 y = wx +b ，之后进行归一化（例如使用Softmax函数），从而得到在n个类上的概率，即可解决多分类问题\n 回归问题的应用场景 回归问题通常是用来预测一个值，如预测房价、未来的天气情况等等。例如一个产品的实际价格为500元，通过回归分析预测值为499元，我们认为这是一个比较好的回归分析。\n一个比较常见的回归算法是线性回归算法（LR）。\n另外，回归分析用在神经网络上，其最上层是不需要加上softmax函数的，而是直接对前一层累加即可。回归是对真实值的一种逼近预测。\n分类问题的应用场景 分类问题是用于将事物打上一个标签，通常结果为离散值。\n例如判断一幅图片上的动物是一只猫还是一只狗，分类通常是建立在回归之上，分类的最后一层通常要使用softmax函数进行判断其所属类别。\n分类并没有逼近的概念，最终正确结果只有一个，错误的就是错误的，不会有相近的概念。\n最常见的分类方法是逻辑回归，或者叫逻辑分类。\n总结 一个小测验：假设你经营着一家公司，你想开发学习算法来处理这两个问题：\n  你有一大批同样的货物，想象一下，你有上千件一模一样的货物等待出售，这时你想预测接下来的三个月能卖多少件？\n  你有许多客户，这时你想写一个软件来检验每一个用户的账户。对于每一个账户，你要判断它们是否曾经被盗过？\n  那这两个问题，它们属于分类问题、还是回归问题?\n  问题一是一个回归问题，因为你知道，如果我有数千件货物，我会把它看成一个实数，一个连续的值。因此卖出的物品数，也是一个连续的值。\n  问题二是一个分类问题，因为我会把预测的值，用 0 来表示账户未被盗，用 1 表示账户曾经被盗过。所以我们根据账号是否被盗过，把它们定为0 或 1，然后用算法推测一个账号是 0 还是 1，因为只有少数的离散值，所以我把它归为分类问题。\n  ","date":"2020-01-06T15:45:03+08:00","permalink":"https://konosuba.xyz/blog/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92/","title":"分类(classification)与回归(regression)的区别与关系"},{"content":"题目 一个袋子里有30个银币，其中一枚是假币，并且假币和真币一模一样，肉眼很难分辨，目前只知道假币比真币重量轻一点。请问，如何区分出假币？\n分析 首先为每个银币编号，然后将所有的银币等分为两份，放在天平的两边。这样就将区分30个银币的问题变为区别两堆银币的问题。\n因为假币分量较轻，因此天平较轻的一侧中一定包含假币。再将较轻的一侧中银币等分为两份，重复上述做法。直到剩下两枚银币，便可用天平直接找出假银币。类似于二分法\n代码 由于这个是自己做的一个练习题，没有使用OJ判题，所以自己利用随机数生成银币的重量和假币相关信息\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;algorithm\u0026gt;#include \u0026lt;ctime\u0026gt;using namespace std; void generate_seq(int coin[]) { srand(time(0)); int coin_weight = rand() % 100; int fake_weight = rand() % coin_weight; int fake_add = rand() % 30; for (int i = 1; i \u0026lt;= 30; i++) { if (i == fake_add) coin[i] = fake_weight; else coin[i] = coin_weight; } cout \u0026lt;\u0026lt; \u0026#34;fake_add=\u0026#34; \u0026lt;\u0026lt; fake_add \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;fake_weight=\u0026#34; \u0026lt;\u0026lt; fake_weight \u0026lt;\u0026lt; endl; } void show_seq(int coin[]) { for (int i = 1; i \u0026lt;= 30; i++) { cout \u0026lt;\u0026lt; coin[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } int find_fake(int coin[], int begin, int end) { if (begin == end) return begin; double mid = (begin + end) / 2; int weight_a = 0, weight_b = 0; if ((end - begin + 1) % 2 == 0) //可等分  { for (int i = begin; i \u0026lt;= (int)mid; i++) weight_a += coin[i]; for (int i = (int)mid + 1; i \u0026lt;= end; i++) weight_b += coin[i]; cout \u0026lt;\u0026lt; begin \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; end \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; mid \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; weight_a \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; weight_b \u0026lt;\u0026lt; endl; if (weight_a \u0026lt; weight_b) find_fake(coin, begin, (int)mid); else find_fake(coin, (int)mid+1, end); }else //不可等分，中间留一个mid  { for (int i = begin; i \u0026lt; mid; i++) weight_a += coin[i]; for (int i = mid + 1; i \u0026lt;= end; i++) weight_b += coin[i]; cout \u0026lt;\u0026lt; begin \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; end \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; mid \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; weight_a \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; weight_b \u0026lt;\u0026lt; endl; if (weight_a \u0026lt; weight_b) find_fake(coin, begin, (int)mid - 1); else if (weight_a \u0026gt; weight_b) find_fake(coin, (int)mid + 1, end); else return mid; } } int main() { //产生随机数列  int coin[31]; generate_seq(coin); //打印数列  show_seq(coin); //找  int fake_add = find_fake(coin, 1, 30); cout \u0026lt;\u0026lt; \u0026#34;fake_add=\u0026#34; \u0026lt;\u0026lt; fake_add \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;fake_weight=\u0026#34; \u0026lt;\u0026lt; coin[fake_add] \u0026lt;\u0026lt; endl; return 0; } ","date":"2019-12-30T20:35:42+08:00","permalink":"https://konosuba.xyz/blog/%E5%81%87%E5%B8%81%E9%97%AE%E9%A2%98/","title":"C++解决假币问题"},{"content":"引 最近在百度站长平台加入了这个博客，由于之前在Google上都是直接提交sitemap地址，但是在百度索引sitemap实在太慢了，所以还是选择使用它推荐的crul主动推送方式，在这做个记录\n在Windows上安装配置crul 进入curl的官网下载最新的Windows版的binary the curl project安装包\n下载完成后解压到任意目录下\n之后进入系统属性-\u0026gt;高级系统设置-\u0026gt;高级-\u0026gt;环境变量-\u0026gt;系统变量\n新建一个变量，命名为curl，变量值选择之前解压的文件夹-\u0026gt;bin文件夹-\u0026gt;curl.exe\n一路保存\n之后打开cmd，敲入curl，输出如图，则配置成功\n使用curl推送链接 由于使用curl推送链接需要一个只有链接地址的文件，然而sitemap很明显不符合这个条件，所以需要先利用这个在线工具将网站中的链接提取出来\n如图，将图中右侧框中的链接复制到一个新建的txt文档，命名为urls.txt\n然后在cmd中进入txt文件所在目录，执行百度搜索资源平台给的推送命令，例如：\n如果有类似以下的输出，则说明推送成功！\n{ \u0026#34;remain\u0026#34;:4999998, \u0026#34;success\u0026#34;:2, \u0026#34;not_same_site\u0026#34;:[], \u0026#34;not_valid\u0026#34;:[] } 在服务器自动推送 很明显，现在这种必须要每次手动推送，很耗费能量，所以之后会试着在网站服务器端配置自动推送，这样才是真正的自动推送嘛\n","date":"2019-12-03T21:33:22+08:00","permalink":"https://konosuba.xyz/blog/crul_baidu_post/","title":"百度搜索资源平台用crul做链接主动推送"},{"content":"我们通常使用jTessBoxEditor训练工具进行训练，由于该工具是用Java开发的，所以在安装这个软件之前要保证电脑中有Java环境，这里就不介绍了。\n安装jTessBoxEditor 可以在这里下载到最新版安装包\n把下载得到的压缩包解压到任意位置，双击其中的train.bat文件，等待一会，弹出窗口就可以开始训练了\n制作训练样本 生成tif文件 打开软件，选择Tools-\u0026gt;Merge TIFF，文件类型选择ALL Image Files，选择所有要训练的样本图片，打开\n之后会又弹出窗口，文件名需要自己设定，注意要按照格式设置：\n[lang].[fontname].exp[num].tif\n其中lang为语言名称，fontname为字体名称，num为序号。这三项都可以自己定义\n这里我们设置为captcha.font.exp0.tif，文件类型TIFF，保存\n生成box文件 将之前生成的captcha.font.exp0.tif复制到Tesseract-OCR的安装目录\n打开cmd进入安装目录，执行命令\ntesseract.exe num.font.exp0.tif num.font.exp0 batch.nochop makebox 将.box文件和.tif文件放在同一文件夹\n手动调整 打开jTessBoxEditor工具，点击Box Editor-\u0026gt;Open，选择打开之前生成的.box文件\n软件中便会显示Tesseract自动标记识别的字符，接下来就需手动调整每一张的字符框和识别结果\n全部修改完成后，选择Save保存即可\n训练 先新建一个名为font_properties的文件，注意，只是文件，没有后缀！打开后，内容输入\ncaptcha 0 0 0 0 0 这里全取值为0，表示字体不是粗体、斜体等等\n之后在命令行分别运行命令：\nshapeclustering.exe -F font_properties -U unicharset captcha.font.exp0.tr mftraining.exe -F font_properties -U unicharset captcha.font.exp0.tr cntraining.exe captcha.font.exp0.tr 之后给文件 inttemp，normproto，pffmtable，shapetable，unicharset 添加前缀captcha.，也就是我们的字体名\n生成语言库 命令\ncombine_tessdata.exe captcha. 会生成一个captcha.traineddata文件，将其复制到Tesseract-OCR安装目录中的tessdata文件夹即可\n使用训练结果 在调用tesseract或pytesseract时，只需添加参数lang=\u0026ldquo;captcha\u0026rdquo;（我们的字体名），程序就会自动调用啦\n","date":"2019-11-20T19:29:52+08:00","permalink":"https://konosuba.xyz/blog/tesseract%E8%AE%AD%E7%BB%83/","title":"Tesseract-OCR样本训练方法"},{"content":"安装Tesseract-OCR 在官网下载最新的Windows安装包，双击运行\n根据需要选择，一路Next，直到这个页面\n在Additional language data(download)中选择要下载的其他语言的数据，之后程序会自动下载。一直到安装成功\n配置环境变量 进入高级系统设置，选择高级-\u0026gt;环境变量\n选中系统变量中Path-\u0026gt;编辑\n新建一项，地址为Tesseract-OCR的安装目录即可（例如C:\\Program Files\\Tesseract-OCR）\n可以通过在控制台中输入tesseract命令来检查是否配置成功，输出如图即表示成功\n配置Python 直接使用pip install pytesseract进行安装\npytesseract 功能  get_tesseract_version　返回系统中安装的Tesseract版本。 image_to_string　将图像上的Tesseract OCR运行结果返回到字符串 image_to_boxes　返回包含已识别字符及其框边界的结果 image_to_data　返回包含框边界，置信度和其他信息的结果 image_to_osd　返回包含有关方向和脚本检测的信息的结果  参数 image_to_data(image, lang=None, config='', nice=0, output_type=Output.STRING)  image object　图像对象 lang String，Tesseract　语言代码字符串 config String　任何其他配置为字符串，例如：config='\u0026ndash;psm 6' nice Integer　修改Tesseract运行的处理器优先级。Windows不支持。 output_type　类属性，指定输出的类型，默认为string。  简单实例 识别一张图像中字符并直接输出\nimport pytesseract im = \u0026#34;C:/Users/1/Desktop/test.jpg\u0026#34; result = pytesseract.image_to_string(im) print(result) 这样识别到的字符就会转化成字符串输出\n","date":"2019-11-20T18:15:12+08:00","permalink":"https://konosuba.xyz/blog/tesseract%E5%AE%89%E8%A3%85/","title":"Tesseract-OCR安装与python中使用"},{"content":" 这是我的【项目笔记】利用OpenCV的MLS图像扭曲变形实现中的第一部分\n  本文主要对MLS进行了一定讲解\n 先简单了解一下什么是最小二乘法\n最小二乘法 当我们在测量某个值y时，由于误差的存在，可能多次测量的结果不尽相同\n我们把多次测量得到的不同结果yi画在同一坐标系中\n同时将猜测的实际值y也画在坐标系中\n每个yi和y都有一个差值| y - yi |，称为误差\n记所有误差的平方和\n由于实际值y是我们猜测的，所以它的值可以变化，同时误差的平方和ε也会随之改变\n于是高斯或是法国科学家勒让德就提出使误差的平方和最小的 y 就是真值，这是基于，如果误差是随机的，应该围绕真值上下波动\n这就是最小二乘法，即\n此外，经证明得出误差的分布服从正态分布（不愧是天下第一分布），这里就不证明了\n总的来说，对于被选择的参数，应该使算出的函数曲线与观测值之差的平方和最小。用函数表示为：\n最小化问题的精度，依赖于所选择的函数模型\n移动最小二乘法 移动最小二乘法与传统的最小二乘法相比，有两个比较大的改进：\n  拟合函数的建立不同。这种方法建立拟合函数不是采用传统的多项式或其它函数，而是由一个系数向量 a(x)和基函数 p(x)构成， 这里 a(x)不是常数，而是坐标 x 的函数。     引入紧支（ Compact Support）概念。认为点x处的值 y只受 x附近子域内节点影响，这个子域称作点 x 的影响区域， 影响区域外的节点对 x的取值没有影响。在影响区域上定义一个权函数w(x)，如果权函数在整个区域取为常数，就得到传统的最小二乘法。    节选自《基于移动最小二乘法的曲线曲面拟合-曾清红》\n 利用MLS变换图像 这一部分，我主要参考了论文《Image Deformation Using Moving Least Squares》中的内容\n考虑由用户设定锚点来对图像变形进行控制的情况，首先进行准备工作，推导出公式\n准备工作 设p为一组控制点，q是它对应的变形位置\n对于图像中的某一点v，有最小的仿射变换lv(x)，使\n成立。其中pi和qi是行向量，权值wi满足\n各点权重wi 由于对于每个v都有不同的wi的值，称之为移动最小二乘最小化（a Moving Least Squares minimization）。对于每个v都有不同的lv(x)\n此时定义变形函数f(x) = lv(x)，可见当v接近pi时，wi趋于无穷、f(pi) = qi，此外若qi = pi，则lv(x) = x、f(v) = v\n由于lv(x)是一个仿射变换，由线性变换矩阵M和偏移量T组成，即\n又可根据M求T，即\n偏移量T 其中\n因此，lv(x)可以改写为\n仿射变换lv(x) 于是方程(1)中的最小二乘问题又可以重写为\n最小二乘 其中ˆpi = pi − p∗ 且ˆqi = qi −q∗.\n 可以发现，我们要进行的图像变形最终效果与变换矩阵M相关联，因此根据矩阵M的不同，可以获得不同效果的变形。论文中将其分为了仿射变换、相似变换和刚性变换\n在这里仅呈现了每种变换对应的变化矩阵和变化函数，具体推导可以参见论文原文\n仿射变换 找到使方程(4)最小的矩阵M如下\n仿射变换矩阵 由此得到的变换函数如下\n变换函数 也可以写为\n其中\n可见，一旦给定了某个点v，此处的Aj便可以提前计算得出\n如图b是仿射变换的效果图\n相似变换 得到进行相似变换时的变换矩阵M为\n相似变换矩阵 其中\n由此得出变换函数\n变换函数 其中可以提前计算的部分\n如图c是相似变换的效果图\n刚性变换 刚性变换的矩阵形式与相似变化相同，仅是其中的参数miu发生了变化\n刚性变换矩阵 其中\n得出刚性变化的变化函数为\n变换函数 下图中d即刚性变换的效果\n  参考文献：\n  《Image Deformation Using Moving Least Squares》\n  《基于移动最小二乘法的曲线曲面拟合》\n  参考博客：\n  如何理解最小二乘法？\u0026ndash;马同学\n ","date":"2019-11-07T13:58:04+08:00","permalink":"https://konosuba.xyz/blog/mls/","title":"利用MLS移动最小二乘法对图像变形"},{"content":"引 这学期开学的时候实验室接了个项目，要做一个类似Adobe Illustrator中的“操纵扭曲”功能的Demo\n 就像这样\n 需求分析 可见需要实现的功能核心就是通过鼠标的拖拽对图像进行扭曲变形，这里的变形主要可以分为两类：\n  鼠标拖拽导致的普通变形\n  在某一固定锚点基础上的旋转式变形\n  确定方案 明确了这个后我便开始查阅资料，发现这篇paper 《Image Deformation Using Moving Least Squares》 中利用了MLS移动最小二乘来实现图像变形，其实现的效果和我们的目标极为相似，于是我也决定利用该算法来实现这个Demo\n由于要利用鼠标拖拽进行操作，便选择使用Qt来进行图形化界面设计，然鹅我以前也没有用过Qt，因此学习了一些Qt基本知识\n开始吧 明确了方案和目标后，便开始了漫长的学习+实践：\n  程序结构框架确定\n  核心算法实现\n  旋转式变形的实现\n  在进行到这里之后，发现程序无法实现对某个关节的单独拉伸，于是我们考虑寻找图像中的骨骼，在关节的交点添加一些锚点进行固定\n 图形骨骼查找  实现效果 最终项目完成，实现了这些功能，如图是个小小的演示\n 本文将会持续更新\n","date":"2019-10-23T23:25:14+08:00","permalink":"https://konosuba.xyz/blog/image_warp_opencv_paper/","title":"【项目笔记】利用OpenCV的MLS图像扭曲变形实现"},{"content":"最近在研究手绘图形识别相关的内容，想起了这篇去年的文章，研究的内容也大致差不多，考虑使用Google的循环神经网络，于是转载过来记录一下\n原文发表于2018-12-19\n这两天，一个“魔法画板”在国外传疯了。\nAI圈内外的灵魂画手们玩到根本停不下来，创造的惊喜画作能装满好几个美术馆。\n这个画板背后，可不是一个普通的画画AI。它，会脑补。\n随便画一笔，就能得到一只猫：\n画个圆圈，变成猫：\n画个三角，变成猫：\n画个方块，变成猫：\n真是万物皆可喵喵。\n当然，你也可以不让它画猫，改成画狗。只要你设定了一个绘画的目标，之后随便画一笔，AI就能脑补出余下的画面。\n这个“魔法”，是来自谷歌的吸猫少女Monica Dinculescu用Sketch RNN开发的。\n因为她爱猫成痴，不仅自己头像是和自家喵子的合影，连个人主页域名都叫Meowni.ca，我们就叫她喵妮卡好了。\n所以，受到创作者的影响，这个AI默认属性为吸猫爱好者，但除了猫之外，AI也会脑补许多其他内容，脑洞很大。\n发布之后，众人竞相玩耍，好评如潮，2000多人点赞。\n有人让AI画了满屏的骷髅，说，好美啊！\n谷歌大佬David Ha也表示，他已经试过用各种基本形状来教导AI画羊了。\n不止有魔力，还可以加戏 喵妮卡给应用起名为魔法画板 (Magic Sketchpad) ，也名副其实。\n毕竟，只要画一笔，妈咪妈咪哄！一整张图就出现在眼前。\n△ 你想要什么样的美人鱼？\n而且，只要按一下选择栏左边的刷新按钮，AI就会根据刚才那一笔，不断为你展现新的画法。\n一共有100多种东西可以画，青蛙，秋千，直升飞机，连龙猫里的猫巴士都有。\n我是一只豆豆眼的猫头鹰：\n我是一只很鬼魅的仙人掌：\n为了这100多种选项，都能找到合适的色彩来诠释，画板还提供了18种颜色的画笔。\n这样一来，就有数不清的排列组合。有大胆想法的小伙伴们，可以在魔法画板上尽情加戏了。\n在你开始表演之前，量子位先抛抛砖：\n鲸鱼喷出的不一定是水，也有可能是花。\n牙刷上方温柔的曲线不一定是牙膏，也有可能是蜗牛。\n另外，如果你还没想到，除了排列组合之外，还可以鬼畜啊。\n一头鲸鱼喷水没什么，十几头鲸一起喷，就很有节奏感了 (误) 。\n一个人做瑜伽太孤单了，十几个人一起做，姿态各不相同，清明瑜伽图岂不美哉？\n不过虽然好玩，量子位似乎还是发现了一个bug，像猫巴士 (Catbus) 这种组合选项：画方成车，画圆成猫，无法兼顾。那么，怎样才能一步生成下面这样的效果呢？\n想要体验一下的盆友，传送门照例在文末~\n人家是有背景的 可能你已经发觉了，它的画风很像的谷歌推出的Quick, Draw!，中文名为“猜画小歌”。\n是的，他们是一家人。\n喵妮卡在推特上说了，她的魔法画板使用的就是Quick, Draw!数据集。\n这个数据集里面，有5000万张画，分为345个类别。每一张画，都记录了画画的整个过程：画笔运动的方向，何时提笔，何时停止绘画。\n如果你玩过猜画小歌，那这个数据集里，也有你的一份贡献。\n既然使用的是Quick, Draw!数据集，模型基本上没有什么悬念。\n正是Sketch-RNN。这是一个用Quick, Draw！数据集训练出来循环神经网络（RNN）。目标是让AI以类似人类的方式来画画，并概括出抽象的概念。\n模型有这样的能力，做出来魔法画板也就没有那么难了。\n你随手画个圈，就是为Sketch-RNN输入了一个序列，它可以根据这个序列和你选择要画的东西，预测接下来的序列：也就是补完这幅画。\n虽然画风奇特，但画啥就有点像啥。\n具体的实现代码，喵妮卡也全部放出来了。（传送门在文末。）\n三种额外玩法 除了这个万物皆可喵的网页之外，喵妮卡所在的Google Magenta团队还用Sketch-RNN创作了几个不同的涂鸦应用。\n9×N种预测，总能猜中你的心 你涂鸦的每一笔，都被我预料到了。\n无论你画了个啥，我都能猜出你接下来准备如何下笔。\n并且，我有无数种方案，只要点击predict，就可以出现新的9种图案。\n而且我还能选择不同的美术风格，通过调整temperature，数值越接近1，我的画风越抽象、越狂放不羁；\n数值越接近0，我的画风越写实，下笔婉转，基本符合小学美术的要求。\n不同图像，一键生成渐变效果 和GAN的许多应用Demo一样，Sketch-RNN也可以实现“渐变”功能。\n比如，我们随机选了两个公交车的图案，图案的美术风格依然由“狂放度”temperature决定。\n之后，点击Interpolate!就可以实现插值效果，也就是两个图案渐变过程的每一帧变化图案。\n###我画得跟你一样\n这个玩法用上了变分自动编码器（Variational Auto-Encoder，VAE）\nVAE在这里的应用，是“模仿你画画”。\n比如，画一只猫猫，画完之后点击auto-encode，就可以模仿你的笔触，画出各种不同的猫。\n不过，在不同品类上，似乎学得不太像。\n可能是贡献数据集的那些外国人，不认识“王”字，对小脑斧的理解跟我们不太一样吧。\n另外，这个AI很有个性，非常坚持自己的看法。\n比如选中菠萝pineapple，你非要画一个苹果，它也不相信你画的就是菠萝。\n△ “图样，本AI见过的菠萝多了去了，不要拿苹果糊弄我” 真是“投之以苹果，报之以菠萝”。\n传送门 魔法画板 亲测手机可玩\nhttps://magic-sketchpad.glitch.me/\n实现代码：\nhttps://glitch.com/edit/#!/magic-sketchpad?path=README.md:1:0\n其他可玩Demo 多预测：\nhttps://magenta.tensorflow.org/assets/sketch_rnn_demo/multi_predict.html\n插值：\nhttps://magenta.tensorflow.org/assets/sketch_rnn_demo/interp.html\n变分自动编码器（VAE）：\nhttps://magenta.tensorflow.org/assets/sketch_rnn_demo/multi_vae.html\n背后的Sketch-RNN Sketch-RNN论文：\nhttps://arxiv.org/abs/1704.03477\nGoogle博客：\nhttps://ai.googleblog.com/2017/04/teaching-machines-to-draw.html\nMagenta博客：\nhttps://magenta.tensorflow.org/sketch-rnn-demo\n 版权声明：本文为CSDN博主「量子位」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n原文链接：\nhttps://blog.csdn.net/yH0VLDe8VG8ep9VGe/article/details/85110781\n","date":"2019-10-20T00:45:31+08:00","permalink":"https://konosuba.xyz/blog/reprint_magic_sketchpad/","title":"【转载】谷歌小姐姐搞出魔法画板：你随便画，补不齐算AI输"},{"content":"今天开始在看Udacity上的TensorFlow入门课程，其中构建的第一个神经网络模型就是将摄氏度转换成华氏度，于是在这里记录一下\n公式 已知摄氏度转换成华氏度有数学公式：\nf = c * 1.8 + 32 而我们就要在不告知模型这个公式的前提下，通过告知一系列对应的摄氏度与华氏度样例，来训练它以实现摄氏度转华氏度这一功能\nimport dependencies 导入依赖项 需要引入TensorFlow与NumPy库构建神经网络\nfrom __future__ import absolute_import, division, print_function, unicode_literals import tensorflow as tf import numpy as np 还需要引入logging以记录日志\nimport logging logger = tf.get_logger() #返回tf的日志实例 logger.setLevel(logging.ERROR) Set up training data 建立训练数据 由于在这里我们使用的是监督式机器学习，所以准备两组链表celsius_q和fahrenheit_a分别代表摄氏温度与对应华氏温度，用来训练模型\ncelsius_q = np.array([-40, -10, 0, 8, 15, 22, 38], dtype=float) fahrenheit_a = np.array([-40, 14, 32, 46, 59, 72, 100], dtype=float) for i,c in enumerate(celsius_q): print(\u0026#34;{} degrees Celsius = {} degrees Fahrenheit\u0026#34;.format(c, fahrenheit_a[i])) 输出：\n-40.0 degrees Celsius = -40.0 degrees Fahrenheit -10.0 degrees Celsius = 14.0 degrees Fahrenheit 0.0 degrees Celsius = 32.0 degrees Fahrenheit 8.0 degrees Celsius = 46.0 degrees Fahrenheit 15.0 degrees Celsius = 59.0 degrees Fahrenheit 22.0 degrees Celsius = 72.0 degrees Fahrenheit 38.0 degrees Celsius = 100.0 degrees Fahrenheit 一些机器学习术语：  Feature（特征）：模型的输入。在这里即摄氏度 Labels（标签）：模型的输出。在这里即华氏度 Example（样本）：训练期间数据集的一行内容，可以是标注样本(labeled example)和无标注样本(unlabeled example)。在这里即一对摄氏度与华氏度数据，为标注样本  Create the model 创建模型 由于问题比较简单，因此我们要建立的密集网络将只需要一个单层神经元\nBuild a layer 建立一个层 我们会把这一层叫做l0，并且使用 tf.keras.layers.Dense(全连接层)来建立\ntf.keras.layers.Dense   units=1 指定本层神经元数量。神经元的数量定义了本层需要有多少内部变量来学习解决这个问题。由于这是本模型的最后一层，因此它也代表模型输出的大小。（在多层神经网络中，该层的大小与形状需要与下一层的input_shape相匹配\n  input_shape=[1] 指定本层输入值为单值。表明这是一个包含单个成员的一维数组。由于这是本模型的第一层（也是唯一一层），因此该输入形状也是整个模型的输入形状。单值是浮点数，即摄氏度\n  l0 = tf.keras.layers.Dense(units=1, input_shape=[1]) Assemble layers into the model 将Layer组装到模型中 定义了层之后，就要将它们组装成模型。Sequential model 顺序模型的定义需要以层列表作为参数，指定从输入到输出的计算顺序\nmodel = tf.keras.Sequential([l0])  注意： 以上两步经常合并为一步操作，如\n model = tf.keras.Sequential([ tf.keras.layers.Dense(units=1, input_shape=[1]) ]) Compile the model, with loss and optimizer functions 使用损失和优化器功能编译模型 搭好模型架构之后，在训练模型之前，还要执行编译操作。在编译时，经常需要指定三个参数：\n  Loss function 一种衡量结果与预期相差多少的方法（测得的差异称为loss(损失)）\n  Optimizer function 一种调整内部值以减少损耗的方法\n  Metrics function （较复杂，此处不用，日后再看）\n  model.compile(loss=\u0026#39;\u0026#39;, optimizer=tf.keras.optimizers.Adam(0.1)) 在训练过程中使用model.fit()来首先计算每个点的损耗，之后对其改善。优化器功能用于计算对模型内部变量的调整，目的是调整内部变量直到模型（实际是一个数学函数）接近将摄氏度转换为华氏度的公式为止\n这里使用的优化函数mean_squared_error（均方误差）和优化器Adam是这种简单模型的标准配置，实际还有其他可用配置。\n在建立自己的模型时，我们需要考虑的Optimizer优化器的部分是学习率（即上式中的0.1），这是在模型中调整值时采取的步长，它决定着目标函数能否收敛到局部最小值以及何时收敛到最小值。合适的学习率能够使目标函数在合适的时间内收敛到局部最小值。范围通常在0.001（默认）和0.1之间\nTrain the model 训练模型 在训练过程中，模型输入摄氏温度，使用当前的内部变量（权重）执行计算，并输出相应华氏温度的值。 由于权重最初是随机设置的，因此输出并不会接近正确的值。实际输出与期望输出之间的差值通过损失函数计算，而优化器函数将指导如何调整权重。\n计算，比较，调整的整个流程由fit方法进行控制。 它的第一个参数是输入，第二个参数是期望的输出结果。epochs参数指定模型应运行此循环多少次，而verbose参数控制该方法的日志显示。\nhistory = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False) #fit方法返回History对象 print(\u0026#34;Finished training the model\u0026#34;) 输出：\nFinished training the model  verbose参数\n   默认为1 verbose = 0 为不在标准输出流输出日志信息 verbose = 1 为输出进度条记录 verbose = 2 为每个epoch输出一行记录    History对象\n  可以由fit()方法返回。History.history属性是一个记录了连续迭代的训练/验证（如果存在）损失值和评估值的字典。可以利用该对象实现训练历史可视化\n Display training statistics 展示训练统计数据 由于fit会返回一个History对象，因此我们可以使用该对象来绘制每个训练时期后模型损失的下降趋势。若为高损耗则意味着模型预测的华氏度与fahrenheit_a中的期望值相去甚远。\n使用Matplotlib进行绘制\nimport matplotlib.pyplot as plt plt.xlabel(\u0026#39;Epoch Number\u0026#39;) #x坐标轴 plt.ylabel(\u0026#34;Loss Magnitude\u0026#34;) #y坐标轴 plt.plot(history.history[\u0026#39;loss\u0026#39;]) #标点 plt.show() 结果：\n可见，我们的模型起初改进非常快，然后有了稳定而缓慢的改进，直到最终接近“完美”为止。\nUse the model to predict values 使用模型预测数值 至此，我们已经拥有了一个可以利用摄氏度获得华氏度的模型。我们可以利用它计算先前未知的摄氏温度\nprint(model.predict([100.0])) #向模型输入100.0 输出：\n[[211.74744]] 而我们通过公式可以得到：\n100*1.8 + 32 = 212 由此可见，我们的模型得到的结果已经非常接近真实答案\nTo review 回顾  我们创建了一个含有单层神经元的模型 将模型训练了3500次（7对数据，500轮）  我们的模型调整了Dense层中的变量（权重），直到它能够为任何摄氏值返回正确的华氏温度值\nl0 = tf.keras.layers.Dense(units=1, input_shape=[1]) model = tf.keras.Sequential([l0]) model.compile(loss=\u0026#39;mean_squared_error\u0026#39;, optimizer=tf.keras.optimizers.Adam(0.1)) history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False) model.predict([100.0]) Looking at the layer weights 查看Layer权重 最后我们打印Dense层的内部变量\nprint(\u0026#34;These are the layer variables: {}\u0026#34;.format(l0.get_weights())) #以包含Numpy矩阵的列表形式返回层的权重 输出：\nThese are the layer variables: [array([[1.7979496]], dtype=float32), array([31.952478], dtype=float32)] 这里的第一个变量1.7979496接近于1.8，第二个变量31.952478接近于32，而这两个值也是实际的转换公式中的两个变量\n对于只有单个输入和单个输出的单神经元，它内部看起来与直线方程相同，即y=mx+b，因此我们的模型能够如此逼近转换公式\n而有了额外的神经元，额外的输入和额外的输出，公式会变得更加复杂，但是思路是一样的。\nA little experiment 小实验 如果我们创建多个含不同数量神经元的层，会是怎样的结果呢？\nl0 = tf.keras.layers.Dense(units=4, input_shape=[1]) l1 = tf.keras.layers.Dense(units=4) l2 = tf.keras.layers.Dense(units=1) model = tf.keras.Sequential([l0, l1, l2]) model.compile(loss=\u0026#39;mean_squared_error\u0026#39;, optimizer=tf.keras.optimizers.Adam(0.1)) model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False) print(\u0026#34;Finished training the model\u0026#34;) print(\u0026#34;Model predicts that 100 degrees Celsius is: {} degrees Fahrenheit\u0026#34;.format(model.predict([100.0]))) print(\u0026#34;These are the l0 variables: {}\u0026#34;.format(l0.get_weights())) print(\u0026#34;These are the l1 variables: {}\u0026#34;.format(l1.get_weights())) print(\u0026#34;These are the l2 variables: {}\u0026#34;.format(l2.get_weights())) 输出：\nFinished training the model Model predicts that 100 degrees Celsius is: [[211.74742]] degrees Fahrenheit #得到预测结果仍然与实际相近 These are the l0 variables: [array([[-0.52520204, -0.25983605, 0.27832836, 0.11471745]], dtype=float32), array([-3.468158 , -3.3907545, 3.5017395, 2.1893277], dtype=float32)] These are the l1 variables: [array([[-0.37798777, 0.6455525 , 0.7230809 , 0.3954812 ], [-0.85110897, 0.6376249 , 0.31107017, -0.70929325], [-0.534542 , -0.980425 , -0.92369473, 0.72322994], [ 0.38675487, 0.41835558, -0.24832523, -0.08700816]], dtype=float32), array([ 3.2148993, -3.1253922, -3.340591 , 3.433869 ], dtype=float32)] These are the l2 variables: [array([[ 0.74975073], [-0.56715256], [-1.4492323 ], [ 0.39553005]], dtype=float32), array([3.2948794], dtype=float32)] 可以看到，模型仍然能很好的得到结果，但其中的变量早已不接近1.8或32，这是因为多层Layer带来的复杂度隐藏了转换方程的“简单”形式\n","date":"2019-10-11T20:33:51+08:00","permalink":"https://konosuba.xyz/blog/tensorflow%E5%B0%86%E6%91%84%E6%B0%8F%E5%BA%A6%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%8D%8E%E6%B0%8F%E5%BA%A6/","title":"第一个TensorFlow模型：摄氏度转换为华氏度"},{"content":"今天在做mooc课程《Python语言程序设计》的练习题时，遇到一道题，硬生生纠结了半个小时，结果发现答案居然只是短短的两行，这功力不够果然还是不行啊，用C的思维去写Python怕是要纠结死🤔\n先看看题\n题目 数值运算\n描述 获得用户输入的一个字符串，格式如下：\nM OP N 其中，M和N是任何数字，OP代表一种操作，表示为如下四种：+, -, *, /（加减乘除）\n根据OP，输出M OP N‬的运算结果，统一保留小数点后两位\n注意：M和OP、OP和N之间可以存在多个空格，不考虑输入错误情况\n示例输入‪ 10 + 100 1 / 20 示例输出 110.00 0.05 解答 我最开始的想法是读入字符串，然后根据空格分为M、OP和N，之后再转换为int型进行计算\n然而，我却完全忘记了Python有着eval()的存在\u0026hellip;.\neval() |eval()函数用来执行一个字符串表达式，并返回表达式的值 ‬‪‬‪‬‪‬‮‬‪‬‭‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‫\neval(expression[, globals[, locals]])  参数\n  expression \u0026ndash; 表达式\n  globals \u0026ndash; 变量作用域，全局命名空间，若被提供，必须是一个字典对象\n  locals \u0026ndash; 变量作用域，局部命名空间，若被提供，可以是任何映射对象\n 可见，使用eval()后，就不需要我们自己对用户输入的算式进行处理，只需要直接调用，函数会自动帮我们计算结果\n之后根据题意，我们还要将运算结果保留两位小数，这时format()就派上了用场\nformat() 这是一种格式化字符串的函数，基本语法是使用{}和: ‪‬‪‬‪‬‪‬‪‬‮‬‭‬‪‬‪‬‪‬‪‬‪‬‪‬‮ |format()‫‬‪‬‪函数‬‪‬‪‬可以接受不限个参数，位置可以不按顺序\n\u0026gt;\u0026gt;\u0026gt; \u0026#34;{} {}\u0026#34;.format(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;) # 不设置指定位置，按默认顺序 \u0026#39;hello world\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#34;{0} {1}\u0026#34;.format(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;) # 设置指定位置 \u0026#39;hello world\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#34;{1} {0} {1}\u0026#34;.format(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;) # 设置指定位置 \u0026#39;world hello world\u0026#39; 数字格式化 我们阔以使用str.format()格式化数字\n|{:.2f} 保留小数点后两位\n|{:+.2f} 带符号保留小数点后两位\n|{:0\u0026gt;2d} 数字补0（填充左边，宽度为2）\n|{:,} 以逗号分隔的数字形式\n|{:.2%} 百分比格式\n|{:.2e} 指数记法\n|{:\u0026gt;10d} 右对齐（默认，宽度为10）\n|{:^10d} 中间对齐（宽度为10）\n|{:b} 二进制\nAnswer 于是，利用eval()与format()，我们阔以直接写出答案：\ns = input() print(\u0026#34;{:.2f}\u0026#34;.format(eval(s))) 怎么样，是不是很简单\n","date":"2019-10-10T20:37:31+08:00","permalink":"https://konosuba.xyz/blog/python%E4%B8%ADeval%E4%B8%8Eformat/","title":"Python中eval()与format()"},{"content":"在梯度下降算法中，我们用梯度乘以一个称为学习速率（有时也称为步长）的标量，以确定下一个点的位置。例如，如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。\n超参数是编程人员在机器学习算法中用于调整的旋钮。大多数机器学习编程人员会花费相当多的时间来调整学习速率。如果学习速率过小，就会花费太长的学习时间：\n相同的 U 形曲线。很多点都相互非常接近，它们的轨迹朝着 U 形底部缓慢前进。\n相反，如果学习速率过大，下一个点将永远在 U 形曲线的底部随意弹跳，就好像量子力学实验出现了严重错误一样：\n相同的 U 形曲线。这条曲线包含的点非常少。点的轨迹会跳过 U 形底部，然后再次跳回。\n每个回归问题都存在一个“恰好”的学习速率，这个值与损失函数的平坦程度有关。例如，若已知损失函数的梯度较小，则可以放心地试着采用更大的学习速率，以补偿较小的梯度并获得更大的步长。\n相同的 U 形曲线。点的轨迹大约需要 8 步达到最低点。\n","date":"2019-09-26T11:12:23+08:00","permalink":"https://konosuba.xyz/blog/%E5%AD%A6%E4%B9%A0%E9%80%9F%E7%8E%87/","title":"ML学习速率"},{"content":" Update：使用python库tqdm轻松实现\n 一个小程序，用Python在控制台中打印进度条，主要使用time库对时间进行控制，利用了\\r转义符使光标回到当前行首的特性，通过多次打印进度条实现动画效果\n代码 import time scale = 50 # 进度条长度 print(\u0026#34;\u0026gt;\u0026gt;执行开始\\n\u0026#34;) start = time.perf_counter() # 开始时刻 for i in range(scale+1): a = \u0026#39;|\u0026#39; * i b = \u0026#39;.\u0026#39; * (scale - i) c = (i / scale) * 100 dur = time.perf_counter() - start # 当前用时 print(\u0026#34;\\r{:^3.0f}% [{}\u0026gt;\u0026gt;{}] {:.2f}s\u0026#34;.format(c, a, b, dur), end=\u0026#39;\u0026#39;) # 打印进度条 time.sleep(0.1) # 休息时间，调整速度 print(\u0026#34;\\n\\n\u0026gt;\u0026gt;执行结束\u0026#34;) 效果 ","date":"2019-09-19T20:59:58+08:00","permalink":"https://konosuba.xyz/blog/python%E6%96%87%E6%9C%AC%E8%BF%9B%E5%BA%A6%E6%9D%A1/","title":"Python文本进度条"},{"content":" 内容摘自《OpenCV入门教程》\n 在读取矩阵元素时，以及获取矩阵某行的地址时，需要指定数据类型。这样首先需要不停地写\u0026lt;uchar\u0026gt;，让人感觉很繁琐，在繁琐和烦躁中容易犯错。\n如下面代码中的错误，用at()获取矩阵元素时错误的使用了double类型。这种错误不是语法错误，因此在编译时编译器不会提醒。在程序运行时，at()函数获取到的不是期望的(i,j)位置处的元素，数据已经越界，但是运行时也未必会报错。这样的错误使得你的程序忽而看上去正常，忽而弹出“段错误”，特别是在代码规模很大时，难以查错。\n如果使用Mat_类，那么就可以在变量声明时确定元素的类型， 访问元素时不再需要指定元素类型，即使得代码简洁，又减少了出错的可能性。\n上面代码可以用Mat_实现，实现代码如下面例程里的第二个双重for循环。\n#include \u0026lt;iostream\u0026gt;#include \u0026#34;opencv2/opencv.hpp\u0026#34;#include \u0026lt;stdio.h\u0026gt;using namespace std; using namespace cv; int main(int argc,char* argv[]) { Mat M(600, 800, CV_8UC1); for(int i = 0; i \u0026lt; M.rows; ++i) { //获取指针时需要指定类型  uchar *p = M.ptr\u0026lt;uchar\u0026gt;(i); for(int j = 0; j \u0026lt; M.cols; ++j) { double d1 = (double)((i + j) % 255); //用at读像素时，需要指定类型  M.at\u0026lt;uchar\u0026gt;(i, j) = d1; double d2 = M.at\u0026lt;uchar\u0026gt;(i, j); } } //在变量声明时，指定矩阵元素类型  Mat_\u0026lt;uchar\u0026gt; M1 = (Mat_\u0026lt;uchar\u0026gt;\u0026amp;)M; for(int i = 0; i \u0026lt; M1.rows; ++i) { //不需要指定元素类型，语言简洁  uchar *p = M1.ptr(i); for(int j=0;j\u0026lt;M1.cols;++j) { double d1=(double)((i+j)%255); //直接使用matlab风格的矩阵元素读写，简洁  M1(i,j) = d1; double d2 = M1(i,j); } } return 0; } ","date":"2019-09-18T21:09:06+08:00","permalink":"https://konosuba.xyz/blog/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AE%9A%E4%B9%89mat_%E7%B1%BB/","title":"为什么要定义Mat_类"},{"content":"  (adsbygoogle = window.adsbygoogle || []).push({ google_ad_client: \"ca-pub-9673215637005333\", enable_page_level_ads: true });  原型 str.split(str=\u0026#34;\u0026#34;, num=string.count(str)) |split()函数通过指定分隔符对字符串进行切片\n参数 若参数str无指定值。默认为所有的空字符，包括空格、\\n、\\t等\n若参数num有指定值，则分割num+1个子字符串，若无指定值，默认-1，即分隔所有\n返回值 返回分割后的字符串列表\n","date":"2019-09-16T20:13:56+08:00","permalink":"https://konosuba.xyz/blog/python_split%E5%87%BD%E6%95%B0/","title":"Python split()函数"},{"content":"在浏览Python官方文档时无意发现了这个彩蛋，只需在终端中import this\nThe Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! 中文翻译：\n优美胜于丑陋 明了胜于晦涩 简单胜于复杂 复杂胜于杂乱 扁平胜于嵌套 间隔胜于紧凑 可读性很重要 特例不足以特殊到违背这些原则 不要忽视错误，除非程序需要这样做 面对模棱两可，拒绝猜测 解决问题最直接的方法应该有一种，最好只有一种 可能这种方法一开始不够直接，因为你不是范罗苏姆 做也许好过不做，但不想就做还不如不做 如果方案难以描述明白，那么一定是个糟糕的方案 如果容易描述，那么可能是个好方案 命名空间是一种绝妙的理念，多加利用 感觉它虽然名为Zen of Python，但它可以是Zen of Each Code，这当中的绝大多数都是在编程时需要注意的\n还在豆瓣发现了元创的个人翻译，它将其翻译为“蛇宗三字经”，粘贴在这里，原文地址：蛇宗三字经\nBeautiful is better than ugly. 美胜丑 Explicit is better than implicit. 明胜暗 Simple is better than complex. 简胜复 Complex is better than complicated. 复胜杂 Flat is better than nested. 浅胜深 Sparse is better than dense. 疏胜密 Readability counts. 辞达意 Special cases aren't special enough to break the rules. 不逾矩 Although practicality beats purity. 弃至清 Errors should never pass silently. 无阴差 Unless explicitly silenced. 有阳错 In the face of ambiguity, refuse the temptation to guess. 拒疑数 There should be one-- and preferably only one --obvious way to do it. 求完一 Although that way may not be obvious at first unless you're Dutch. 虽不至，向往之 Now is better than never. 敏于行 Although never is often better than *right* now. 戒莽撞 If the implementation is hard to explain, it's a bad idea. 差难言 If the implementation is easy to explain, it may be a good idea. 好易说 Namespaces are one honking great idea -- let's do more of those! 每师出，多有名 ","date":"2019-09-07T21:07:51+08:00","permalink":"https://konosuba.xyz/blog/zen_of_python/","title":"Zen of Python -Python之禅"},{"content":"Python内置了读写文件的函数，用法与C兼容\n读文件 open() 使用内置的open()函数，传入文件名和标识符：\n\u0026gt;\u0026gt;\u0026gt; f = open(\u0026#39;test.txt\u0026#39;, \u0026#39;r\u0026#39;) 若文件不存在，open()函数会抛出一个IOError的错误，并给出错误码和详细信息\nTraceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; FileNotFoundError: [Errno 2] No such file or directory: \u0026#39;test.txt\u0026#39; read() 打开成功后，使用read()一次性读取文件的全部内容，Python将内容读到内存中，用str对象存储\nreadline() |readline()可以每次读取一行的内容\nreadlines() |readlines()一次读取所有内容并按行返回list\nclose() 使用完毕后，需要调用close()关闭文件\nwith语句 为避免忘记调用close()，Python引入with语句自动调用close()\nwith open(\u0026#39;test.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: print(f.read()) 写文件 与读文件类似，唯一区别是传入标识符'w'或'wb'表示写文本文件或写二进制文件\n所有标识符定义及其意义见官方文档\nfile-like Object (file object文件对象) 在Python中，像open()函数返回的这种有read()或write()方法的对象统称为file-like Object（或file object）\n共有三种类别的文件对象：原始二进制文件, 缓冲二进制文件 以及 文本文件，创建文件对象的规范方式是使用open()函数。\n","date":"2019-09-07T20:31:38+08:00","permalink":"https://konosuba.xyz/blog/python%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","title":"Python文件操作"},{"content":"Python中可以使用断言assert,logging等来进行调试\n断言 def fun(s): n = int(s) assert n != 0, \u0026#39;n is zero!\u0026#39; return 10 / n def main(): fun(\u0026#39;0\u0026#39;) 若assert后面的语句不为True，则assert会抛出异常AssertionError，并显示后一句'n is zero':\nTraceback (most recent call last): File \u0026#34;hello.py\u0026#34;, line 12, in \u0026lt;module\u0026gt; main() File \u0026#34;hello.py\u0026#34;, line 9, in main fun(\u0026#39;0\u0026#39;) File \u0026#34;hello.py\u0026#34;, line 4, in fun assert n != 0, \u0026#39;n is zero!\u0026#39; AssertionError: n is zero! 在我们不需要使用assert时可以在启动Python解释器时，添加-O(大写字母O)参数来关闭断言：\n..path:\u0026gt; python -O hello.py Traceback (most recent call last): File \u0026#34;hello.py\u0026#34;, line 12, in \u0026lt;module\u0026gt; main() File \u0026#34;hello.py\u0026#34;, line 9, in main fun(\u0026#39;0\u0026#39;) File \u0026#34;hello.py\u0026#34;, line 5, in fun return 10 / n ZeroDivisionError: division by zero 关闭后，解释器将忽略assert，可以把它看作pass\nlogging 和assert相比，logging不会抛出错误，允许指定要输出错误的级别（debug,info,warning,error等）\nimport logging # 指定输出错误级别为INFO logging.basicConfig(level=logging.INFO) s = \u0026#39;0\u0026#39; n = int(s) logging.info(\u0026#39;n=%d\u0026#39; % n) print(10/n) 运行结果：\nINFO:root:n=0 Traceback (most recent call last): File \u0026#34;hello.py\u0026#34;, line 9, in \u0026lt;module\u0026gt; print(10/n) ZeroDivisionError: division by zero 在指定输出等级后，其余等级就不起作用，方便控制\n此外，logging可以将语句输出到不同地方，如console和文件\npdb pdb(The Python Debugger)是Python内置的调试器，可以让程序单步运行\n控制台中使用 在启动Python解释器时附带参数-m pdb，程序会开始单步运行，等待下一指令：\n..path:\u0026gt; python -m pdb hello.py \u0026gt; c:\\users\\1\\documents\\c\\python\\hello.py(2)\u0026lt;module\u0026gt;() -\u0026gt; import logging #定位下一步要执行的代码 (Pdb) #等待指令 常用指令： |h(elp) [command] 无参数时打印所有操作，有则打印相应操作帮助\n|l(ist) 查看所有代码\n|n(ext) 单步执行代码\n|p 变量名 查看变量\n|c(ont(inue)) 继续执行，直到遇到断点\n|q(uit) 结束调试\n更多见官方文档\npdb.set_trace() 首先import pdb，在代码可能出错的地方放置pdb.set_trace()即可设置断点\nimport pdb s = \u0026#39;0\u0026#39; n = int(s) pdb.set_trace() # 运行到这里会自动暂停 print(10 / n) ","date":"2019-09-07T19:08:46+08:00","permalink":"https://konosuba.xyz/blog/python%E8%B0%83%E8%AF%95/","title":"Python调试"},{"content":"在Python中也同样使用try...except...finally...的错误处理机制\ntry except try: print(\u0026#39;try...\u0026#39;) r = 10/0 print(\u0026#39;result:\u0026#39;, r) except ZeroDivisionError as e: print(\u0026#39;except:\u0026#39;, e) finally: print(\u0026#39;finally...\u0026#39;) print(\u0026#39;END\u0026#39;) 当认为某一块代码有错误时，就可以用try来运行该段代码，若执行出错，则后续代码不会执行，而会跳转到except块，执行完except后，若后续有finally片段，则执行finally块\n上面的代码中有一个除0的错误，运行结果:\ntry... except: division by zero finally... END 当计算r后，捕捉到ZeroDivisionError错误，执行\texcept语句段，之后执行finally\nelse 可以在except后面加上else，当没有错误发生时将执行else语句块\ntry: print(\u0026#39;try...\u0026#39;) r = 10/5 print(\u0026#39;result:\u0026#39;, r) except ZeroDivisionError as e: print(\u0026#39;except:\u0026#39;, e) else: print(\u0026#39;no error\u0026#39;) print(\u0026#39;END\u0026#39;) 结果:\ntry... result: 2.0 no error END  Python的错误是一个class，所有错误类型都继承自BaseException，故使用except时需注意它会也会捕获该类型的子类。\n  常见错误类型及继承关系（中文）：官方文档\n  ## 优势 使用```try...except```捕获错误还有一个巨大的好处，就是可以跨越多层调用，比如函数```main()```调用```fun()```，```fun()```调用```bar()```，结果```bar()```出错了，这时，只要```main()```捕获到了，就可以处理 ​```py def fun(s): return 10/int(s) def bar(s): return fun(s) * 2 def main(): try: print('try...') bar('0') except Exception as e: print('Error:', e) finally: print('finally...') 结果:\ntry... Error: division by zero finally... 栈输出 若错误没有被捕捉，会一直往上抛，最终会被Python解释器捕获，打印一个错误信息，之后程序会退出\n文件hello.py\ndef fun(s): return 10/int(s) def bar(s): return fun(s) * 2 def main(): bar(\u0026#39;0\u0026#39;) main() 在Python终端中运行文件，输出：\nTraceback (most recent call last): #错误跟踪信息 File \u0026#34;hello.py\u0026#34;, line 19, in \u0026lt;module\u0026gt; main() #错误原因 File \u0026#34;hello.py\u0026#34;, line 13, in main bar(\u0026#39;0\u0026#39;) File \u0026#34;hello.py\u0026#34;, line 7, in bar return fun(s) * 2 File \u0026#34;hello.py\u0026#34;, line 3, in fun return 10/int(s) ZeroDivisionError: division by zero #错误类型 错误信息以栈的形式按顺序输出，由此可以找到错误源头\n错误记录 可以使用Python内置的logging模块记录错误信息\nimport logging def fun(s): return 10/int(s) def bar(s): return fun(s) * 2 def main(): try: print(\u0026#39;try...\u0026#39;) bar(\u0026#39;0\u0026#39;) except BaseException as e: logging.exception(e) finally: print(\u0026#39;finally...\u0026#39;) 这样运行，程序会在打印完错误信息后继续运行：\ntry... ERROR:root:division by zero Traceback (most recent call last): File \u0026#34;hello.py\u0026#34;, line 16, in main bar(\u0026#39;0\u0026#39;) File \u0026#34;hello.py\u0026#34;, line 10, in bar return fun(s) * 2 File \u0026#34;hello.py\u0026#34;, line 6, in fun return 10/int(s) ZeroDivisionError: division by zero finally... 抛出错误 常常使用raise函数抛出错误，当前函数不知道怎么处理错误时，将其向上抛，交给上层函数来处理\n|raise语句如果不带参数，就会把当前错误原样抛出。此外在except中raise一个Error，还可以把一种类型的错误转化成另一种类型：\ntry: 10 / 0 except ZeroDivisionError: raise ValueError(\u0026#39;input error!\u0026#39;) 只要是合理的转换逻辑即可，但绝不应该将一个IOError转换成毫不相干的ValueError\n","date":"2019-09-06T19:14:26+08:00","permalink":"https://konosuba.xyz/blog/python%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/","title":"Python错误处理"},{"content":"使用树莓派原装CSI摄像头录制视频并利用灰度重心法获取重心，将图像和重心数据通过Socket实时传输到电脑上\n因为需要实现程序一启动便打开摄像头计算数据，同时启动Socket服务器等待客户端连接，所以利用C++11中的thread库通过多线程实现程序\n树莓派-服务端 #include \u0026lt;iostream\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;cstring\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;sys/types.h\u0026gt;#include \u0026lt;sys/socket.h\u0026gt;#include \u0026lt;netinet/in.h\u0026gt;#include \u0026lt;arpa/inet.h\u0026gt;#include \u0026lt;thread\u0026gt;#include \u0026lt;opencv2/opencv.hpp\u0026gt;using namespace cv; using namespace std; #define USEPORT 1234 #define T 20 Mat FRAME; Point PCENTER; //灰度重心法函数 Point gray_center(Mat\u0026amp; img) { Mat img_gray; cvtColor(img, img_gray, COLOR_BGR2GRAY, 0); Point Center; double sumval = 0; MatIterator_\u0026lt;uchar\u0026gt; it, end; for (int i = 0; i \u0026lt; img_gray.cols; i++) { for (int j = 0; j \u0026lt; img_gray.rows; j++) { double s = img_gray.at\u0026lt;uchar\u0026gt;(j, i); if (s \u0026lt; T) s = 0; sumval += s; } } Center.x = Center.y = 0; double x = 0, y = 0; for (int i = 0; i \u0026lt; img_gray.cols; i++) { for (int j = 0; j \u0026lt; img_gray.rows; j++) { double s = img_gray.at\u0026lt;uchar\u0026gt;(j, i); if (s \u0026lt; T) s = 0; x += i * s / sumval; y += j * s / sumval; } } Center.x = cvRound(x); Center.y = cvRound(y); return Center; } //摄像头图像处理 void cam_stand_by() { VideoCapture capture; if (!capture.isOpened()) { cout \u0026lt;\u0026lt; \u0026#34;fail to open camera!\u0026#34; \u0026lt;\u0026lt; endl; exit(-1); } while (1) { capture \u0026gt;\u0026gt; FRAME; PCENTER = gray_center(FRAME); if (waitKey(30) \u0026gt;= 0) break; } } int main() { //开启一个线程，并将其分离,使不阻塞主程序 \tthread cam_th(cam_stand_by); cam_th.detach(); //启动服务端 \tint serverSock = socket(AF_INET, SOCK_STREAM, 0); if (serverSock \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;socket creation failed\u0026#34; \u0026lt;\u0026lt; endl; exit(-1); } cout \u0026lt;\u0026lt; \u0026#34;socket creation successfully\u0026#34; \u0026lt;\u0026lt; endl; struct sockaddr_in serverAddr; memset(\u0026amp;serverAddr, 0, sizeof(serverAddr)); serverAddr.sin_family = AF_INET; serverAddr.sin_port = htons(USEPORT); serverAddr.sin_addr.s_addr = htonl(INADDR_ANY); if (bind(serverSock, (struct sockaddr*)\u0026amp;serverAddr, sizeof(struct sockaddr)) == -1) { cout \u0026lt;\u0026lt; \u0026#34;Bind error, Port[\u0026#34;\u0026lt;\u0026lt; USEPORT \u0026lt;\u0026lt; \u0026#34;]\u0026#34; \u0026lt;\u0026lt; endl; exit(-1); } cout \u0026lt;\u0026lt; \u0026#34;Bind successfully\u0026#34; \u0026lt;\u0026lt; endl; if (listen(serverSock, 10) == -1) { cout \u0026lt;\u0026lt; \u0026#34;Listen error!\u0026#34; \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; \u0026#34;Listening on port[\u0026#34; \u0026lt;\u0026lt; USEPORT \u0026lt;\u0026lt; \u0026#34;]\u0026#34; \u0026lt;\u0026lt; endl; while (1) { struct sockaddr clientAddr; int size = sizeof(struct sockaddr); int clientSock = accept(serverSock, (struct sockaddr*)\u0026amp;clientAddr, (socklen_t*)\u0026amp;size); cout \u0026lt;\u0026lt; \u0026#34;\\n****NEW client touched****\u0026#34; \u0026lt;\u0026lt; endl; while (1) { if (send(clientSock, FRAME.data, FRAME.total()*FRAME.elemSize(), 0) \u0026lt; 0) break; send(clientSock, \u0026amp;PCENTER, sizeof(Point), 0); } cout \u0026lt;\u0026lt; \u0026#34;\\n==== CLIENT BREAK ====\u0026#34; \u0026lt;\u0026lt; endl; close(clientSock); } close(serverSock); return 0; } PC-客户端 #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;opencv2/opencv.hpp\u0026gt; //包含opencv#include \u0026lt;WinSock2.h\u0026gt; //包含WinSock2.h头文件using namespace std; using namespace cv; #pragma comment(lib, \u0026#34;ws2_32.lib\u0026#34;) //加载 ws2_32.dll #pragma warning(disable:4996) #define imgSize 640*480*3 //图像大小，由于传输三通道彩色图，所以*3 //有尝试过每次由树莓派先传输图像大小到客户端，但出现了一些问题，所以直接在这里定义宏 constexpr auto RASPI_IP = \u0026#34;192.168.1.119\u0026#34;; int main() { //****初始化 \tWSADATA wsaData; WSAStartup(MAKEWORD(2, 2), \u0026amp;wsaData); //****创建套接字 \tSOCKET sock = socket(PF_INET, SOCK_STREAM, 0); //****创建sockAddr结构体 \tsockaddr_in sockAddr; memset(\u0026amp;sockAddr, 0, sizeof(sockAddr)); sockAddr.sin_family = PF_INET; sockAddr.sin_port = htons(1234); sockAddr.sin_addr.s_addr = inet_addr(RASPI_IP); //树莓派的局域网IP  //****建立连接 \tconnect(sock, (SOCKADDR*)\u0026amp; sockAddr, sizeof(SOCKADDR)); cout \u0026lt;\u0026lt; \u0026#34;客户端发送链接请求\u0026#34; \u0026lt;\u0026lt; endl; int bytes = 0; //****接收服务器传回的数据\t\twhile (1) { cout \u0026lt;\u0026lt; \u0026#34;等待服务端发送信息..\u0026#34; \u0026lt;\u0026lt; endl; char* imgdata = new char[imgSize]; char* pointdata = new char[MAXBYTE]; //recv(sock, imgdata, imgSize, NULL); \t//若直接使用recv接收，会有丢包情况出现，图片不完整 \tfor (int i = 0; i \u0026lt; imgSize; i += bytes) //循环接收图片信息，防止没接收完 \t{ if ((bytes = recv(sock, imgdata + i, imgSize - i, 0)) == -1) { cout \u0026lt;\u0026lt; \u0026#34;Fail to recive\u0026#34; \u0026lt;\u0026lt; endl; exit(-1); } } recv(sock, pointdata, sizeof(Point), NULL); //接收重心Point信息 \tPoint* tack = (Point*)pointdata; Point center(tack-\u0026gt;x, tack-\u0026gt;y); cout \u0026lt;\u0026lt; tack-\u0026gt;x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; tack-\u0026gt;y \u0026lt;\u0026lt; endl; Mat img(Size(640, 480), CV_8UC3, imgdata); circle(img, center, 6, Scalar(0, 255, 0), -1); imshow(\u0026#34;Gray_Center\u0026#34;, img); waitKey(1); } //关闭套接字、终止使用 DLL \tclosesocket(sock); WSACleanup(); return 0; } 最终效果 ","date":"2019-07-09T15:32:53+08:00","permalink":"https://konosuba.xyz/blog/%E5%88%A9%E7%94%A8opencv%E4%B8%8Esocket%E5%AE%9E%E7%8E%B0%E6%A0%91%E8%8E%93%E6%B4%BE%E8%8E%B7%E5%8F%96%E6%91%84%E5%83%8F%E5%A4%B4%E8%A7%86%E9%A2%91%E5%92%8C%E7%81%B0%E5%BA%A6%E9%87%8D%E5%BF%83%E5%8F%91%E9%80%81%E5%88%B0%E7%94%B5%E8%84%91/","title":"利用opencv与Socket实现树莓派获取摄像头视频和灰度重心发送到电脑"},{"content":"本文主要内容为树莓派与PC在局域网内的基于TCP的Socket通信，由于树莓派是Linux系统，而PC是Windows系统，所以要注意一些区别\n这里将树莓派作为服务器端，PC作为客户端，连接后服务端向客户端发送信息\n服务端-树莓派 socket_server_sms.cpp #include \u0026lt;iostream\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;cstring\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;sys/types.h\u0026gt;#include \u0026lt;sys/socket.h\u0026gt;#include \u0026lt;netinet/in.h\u0026gt;#include \u0026lt;arpa/inet.h\u0026gt;using namespace std; #define USEPORT 1234  int main() { //****创建套接字 \tint serverSock = socket(AF_INET, SOCK_STREAM, 0); //Windows中，AF_INET==PF_INET \t//Linux中，不同的版本这两者有微小差别.对于BSD是AF,对于POSIX是PF \tif (serverSock \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;socket creation failed\u0026#34; \u0026lt;\u0026lt; endl; exit(-1); } cout \u0026lt;\u0026lt; \u0026#34;socket creation successfully\u0026#34; \u0026lt;\u0026lt; endl; //****绑定ip和端口 \tstruct sockaddr_in serverAddr; memset(\u0026amp;serverAddr, 0, sizeof(serverAddr)); serverAddr.sin_family = AF_INET; serverAddr.sin_port = htons(USEPORT); //INADDR_ANY绑定所有IP \tserverAddr.sin_addr.s_addr = htonl(INADDR_ANY); //****绑定套接字 \tif (bind(serverSock, (struct sockaddr*)\u0026amp;serverAddr, sizeof(struct sockaddr)) == -1) { cout \u0026lt;\u0026lt; \u0026#34;Bind error, Port[\u0026#34;\u0026lt;\u0026lt; USEPORT \u0026lt;\u0026lt; \u0026#34;]\u0026#34; \u0026lt;\u0026lt; endl; exit(-1); } cout \u0026lt;\u0026lt; \u0026#34;Bind successfully\u0026#34; \u0026lt;\u0026lt; endl; //****监听 \tif (listen(serverSock, 10) == -1) { cout \u0026lt;\u0026lt; \u0026#34;Listen error!\u0026#34; \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; \u0026#34;Listening on port[\u0026#34; \u0026lt;\u0026lt; USEPORT \u0026lt;\u0026lt; \u0026#34;]\u0026#34; \u0026lt;\u0026lt; endl; //****开始接收accept() \tstruct sockaddr clientAddr; int size = sizeof(struct sockaddr); int clientSock = accept(serverSock, (struct sockaddr*)\u0026amp;clientAddr, (socklen_t*)\u0026amp;size); cout \u0026lt;\u0026lt; \u0026#34;****NEW client touched****\u0026#34; \u0026lt;\u0026lt; endl; //****通信 \twhile (1) { string input; cout \u0026lt;\u0026lt; \u0026#34;input something (\u0026#39;quit\u0026#39; to shutdown)\u0026#34; \u0026lt;\u0026lt; endl; cin \u0026gt;\u0026gt; input; send(clientSock, input.c_str(), input.length(), 0); if (input == \u0026#34;quit\u0026#34;) { cout \u0026lt;\u0026lt; \u0026#34;shutdown\u0026#34;\u0026lt;\u0026lt;endl; break; } } close(serverSock); return 0; } 客户端-PC socket_client_raspi.cpp #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;WinSock2.h\u0026gt; //包含WinSock2.h头文件using namespace std; #pragma comment(lib, \u0026#34;ws2_32.lib\u0026#34;) //加载 ws2_32.dll #pragma warning(disable:4996)  int main() { //****初始化 \tWSADATA wsaData; WSAStartup(MAKEWORD(2, 2), \u0026amp;wsaData);\t//****创建套接字 \tSOCKET sock = socket(PF_INET, SOCK_STREAM, 0); //****创建sockAddr结构体 \tsockaddr_in sockAddr;\tmemset(\u0026amp;sockAddr, 0, sizeof(sockAddr));\tsockAddr.sin_family = PF_INET; sockAddr.sin_port = htons(1234); sockAddr.sin_addr.s_addr = inet_addr(RASPI_IP); //树莓派的局域网IP  //****建立连接 \tconnect(sock, (SOCKADDR*)\u0026amp; sockAddr, sizeof(SOCKADDR));\tcout \u0026lt;\u0026lt; \u0026#34;客户端发送链接请求\u0026#34; \u0026lt;\u0026lt; endl; //****接收服务器传回的数据\t\twhile (1) { cout \u0026lt;\u0026lt; \u0026#34;等待服务端发送信息..\u0026#34; \u0026lt;\u0026lt; endl; char tack[MAXBYTE] = { 0 }; recv(sock, tack, MAXBYTE, NULL); //输出接收到的数据 \tcout \u0026lt;\u0026lt; \u0026#34;服务器: \u0026#34; \u0026lt;\u0026lt; tack \u0026lt;\u0026lt; endl; if (strcmp(tack, \u0026#34;quit\u0026#34;) == 0) { cout \u0026lt;\u0026lt; \u0026#34;shutdown\u0026#34; \u0026lt;\u0026lt; endl; break; } } //关闭套接字、终止使用 DLL \tclosesocket(sock); WSACleanup(); return 0; } 运行测试 在树莓派编译运行socket_server_sms.cpp，开始监听\ncmake . make ./socket_server_sms PC编译运行socket_client_raspi.cpp\n服务端发送信息测试\n测试成功\n 树莓派与计算机简单通信成功，接下来是通过树莓派传送摄像头图像和使用灰度重心法找到的光斑中心信息到计算机\n","date":"2019-07-08T15:38:20+08:00","permalink":"https://konosuba.xyz/blog/socket%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%863/","title":"Socket通信原理(3)"},{"content":"本文主要是在计算机本地使用基于TCP协议的Socket建立服务端与客户端的连接与基本通信\n 系统：Windows 10\n  软件：Visual studio 2019\n  语言：C++\n  Socket通信实现步骤   创建ServerSocket和Socket\n  打开连接到的Socket的输入/输出流\n  按照协议对Socket进行读/写操作\n  关闭输入/输出流和Socket\n  本文的程序由服务端发送信息到客户端，若用户输入quit则结束客户端与服务端程序\n服务端Server 由于Windows下的socket程序依赖Winsock.dll或ws2_32.dll，所以必须提前加载\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;winsock2.h\u0026gt; //包含socket的头文件#pragma comment (lib, \u0026#34;ws2_32.lib\u0026#34;)\t//加载 ws2_32.dll #pragma warning(disable:4996) using namespace std; int main() { //****初始化WSA \tWSADATA wsaData;\t//初始化WSAStartup()函数(规范的版本号，指向WSADATA结构体的指针)，向操作系统说明要使用哪个库的文件 \t//-\u0026gt;MSKEWORD(2,2)主版本号2，副版本号2 \tif (WSAStartup(MAKEWORD(2, 2), \u0026amp;wsaData) != 0)\t{\treturn 0; } //****创建套接字 \tSOCKET servSock = socket(PF_INET, SOCK_STREAM, 0); //参数1，IP地址类型,PF_INET6-\u0026gt;IPv6，PF_INET-\u0026gt;IPv4 \t//参数2，数据传输方式,SOCK_STREAM 和 SOCK_DGRAM \t//参数3，传输协议,IPPROTO_TCP 和 IPPTOTO_UDP,写0系统会自动计算处使用那种协议 \t//判断无效套接字 \tif (servSock == INVALID_SOCKET) { cout \u0026lt;\u0026lt; \u0026#34;socket error!\u0026#34; \u0026lt;\u0026lt; endl; return 0; } //****绑定ip和端口 \t//创建sockaddr_in结构体变量(in指internet) \tsockaddr_in sockAddr; //每个字节都用0填充 \tmemset(\u0026amp;sockAddr, 0, sizeof(sockAddr));\t//使用IPv4地址 \tsockAddr.sin_family = PF_INET; //设置端口号，用htons()函数转换 \tsockAddr.sin_port = htons(1234); //具体的IP地址,32位 \tsockAddr.sin_addr.s_addr = inet_addr(\u0026#34;127.0.0.1\u0026#34;); //****绑定套接字bind() \t//参数1，socket服务器端套接字变量 \t//参数2，sockaddr结构体变量的指针，sockaddr_in强转 \t//参数3，参数2变量的大小，一般使用sizeof()计算 \tif (bind(servSock, (SOCKADDR*)\u0026amp; sockAddr, sizeof(SOCKADDR)) == SOCKET_ERROR) { cout \u0026lt;\u0026lt; \u0026#34;bind error!\u0026#34; \u0026lt;\u0026lt; endl; return 0; } cout \u0026lt;\u0026lt; \u0026#34;绑定套接字成功！\u0026#34; \u0026lt;\u0026lt; endl; //****开始监听listen() \t//5-最大排队数 \t//listen()只让套接字进入监听状态，并没有真正接收请求 \tif (listen(servSock, 5) == SOCKET_ERROR) { cout \u0026lt;\u0026lt; \u0026#34;listen error!\u0026#34; \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; \u0026#34;服务器已经进入监听状态..\u0026#34; \u0026lt;\u0026lt; endl; //****接收客户端请求accept() \t//参数与bind()相同 \t//accept()会阻塞程序进行，直到有新的请求到来 \t//返回一个新的套接字来和客户端通信，后面使用新的套接字通信 \tSOCKADDR clntAddr; int nSize = sizeof(SOCKADDR); SOCKET clntSock = accept(servSock, (SOCKADDR*)\u0026amp; clntAddr, \u0026amp;nSize); cout \u0026lt;\u0026lt; \u0026#34;accept函数执行完毕开始接收用户输入\u0026#34; \u0026lt;\u0026lt; endl; //****开始通信 \twhile (1) {\tcout \u0026lt;\u0026lt; \u0026#34;输入一句话并按回车(quit退出)\u0026#34; \u0026lt;\u0026lt; endl; string input; cin \u0026gt;\u0026gt; input; //向客户端发送数据 \tsend(clntSock, input.c_str(), input.length(), NULL); cout \u0026lt;\u0026lt; \u0026#34;数据发送成功\u0026#34; \u0026lt;\u0026lt; endl; //如果输入quit，断开连接 \tif (input == \u0026#34;quit\u0026#34;) break; } //关闭套接字 \tclosesocket(clntSock); closesocket(servSock); //终止 DLL 的使用 \tWSACleanup(); return 0; } 客户端Client #include \u0026lt;iostream\u0026gt;#include \u0026lt;WinSock2.h\u0026gt; //包含WinSock2.h头文件using namespace std; #pragma comment(lib, \u0026#34;ws2_32.lib\u0026#34;) //加载 ws2_32.dll #pragma warning(disable:4996)  int main() { //****初始化WSA \tWSADATA wsaData; //初始化版本 \tWSAStartup(MAKEWORD(2, 2), \u0026amp;wsaData);\t//****创建用户端socket\t\tSOCKET sock = socket(PF_INET, SOCK_STREAM, 0);\t//****创建sockAddr结构体 \tsockaddr_in sockAddr; //每个字节都用0填充 \tmemset(\u0026amp;sockAddr, 0, sizeof(sockAddr));\t//绑定服务器、端口\t\tsockAddr.sin_family = PF_INET; sockAddr.sin_port = htons(1234); sockAddr.sin_addr.s_addr = inet_addr(\u0026#34;127.0.0.1\u0026#34;); //****建立链接 \tconnect(sock, (SOCKADDR*)\u0026amp;sockAddr, sizeof(SOCKADDR)); cout \u0026lt;\u0026lt; \u0026#34;客户端发送链接请求\u0026#34; \u0026lt;\u0026lt; endl; //****接收服务器传回的数据 \twhile (1) { char szBuffer[MAXBYTE] = { 0 }; recv(sock, szBuffer, MAXBYTE, NULL); if (strcmp(szBuffer, \u0026#34;quit\u0026#34;) == 0) break; cout \u0026lt;\u0026lt; \u0026#34;接受服务器传回的消息函数\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; szBuffer \u0026lt;\u0026lt; endl; } //****关闭套接字、终止使用 DLL \tclosesocket(sock); WSACleanup(); return 0; } 运行测试 先运行服务器端，再运行客户端\n启动服务端：\n启动客户端,连接成功\n发送信息测试：\n输入quit，客户端和服务端均结束\n 实现成功，接下来要测试树莓派与PC在局域网内的Socket通信\n","date":"2019-07-08T13:21:57+08:00","permalink":"https://konosuba.xyz/blog/socket%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%862/","title":"Socket通信原理(2)"},{"content":"最近在捣鼓树莓派，实验室要用树莓派做图像处理后回传数据到计算机，所以开始学习socket相关知识，这一篇文章主要是计算机网络通信基础。\nTCP/IP、UDP 在开始之前，先听两个笑话😏\nTCP\n\u0026gt; “嗨，我想听一个 TCP 的笑话。” //第一次握手 \u0026gt; “你好，你想听 TCP 的笑话么？” //第二次握手 \u0026gt; “嗯，我想听一个 TCP 的笑话。” //第三次握手 \u0026gt; “好的，我会给你讲一个TCP 的笑话。” \u0026gt; “好的，我会听一个TCP 的笑话。” \u0026gt; “你准备好听一个TCP 的笑话么？” \u0026gt; “嗯，我准备好听一个TCP 的笑话” \u0026gt; “OK，那我要发 TCP 笑话了。大概有 10 秒，20 个字。” \u0026gt; “嗯，我准备收你那个 10 秒时长，20 个字的笑话了。” \u0026gt; “抱歉，你的链接超时了。你好，你想听 TCP 的笑话么？” UDP\n\u0026gt; 我给你们讲个UDP的笑话吧！ \u0026gt; 我给你们讲个UDP的笑话吧！ \u0026gt; 我给你们讲个UDP的笑话吧！ \u0026gt; 我给你们讲个UDP的笑话吧！ 学完之后，发现这两个笑话很好的表示出了两种协议的通信方式，来看看\nTCP/IP，即传输控制协议/网间协议，是互联网相关各类协议族的总称，比如：TCP，UDP，IP，FTP，HTTP，ICMP，SMTP 等都属于 TCP/IP 族内的协议。UDP是与TCP相对应的协议，属于TCP/IP协议族中的一种\nOSI七层模型 OSI是一个理想的模型，一般的网络系统只涉及其中的几层，在七层模型中，每一层都提供一个特殊 的网络功能。\n从网络角度观察：\n  下面四层（物理层、数据链路层、网络层和传输层）主要提供数据传输和交换功能， 即以节点到节点之间的通信为主\n  第四层作为上下两部分的桥梁，是整个网络体系结构中最关键的部分\n  上三层（会话层、表示层和应用层）则以提供用户与应用程序之间的信息和数据处理功能为主。\n  简言之，下4层主要完成通信子网的功能，上3层主要完成资源子网的功能\n协议关系 TCP/IP协议族包括应用层、运输层、网络层、链路层，分层后设计相对简单\n数据链路层负责接收IP数据包并通过网络发送，或从网络上接受物理帧，抽出IP数据包，交给IP层\n网络层负责相邻计算机之间的通信，功能包括：\n  处理来自传输层的分组发送请求，收到请求后，将分组装入IP数据报，填充报头，选择去往信宿机的路径，然后将数据报发往适当的网络接口     处理剩下的数据报，首先检查其合法性，然后进行寻径–假如该数据报已到达信宿机，则去掉报头，将剩下部分交给适当的传输协议；假如该数据报尚未到达信宿，则转发该数据报     处理路径、流控、拥塞等问题   传输层提供应用程序间的通信，功能包括：\n  格式化信息流     提供可靠传输，TCP和UDP协议就是为了实现这个而存在   应用层为用户提供常用应用程序\nTCP TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。\nTCP为了保证报文传输的可靠，给每个包一个序号，同时序号保证了传送到接收端实体的包的按序接受\n接收端实体对已成功收到的字节发回一个相应的确认（ACK）， 如果发送端实体在合理的往返时延（RTT）内未收到确认，则对应数据将会被重传\n建立连接 使用三次握手协议建立连接，就如前面的笑话开始时的交流确认，客户端和服务端总共发送3个包以确认连接的建立\n  第一次握手：客户端SYN标志位置为1，随机产生一个值seq=J，并将该数据报发送给服务端，客户端进入SYS_SENT状态，等待服务端确认\n  第二次握手：服务端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务端将标志位、SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务端进入SYN_RCVD状态。\n  第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，若正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务端，服务端检查ack是否为K+1，如果正确则连接建立成功，客户端和服务端进入ESTABLISHED状态，完成三次握手，随后就可以传输数据了\n  断开连接 断开一个TCP连接，需要客户端和服务端总共发送4个包以确认连接的断开。在Socket编程中，这一过程由客户端或服务端任一方执行close来触发，又称四次挥手\n  第一次挥手：客户端发送一个FIN，用来关闭客户端到服务端的数据传送，客户端进入FIN_WAIT_1状态\n  第二次挥手：服务端收到FIN后，发送一个ACK给客户端，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），服务端进入CLOSE_WAIT状态\n  第三次挥手：服务端发送一个FIN，用来关闭服务端到客户端的数据传送，服务端进入LAST_ACK状态\n  第四次挥手：客户端收到FIN后，客户端进入TIME_WAIT状态，紧接着发送一个ACK到服务端，确认序号为收到序号+1,服务端进入CLOSED状态，完成四次挥手\n  UDP 非连接的协议，传输数据之前源端与终端不建立连接，当它想传送时就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。\n在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽 的限制\n在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。\n相比TCP就是无需建立链接，结构简单，无法保证正确性，容易丢包\n Socket 前面的图中没有Socket存在，看下图：\nSocket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。\n**服务器端：**服务端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。\n**客户端：**若有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，连接建立。\n客户端发送数据请求，服务端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束\n 理论学习基本完成，接下来在计算机本地实现通信\n","date":"2019-07-07T11:24:59+08:00","permalink":"https://konosuba.xyz/blog/socket%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%861/","title":"Socket通信原理(1)"},{"content":"注意：树莓派插电时千万不要插拔摄像头！据说十有八九摄像头会GG，我差点就中招了\n安装驱动 首先使用ls指令查看是否加载到了对应的video device设备：\nls -al /etc 没有看到设备开始安装驱动\n添加驱动设备到文件夹 sudo vim /etc/modules 在文件末尾添加\nbcm2835-v412 修改raspberry的启动配置 进入管理中心开启pi camera\nsudo raspi-config 选择interfacing option\n开启Camera后重启\n检查/dev ls -al /dev/ | grep video 有video设备则成功\n使用树莓派摄像头 使用raspistill指令\n测试 raspistill -o image.jpg  在使用hdml线连接lcd屏和树莓派时运行，显示屏会显示几秒钟摄像头的实时画面，但使用VNC连接时并不会有实时画面\n raspistill相关  -v：查看调试信息 -w：图像宽度 -h：图像高度 -rot：图像旋转角度，仅支持0，90，180，270度 -o：图像输出地址，若文件名为'-'，将输出发送至标准输出设备 -t：获取图像前等待时间，默认为5000，即5秒 -tl：多久执行一次图像抓取  生成.h246文件 raspistill -o mykeychain.h264 -t 10000 -w 1280 -h 720 错误 在第一次成功调用后，之后再次调用时多次报错：\nmmal: No data received from sensor. Check all connections, including the Sunny one on the camera board 网上说导致该问题的原因有：\n 摄像头sunny部分是否连接牢靠 摄像头是否插紧 最可能：在树莓派带电的时候插拔摄像头，导致管脚烧坏了。这个时候就需要找到是哪个管脚烧坏了，然后补焊一下，加点阻焊剂；  最开始不知道不能热插拔，带点插拔了两三次，不过幸好后面关机重新插了之后就正常了，差点就是血的教训了\nVLC实现http视频流传输 在树莓派输入如下命令\nsudo raspivid -o - -t 0 -w 640 -h 360 -fps 25|cvlc -vvv stream:///dev/stdin --sout \u0026#39;#standard{access=http,mux=ts,dst=:8090}\u0026#39; :demux=h264 意思：使用PI官方的raspivid捕获视频工具把视频流输出到vlc，通过vlc转码成h264网络视频流通过http协议以ts的形式封装，然后输出到8090端口，用这个当监控只要网络稳定绝对不卡。\n之后使用VLC客户端，网络串流:http://树莓派ip:8090即可，不过延迟较高，可能是因为我用的手机热点的原因，之后再试。\nopencv调用树莓派摄像头 配置好opencv后，就能使用opencv自带的videocapture调用摄像头\nC++调用 参考这里，成功调用\n代码：\nvoid OpenCamera() { //打开摄像头 \tVideoCapture capture; capture.open(0); //灰度图像 \tMat edge; //循环显示每一帧 \twhile (1) { //frame存储每一帧图像 \tMat frame; //读取当前帧 \tcapture \u0026gt;\u0026gt; frame; //显示当前视频 \timshow(\u0026#34;正在录制\u0026#34;, frame); //得到灰度图像 \tcvtColor(frame, edge, CV_BGR2GRAY); //3*3降噪 （2*3+1) \tblur(edge, edge,Size(7,7)); //边缘显示 \tCanny(edge,edge,0,30,3); imshow(\u0026#34;高斯模糊视频\u0026#34;,edge); } } 使用VNC连接时延迟较高，在使用HDMI显示屏时效果较好，延迟较低\nVNC连接：\nHDMI连接：\nPython调用 参考官网指南\n*本文参考：使用树莓派CSI摄像头时报错;树莓派3 B+ 的摄像头简单使用\n","date":"2019-07-01T15:27:39+08:00","permalink":"https://konosuba.xyz/blog/%E6%A0%91%E8%8E%93%E6%B4%BE%E9%85%8D%E7%BD%AE%E6%91%84%E5%83%8F%E5%A4%B4/","title":"树莓派配置摄像头"},{"content":"概念 对于亮度不均匀的目标（如光斑，光条纹），灰度重心法可按目标光强分布求出光强权重质心坐标作为跟踪点，也叫密度质心算法。\n将灰度值分布中的质心记作光条纹的中心\n对于M * N大小的图像f，像素的灰度值凡是超过阈值T的均参与重心处理，于是重心坐标为：\n灰度重心法公式 型心法 只可用于二值图像\n灰度重心法version 1 灰度重心法version 2 使用Visual Studio 2019测试 根据灰度重心法version 1找光斑中心\n代码：\n#define T 20 //根据实际情况设定固定阈值 Point grayCenter(Mat\u0026amp; img) { Mat img_gray; cvtColor(img, img_gray, COLOR_BGR2GRAY, 0); Point Center; //中心点 \tint i, j; double sumval = 0; MatIterator_\u0026lt;uchar\u0026gt; it, end; //获取图像各点灰度值总和 \tfor (it = img_gray.begin\u0026lt;uchar\u0026gt;(), end = img_gray.end\u0026lt;uchar\u0026gt;(); it != end; it++) { ((*it) \u0026gt; T) ? sumval += (*it) : NULL; //小于阈值，取0 \t} Center.x = Center.y = 0; double x = 0, y = 0; for (int i = 0; i \u0026lt; img_gray.cols; i++) { for (int j = 0; j \u0026lt; img_gray.rows; j++) { double s = img_gray.at\u0026lt;uchar\u0026gt;(j, i); //取当前点灰度值 \tif (s \u0026lt; T) s = 0; x += i * s / sumval; y += j * s / sumval; } } Center.x = cvRound(x); Center.y = cvRound(y); cout \u0026lt;\u0026lt; \u0026#34;rows=\u0026#34; \u0026lt;\u0026lt; img_gray.rows \u0026lt;\u0026lt; \u0026#34; cols=\u0026#34; \u0026lt;\u0026lt; img_gray.cols \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;x=\u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; y=\u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; return Center; } 运行结果:\n成功找到光斑中心（绿点）\n在树莓派上测试 同样，在树莓派上\ncmake . make 执行! 成功！\n","date":"2019-06-28T00:00:00Z","permalink":"https://konosuba.xyz/blog/%E7%81%B0%E5%BA%A6%E9%87%8D%E5%BF%83%E6%B3%95/","title":"灰度重心法"},{"content":"Shell脚本 是一种为shell编写的脚本程序\n使用文本编辑器既能编写，拓展名不影响脚本执行\n实例：\n#!/bin/bash echo \u0026#34;Hello World\u0026#34;  #!告诉系统这个脚本需要什么解释器执行\n 运行脚本 作为可执行程序 将代码保存后，给文件添加可执行权限+x\nchmod +x ./test.sh # ./test.sh #执行脚本 作为解释器参数 直接运行解释器，将文件作为其参数 这种方式不需要在文件开头指定解释器信息\n/bin/sh test.sh Shell变量 定义变量 your_name=\u0026#34;Tom\u0026#34; **注意：**等号不能有空格\n使用变量 在变量前加美元符号$ 还可在变量外添加大括号{}\necho $your_name echo ${your_name} 只读变量 使用readonly命令将变量定义为只读变量，值不能被改变\nurl=\u0026#34;baidu.com\u0026#34; readonly url 删除变量 使用unset变量删除变量\nunset url Shell字符串 可用单引号，或双引号，也可不用引号\n单引号  单引号内任何字符都会原样输出，单引号字符串中变量无效 单引号字符串中不能出现单独一个的单引号，但可成对出现  双引号  双引号里可以有变量 双引号里可以出现转义字符  拼接字符串 text1=\u0026#39;123\u0026#39; text2=\u0026#39;456\u0026#39; echo ${text1}${text2} #输出123456 字符串长度 str1=\u0026#34;abcd\u0026#34; echo ${#str1} #输出4 提取子字符串 从字符串第2个字符开始截取4个字符：\nstr2=\u0026#34;hello world\u0026#34; echo ${str2:1:4} #输出ello 查找子字符串 查找字符a或o的位置（哪个字母先出现就计算哪个）\nstr3=\u0026#34;how are you\u0026#34; echo `expr index \u0026#34;$str3\u0026#34; ao` #输出2 Shell数组 只支持一维数组\n定义数组 my_arr1=(1 2 \u0026#39;A\u0026#39; \u0026#34;BC\u0026#34;) my_arr2=( 1 \u0026#39;a\u0026#39; \u0026#34;cc\u0026#34; ) 读取数组 使用@符号获取数组中所有元素\necho ${my_arr1[@]} #输出1 2 A BC 数组长度 length=${#my_arr1[@]} length=${#my_arr2[*]} Shell传参 执行脚本时，向脚本传递参数，脚本内获取参数的格式为：$n，n代表数字，代表执行脚本的第n个参数，$0为执行的文件名\n实例 定义文件：\n#!/bin/bash  echo \u0026#34;执行的文件名: $0\u0026#34; echo \u0026#34;第一个参数: $1\u0026#34; echo \u0026#34;第二个参数: $2\u0026#34; 执行脚本：\n$ chmod +x text.sh $ ./test.sh 1 A 执行的文件名: ./test.sh 第一个参数: 1 第二个参数: A 特殊参数  $# 传递到脚本的参数个数 $* 以一个单字符串显示所有向脚本传递的参数。 如\u0026quot;$* \u0026ldquo;用「\u0026quot;」括起来的情况、以\u0026rdquo;$1 $2 … $n\u0026quot;的形式输出所有参数。 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@\t与$* 相同，但是使用时加引号，并在引号中返回每个参数。 如\u0026quot;$@\u0026ldquo;用「\u0026quot;」括起来的情况、以\u0026rdquo;$1\u0026quot; \u0026ldquo;$2\u0026rdquo; … \u0026ldquo;$n\u0026rdquo; 的形式输出所有参数。 $- 显示Shell使用的当前选项，与set命令功能相同。 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。  Shell基本运算符 原生bah不支持简单的数学运算，但可以使用awk或expr实现，expr最常用。\nexpr是一款表达式计算工具，使用它能完成表达式的求值操作\n两数相加：\n#!/bin/bash val=`expr 2 + 2` echo \u0026#34;2 + 2 = $val\u0026#34; 注意：\n 表达式和运算符之间要有空格 完整表达式要被` `包含  关系运算符  -eq 是否相等 -ne 是否不等 -gt 左边是否大于右边 lt 左边是否小于右边 -ge 左边是否大于等于右边 -le 左边是否小于等于右边  布尔运算符  ! 非 -o 或 -a 与  文件测试运算符  -b file 是否是块设备文件 -c file 是否是字符设备文件 -d file 是否是目录 -f file 是否是普通文件 -g file 是否设置了SGID位 -k file 是否设置了粘着位 -r file 是否可读 -w file 是否可写 -x file 是否可执行 -s file 是否为空 -e file 是否存在  ","date":"2019-06-26T15:38:32+08:00","permalink":"https://konosuba.xyz/blog/shell%E5%AD%A6%E4%B9%A0/","title":"Shell学习"},{"content":"vim分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode），底线命令（Last line mode）\n命令模式 此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。\n常用命令：\n i 切换到输入模式，以输入字符 x 删除当前光标所在处的字符 : 切换到底线命令模式，以在最底一行输入命令  命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令\n输入模式 常用：\n Esc 退出输入模式，切换到命令模式 Insert 切换光标为输入/替换模式，光标变成竖线/下划线  底线命令模式 基本命令：\n q 退出程序 w 保存文件  vim按键 移动光标 要进行多次移动，例如向下移动30行，可使用30↓的组合按键\n [Ctrl]+[f] 下一页 [Ctrl]+[b] 上一页 [Ctrl]+[d] 向下半页 [Ctrl]+[u] 向上半页 0 移动到该行最前面字符处 $ 移动到该行最后字符处 G 移动到档案最后一行 nG 一赌东道档案第n行 gg 移动到档案第一行  搜索替换  /word 向光标之下寻找名称为word的字符串 ？word 向光标之上寻找名称为word的字符串 n 重复前一个搜寻的动作 N 反向进行前一个搜寻动作 :n1,n2s/word1/word2/g 在n1与n2行之间寻找word1字符串，并用word2取代 :1,$s/word1/word2/g 或 :%s/word1/word2/g 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 :1,$s/word1/word2/gc 或 :%s/word1/word2/gc 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2，并显示提示字符确认  删除、复制、粘贴  x,X x相当于del，X相当于Backspace dd 删除光标所在行 ndd 删除光标所在向下n行 d1G 删除光标所在到第一行所有数据 dG 删除光标所在到最后一行所有数据 yy 复制光标所在行 nyy 复制光标所在的向下n行 p,P p为将已复制的数据在光标下一行粘贴，P为粘贴在上一行 u 撤销 [Ctrl]+r 重做 . 重复前一动作  一般模式切换到编辑模式  i,I i为『从目前光标所在处输入』， I为『在目前所在行的第一个非空格符处开始输入』 a,A a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』 o,O o 为『在目前光标所在的下一行处输入新的一行』, O 为在目前光标所在处的上一行输入新的一行 r,R r 会取代光标所在字符一次，R会一直取代光标所在的文字，直到按下[Esc]  一般模式切换到命令模式  :w! 若文档为只读属性，强制写入该文档，不过仍与权限有关 :q! 离开而不存储文档 wq! 强制存储后离开 ZZ 若档案没有更动，则不储存离开，若档案已经被更动过，则储存后离开 :w [filename] 将编辑的数据另存为filename :r [filename] 将filename 这个档案内容加到光标所在行后面 n1,n2 w [filename] 将n1到n2的内容另存为filename :! command 暂时离开vi到指令模式下执行command的显示结果，如[:! ls/home] 即可在vi中查看/home下以ls输出的文档信息 :set nu 显示行号，在每一行的前缀显示该行行号 :set nonu 取消行号  ","date":"2019-06-26T10:33:16+08:00","permalink":"https://konosuba.xyz/blog/vim%E5%AD%A6%E4%B9%A0/","title":"Vim学习"},{"content":"[toc]\nLinux文件基本属性 在Linux中可以使用ll或者ls –l命令来显示一个文件的属性以及文件所属的用户和组，如：\n[root@www /]# ls -l total 64 dr-xr-xr-x 2 root root 4096 Dec 14 2012 bin dr-xr-xr-x 4 root root 4096 Apr 19 2012 boot …… bin文件的第一个属性用d表示，d在Linux中代表该文件是一个目录文件 Linux中第一个字符代表这个文件时目录、文件、链接文件等\n  当为[d]则是目录 当为[-]则是文件 若是[l]则表示为链接文档(link file) 若是[b]则表示为装置文件里面的可供储存的接口设备(可随机存取装置) 若是[c]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)   接下来的字符中，三个为一组，且均为『rwx』 的三个参数的组合。其中，[r]代表可读(read)、[w]代表可写(write)、[x]代表可执行(execute)。 要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[-]，如图\nLinux链接 Linux链接分为硬链接（Hard Link）和软链接（Symbolic Link）。默认情况，ln命令创建硬链接\n硬链接 硬连接指通过索引节点来进行连接，多个文件名可以指向同一索引节点，删除其中任何一个不会影响其余文件名的访问，只有当最后一个连接被删除时，文件的数据块及其目录的连接才被释放\n软链接 即符号链接，类似于Windows中快捷方式。两个文件名指向两个不同的节点号，若被指向的文件删除，链接仍存在，但指向一个无效的链接\nLinux文件属主和属组 Linux系统按文件所有者、文件所有者同组用户和其他用户来规定了不同的文件访问权限。\n[root@www /]# ls -l total 64 drwxr-xr-x 2 root root 4096 Feb 15 14:46 cron drwxr-xr-x 3 mysql mysql 4096 Apr 21 2014 mysql …… mysql 文件是一个目录文件，属主和属组都为 mysql，属主有可读、可写、可执行的权限；与属主同组的其他用户有可读和可执行的权限；其他用户也有可读和可执行的权限。\n对于 root 用户来说，一般情况下，文件的权限对其不起作用。\n更改文件属性 chgrp更改文件属组 chgrp [-R] 属组名 文件名  -R: 递归更改文件属性，更改属组时加上该参数，可更改该目录下所有文件的属组\n chown更改文件属住（也可同时更改属组） chown [-R] 属主名 文件名 chown [-R] 属主名: 属组名 文件名  进入 /root 目录（~）将install.log的拥有者改为bin这个账号：  [root@www ~] cd ~ [root@www ~]# chown bin install.log [root@www ~]# ls -l -rw-r--r-- 1 bin users 68495 Jun 25 08:53 install.log  将install.log的拥有者与群组改回为root：  [root@www ~]# chown root:root install.log [root@www ~]# ls -l -rw-r--r-- 1 root root 68495 Jun 25 08:53 install.log chmod更改文件9个属性 Linux文件属性有两种设置方法，一种是数字，一种是符号。\nLinux文件的基本权限就有九个，分别是owner/group/others三种身份各有自己的read/write/execute权限。\n数字类型改变文件权限 文件的权限字符为3 * 3的字符（r\\w\\x）组合，可用数字代表各个权限：\n  r-4 w-2 x-1   每种身份各自的三个权限分数需要累加，例如当权限为： [-rwxrwx\u0026mdash;] 是的分数则是：\n  owner = rwx = 4+2+1 = 7 group = rwx = 4+2+1 = 7 others= \u0026mdash; = 0+0+0 = 0   之后可以使用权限数字770修改权限\nchmod [-R] xyz 文件或目录 例如：\n[root@www ~]# ls -al .bashrc -rw-r--r-- 1 root root 395 Jul 4 11:45 .bashrc [root@www ~]# chmod 777 .bashrc [root@www ~]# ls -al .bashrc -rwxrwxrwx 1 root root 395 Jul 4 11:45 .bashrc 符号类型改变文件权限 用u, g, o代表三种身份的权限，此外a代表all，即全部身份。读写权限可以写成r, w, x\n| chmod | u | +（加入） | r | 文件或目录 | | \u0026mdash;\u0026ndash; | \u0026mdash;\u0026ndash; | \u0026mdash;\u0026ndash; | | | g | -（除去）| w | | | o | =（设定）| x | | | a | | |\n如果我们需要将文件权限设置为-rwxr-xr-- ，可以使用 chmod u=rwx,g=rx,o=r 文件名 来设定\n要去掉权限而不改变其他已存在的权限，例如要拿掉全部人的可执行权限：\n# chmod a-x test1 # ls -al test1 -rw-r--r-- 1 root root 0 Nov 15 10:32 test1 Linux文件与目录管理   绝对路径：路径的写法，由根目录 / 写起，例如：/usr/share/doc这个目录。 相对路径： 路径的写法，不是由 / 写起，例如由/usr/share/doc要到/usr/share/man底下时，可以写成： cd ../man   处理目录的常用命令  ls: 列出目录 cd：切换目录 pwd：显示目前的目录 mkdir：创建一个新的目录 rmdir：删除一个空的目录 cp: 复制文件或目录 rm: 移除文件或目录 mv: 移动文件与目录，或修改文件与目录的名称  使用man [命令]查看各个命令的使用文档\nls列出目录 选项与参数：\n -a：全部文件（包括隐藏的文件） -d：仅列出目录本身，而不列出目录内的文件数据 -l：长数据串列出（包括文件的属性与权限等数据）  cd切换目录 cd /root/test1/ #使用绝对路径切换到test1目录 cd ./test1/ #使用相对路径 cd ~ #回到自己的home目录，此处即/root cd .. #返回上一级 pwd显示目前所在目录 pwd [-P]  -P：显示出确实的路径，而非使用连结（link）路径  mkdir创建新目录 mkdir [-mp] 目录名称 选项与参数：\n -m：配置文件的权限 -p：一次性递归创建多层目录  rmdir删除空目录 rmdir [-p] 目录名称 选项与参数：\n -p：连同上一级“空的”目录一起删除  cp复制文件或目录 cp [-adfilprsu] 来源档（source） 目标档（destination） cp [options] source1 source2 source3 .... directory 选项与参数：\n -a：相当于-pdr -d：若来源档为连结档的属性，则只复制属性 -f：强制，若目标文件已存在且无法开启，则移除后载尝试一次 -i：若目标档已存在，在覆盖时先询问动作的进行 -l：进行硬式连结(hard link)的连结档创建，而非复制文件本身； -p：连同文件的属性一起复制过去，而非使用默认属性(备份常用)； -r：递归持续复制，用於目录的复制行为；(常用) -s：复制成为符号连结档 (symbolic link)，亦即『捷径』文件； -u：若 destination 比 source 旧才升级 destination ！  用 root 身份，将 root 目录下的 .bashrc 复制到 /tmp 下，并命名为 bashrc\n[root@www ~]# cp ~/.bashrc /tmp/bashrc [root@www ~]# cp -i ~/.bashrc /tmp/bashrc cp: overwrite `/tmp/bashrc\u0026#39;? n \u0026lt;==n不覆盖，y为覆盖 rm移除文件或目录 rm [-fir] 文件或目录 选项与参数：\n -f：忽略不存在的文件，不出现警告信息 -i：互动模式，在删除前询问是否操作 -r：递归删除  mv移动文件与目录，或修改名称 mv [-fiu] source destination mv [options] source1 source2 source3 .... directory 选项与参数：\n -f：强制，若目标文件已存在，不会询问而直接覆盖 -i：若目标文件已存在，则询问 -u：若目标文件已经存在，且 source 比较新，才会升级 (update)  Linux文件内容查看   cat：由第一行开始显示文件内容 tac：从最后一行开始显示，是 cat 的倒著写 nl：显示的时候，同时输出行号 more：一页一页的显示文件内容 less：与 more 类似，但是比 more 更好的是，他可以往前翻页！ head：只看头几行 tail：只看末尾几行   使用man [命令]查看使用文档\ncat / tac cat [-AbEnTv] 选项与参数：\n -A：相当于-vET，可列出一些特殊字符而非空白 -b：列出行号（仅空白行标出） -E：显示结尾断行字节$ -n：列出行号（非空白行也有） -T：将[tab]键以^|显示 -v：列出特殊字符  nl nl [-bnw] 文件 选项与参数：\n -b ：指定行号指定的方式，主要有两种： **-b a ：**表示不论是否为空行，也同样列出行号(类似 cat -n) **-b t ：**如果有空行，空的那一行不要列出行号(默认值) -n ：列出行号表示的方法，主要有三种： **-n ln ：**行号在荧幕的最左方显示 **-n rn ：**行号在自己栏位的最右方显示，且不加 0 **-n rz ：**行号在自己栏位的最右方显示，且加 0 -w ：行号栏位的占用的位数。  more more运行时可使用操作：\n 空白键 (space)：代表向下翻一页 Enter：代表向下翻『一行』 /字串：代表在这个显示的内容当中，向下搜寻『字串』这个关键字 :f：立刻显示出档名以及目前显示的行数 q：代表立刻离开 more ，不再显示该文件内容 b 或 [ctrl]-b：代表往回翻页，不过这动作只对文件有用，对管线无用。  less less运行时可使用操作：\n 空白键：向下翻动一页 [pagedown]：向下翻动一页 [pageup]：向上翻动一页 /字串：向下搜寻『字串』的功能 ?字串：向上搜寻『字串』的功能 n：重复前一个搜寻 (与 / 或 ? 有关！) N：反向的重复前一个搜寻 (与 / 或 ? 有关！) q：离开 less 这个程序  less head [-n number] 文件 选项与参数：\n -n：后接数字，代表显示几行 默认显示10行  tail tail [-n number] 文件 选项与参数：\n -n -f：持续侦测后面所接的文档名，直到按下[ctrl]-c结束侦测  ","date":"2019-06-25T13:23:08+08:00","permalink":"https://konosuba.xyz/blog/linux%E6%96%87%E4%BB%B6/","title":"Linux文件"},{"content":"Linux系统启动过程   内核的引导 运行init 系统初始化 建立终端 用户登录系统   内核的引导 计算机接通电源，BIOS开机自检，启动操作系统，操作系统接管硬件后，首先读入/boot目录下的内核文件\n运行init init进程是所有进程的起点，没有它任何进程都不会启动。init程序首先需要读取配置文件/etc/inittab\n运行级别 Linux允许为不同的场合，分配不同的开机启动程序，即“运行级别”(runlevel)。启动时根据运行级别，确定要运行哪些程序\nLinux共7种运行级别:\n  运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登陆后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动   系统初始化 init配置文件中有一行：si::sysinit:/etc/rc.d/rc.sysinit，它调用执行了/etc/rc.d/rc.sysinit，而rc.sysinit是一个bash shell的脚本，主要完成一些系统初始化的工作，rc.sysinit是每个运行级别都要首先运行的重要脚本。\n主要完成的工作：激活交换分区，检查磁盘，加载硬件模块及其他一些需要优先执行的任务\n另外一行：15:5:wait:/etc/rc.d/rc 5，表示以5为参数运行/etc/rc.d/rc，/etc/rc.d/rc是一个Shell脚本，接受5作为参数，执行/etc/rc.d/rc5.d/目录下所有rc启动脚本，/etc/rc.d/rc5.d/目录中的这些启动脚本实际上都是一些连接文件，而不是真正的rc启动脚本，真正的rc启动脚本实际上都是放在/etc/rc.d/init.d/目录下。而这些rc启动脚本有着类似的用法，它们一般能接受start、stop、restart、status等参数。/etc/rc.d/rc5.d/中的rc启动脚本通常是K或S开头的连接文件，对于以 S 开头的启动脚本，将以start参数来运行。\n而如果发现存在相应的脚本也存在K打头的连接，而且已经处于运行态了(以/var/lock/subsys/下的文件作为标志)，则将首先以stop为参数停止这些已经启动了的守护进程，然后再重新运行。\n这样做是为了保证是当init改变运行级别时，所有相关的守护进程都将重启。\n至于在每个运行级中将运行哪些守护进程，用户可以通过chkconfig或setup中的\u0026quot;System Services\u0026quot;来自行设定。\n建立终端 rc执行完毕，返回init。此时基本系统环境已设置好，各种守护进程已启动。\ninit接下来会打开6个终端，以便用户登录系统，即inittab中以下6行就是定义了6个终端：\n1:2345:respawn:/sbin/mingetty tty1 2:2345:respawn:/sbin/mingetty tty2 3:2345:respawn:/sbin/mingetty tty3 4:2345:respawn:/sbin/mingetty tty4 5:2345:respawn:/sbin/mingetty tty5 6:2345:respawn:/sbin/mingetty tty6 2、3、4、5的运行级别中都将以respawn方式运行mingetty程序，mingetty程序能打开终端、设置模式，同时显示文本登陆界面\n用户登录系统 常用三种登陆方式：\n 命令行登陆 ssh登陆 图形界面登陆  命令行登陆 Linux的账号验证程序是login，login会接手mingetty传来的用户名作为用户名参数， 之后login对用户名进行分析：如果用户名不是 root，且存在/etc/nologin文件，login 将输出 nologin 文件的内容，然后退出。\n这通常用来系统维护时防止非root用户登录。只有/etc/securetty中登记了的终端才允许 root 用户登录，如果不存在这个文件，则 root 用户可以在任何终端上登录。\n/etc/usertty文件用于对用户作出附加访问限制，如果不存在这个文件，则没有其他限制。\n流程图 Linux系统目录结构 Linux中，所有的文件和目录都被组织成以一个根节点开始的倒置的树状结构\n/bin bin是Binary的缩写，该目录存放最常使用的命令\n/boot 存放启动Linux时使用的一些核心文件，包括链接文件及镜像文件\n/dev dev是Device的缩写，该目录存放Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的\n/etc 存放所有的系统管理所需要的配置文件和子目录\n/home 用户的主目录，Linux中，每个用户有一个自己的目录，一般该目录以用户的账号命名\n/lib 存放系统最基本的动态连接共享库，作用类似Windows中的DLL文件，几乎所有应用程序都需要用到这些共享库\n/lost+found 一般为空，当系统非法关机后，会存放一些文件\n/media Linux系统自动识别一些设备，如U盘、光驱等，识别的设备挂载到这个目录下\n/mnt 系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。\n/opt 给主机安装额外软件所摆放的目录，默认为空\n/proc 这是一个虚拟目录，是系统内存的映射，可以通过直接访问该目录来获取系统信息。 该目录的内容不再硬盘而是在内存里，可以直接修改里面的某些文件\n/root 该目录为系统管理员，也称作超级权限者的用户主目录。\n/sbin s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。\n/selinux Redhat/CentOS特有目录，Selinux类似于Windows中防火墙。该目录即存放selinux相关文件\n/srv 存放一些服务启动后需要提取的数据\n/sys 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。\nsysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。 该文件系统是内核设备树的一个直观反映。\n当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中被创建。\n/tmp 存放临时文件\n/usr 用户的很多应用程序和文件都放在该目录下，类似Windows中的program files目录\n/usr/bin 系统用户使用的应用程序\n/usr/sbin 超级用户使用的比较高级的管理程序和系统守护程序。\n/usr/src 内核源代码默认的放置位置\n/var 存放不断扩充的文件，习惯将经常被修改的目录放在这个目录下。包括各种日志文件\n/run 临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run。\nLinux系统中有几个目录比较重要，不能误删或随意更改\n  /etc /bin, /sbin, /usr/bin, /usr/sbin 此外，/bin, /usr/bin是给系统用户使用的指令（除root外的），而/sbin, /usr/sbin是给root使用的指令 /var   Linux中有两个特殊的目录，一个当前目录，可使用一个点.表示；另一个是当前目录的上一级目录，可使用两个点..表示\n若一个目录或文件名以一个点.开始，表示这个目录或文件是一个隐藏目录或文件。即以默认方式查找时，不显示该目录或文件\n","date":"2019-06-24T11:51:27+08:00","permalink":"https://konosuba.xyz/blog/linux%E6%93%8D%E4%BD%9C%E5%AD%A6%E4%B9%A0-%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E5%8F%8A%E7%9B%AE%E5%BD%95/","title":"Linux操作学习 系统启动及目录"},{"content":"类和实例 定义类 使用class关键字\nclass Student(object): #class 类名(继承类) 无继承类则使用object,也可省略 \u0026#34;\u0026#34;\u0026#34;docstring for Student\u0026#34;\u0026#34;\u0026#34; def __init__(self, name, score): #初始属性，第一个参数永远是self，表示创建的实例本身 super (Student, self).__init__() self.name = name self.score = score def print_score(self) print(\u0026#39;%s: %s\u0026#39; % (self.name, self.score)) 实例化 类名+（）\n\u0026gt;\u0026gt;\u0026gt; bob = Student(\u0026#39;Bob\u0026#39;, 98) \u0026gt;\u0026gt;\u0026gt; bob.print_score() Bob: 98 创建实例后，可以自由地给一个实例变量绑定属性，如\n\u0026gt;\u0026gt;\u0026gt; bob.school = \u0026#39;SWUST\u0026#39; \u0026gt;\u0026gt;\u0026gt; bob.school \u0026#39;SWUST\u0026#39; 访问限制  private私有变量：变量名以__开头 注意：__name__外部可以访问，是特殊变量  继承和多态 基类：\nclass Animal(object): def run(self): print(\u0026#39;Animal is running...\u0026#39;) 子类：\nclass Dog(Animal) pass 子类调用父类方法：\n\u0026gt;\u0026gt;\u0026gt; dog = Dog() \u0026gt;\u0026gt;\u0026gt; dog.run() Animal is running... 同样支持多态\n动态语言 对于动态语言，传入时不一定需要Animal类型，只需要保证传入的对象有run()方法即可\n获取对象信息 使用type() \u0026gt;\u0026gt;\u0026gt; type(123) \u0026lt;class 'int'\u0026gt; 使用isinstance() \u0026gt;\u0026gt;\u0026gt; a = 10 \u0026gt;\u0026gt;\u0026gt; isinstance(a, int) True \u0026gt;\u0026gt;\u0026gt; isinstance(a, float) False 使用dir() 获得一个对象的所有属性和方法，它返回一个包含字符串的list\n\u0026gt;\u0026gt;\u0026gt; dir('ABC') ['__add__', '__class__',..., '__subclasshook__', 'capitalize', 'casefold',..., 'zfill'] 类似__xxx__的属性和方法在Python中都是有特殊用途的，比如__len__方法返回长度。在Python中，如果你调用len()函数试图获取一个对象的长度，实际上，在len()函数内部，它自动去调用该对象的__len__()方法\n限制类的实例绑定属性 在定义时，定义一个特殊的__slots__变量来限制实例能添加的属性\nclass Student(object): __slots__ = (\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;) #用tuple定义允许绑定的属性名称 尝试绑定\n\u0026gt;\u0026gt;\u0026gt; s = Student() \u0026gt;\u0026gt;\u0026gt; s.name = \u0026#39;Michael\u0026#39; \u0026gt;\u0026gt;\u0026gt; s.score = 99 #绑定属性\u0026#39;score\u0026#39; Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;Student\u0026#39; object has no attribute \u0026#39;score\u0026#39; 由于'score'没有被放到__slots__中，所以不能绑定score属性，试图绑定score将得到AttributeError的错误。\n使用__slots__要注意,__slots__定义的属性仅对当前类实例起作用，对继承的子类是不起作用的\n","date":"2019-06-21T15:23:06+08:00","permalink":"https://konosuba.xyz/blog/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","title":"Python面向对象"},{"content":"[toc]\n什么是函数式编程？ 函数式编程是一种抽象程度很高的编程范式，纯粹的函数式编程语言编写的函数没有变量，因此，任意一个函数，只要输入是确定的，输出就是确定的，这种纯函数我们称之为没有副作用。\n而允许使用变量的程序设计语言，由于函数内部的变量状态不确定，同样的输入，可能得到不同的输出，因此，这种函数是有副作用的\n函数式编程的一个特点就是，允许把函数本身作为参数传入另一个函数，还允许返回一个函数！\nPython对函数式编程提供部分支持。由于Python允许使用变量，因此，Python不是纯函数式编程语言\n高阶函数 Python中函数两个特性\n 变量可以指向函数  函数本身可以赋值给变量，通过变量可以调用函数\n\u0026gt;\u0026gt;\u0026gt; f = abs \u0026gt;\u0026gt;\u0026gt; f(-10) 10  函数名是变量  把函数名看作变量，可将其指向其他对象，则无法调用原函数\n\u0026gt;\u0026gt;\u0026gt; abs = 10 \u0026gt;\u0026gt;\u0026gt; abs(-10) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: \u0026#39;int\u0026#39; object is not callable 传入函数 由于变量可以指向函数，函数的参数能接收变量，那么一个函数就可以接收另一个函数作为参数，这种函数就称之为高阶函数\n一个最简单的高阶函数：\ndef add(x, y, f) return f(x) + f(y) 当调用add(-5, -6, abs)时，函数计算abs(-5)+abs(-6)，返回11\n 把函数作为参数传入，这样的函数称为高阶函数，函数式编程就是指这种高度抽象的编程范式\n  Python内建高阶函数 map()函数 |map() 函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回\ndef f(x): return x * x \u0026gt;\u0026gt;\u0026gt; r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9]) \u0026gt;\u0026gt;\u0026gt; list(r) [1, 4, 9, 16, 25, 36, 49, 64, 81] reduce()函数 |reduce 把一个函数作用在一个序列[x1, x2, x3, ...]上，这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算，其效果就是：\nreduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) filter()函数 该函用于过滤序列。\n|filter() 接收一个函数和一个序列，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还时False决定保留还是丢弃该元素。\n例如，删掉list中的偶数，保留奇数\ndef is_odd(n): return n % 2 == 1 \u0026gt;\u0026gt;\u0026gt; list(filter(is_odd, [1, 2, 3, 4, 5])) [1, 3, 5] 用filter求素数 利用埃氏筛法\n 先构造一个从3开始的奇数序列  利用生成器\ndef _odd_iter(): n = 1 while 1: n += 2 yield n  定义一个筛选函数  def _not_divisible(n): return lambda x: x % n \u0026gt; 0  最后定义一个生成器，不断返回下一素数  def primes(): yield 2 it = _odd_iter() while 1: n = next(it) yield n it = filter(_not_divisible(n), it)  调用得到1000内素数  for n in primes(): if (n \u0026lt; 1000): print(n) else: break |filter()的作用是从一个序列中筛出符合条件的元素。由于filter()使用了惰性计算，所以只有在取filter()结果的时候，才会真正筛选并每次返回下一个筛出的元素。\nsorted()函数 它可以接收一个key函数来实现自定义的排序，例如按绝对值大小排序：\n\u0026gt;\u0026gt;\u0026gt; sorted([36, 5, -12, 9, -21], key=abs) [5, 9, -12, -21, 36] key指定的函数将作用于list的每一个元素上，并根据key函数返回的结果进行排序。 然后sorted()函数按照keys进行排序，并按照对应关系返回list相应的元素\n返回函数\u0026amp;闭包 函数作为返回值 def lazy_f(x, y): def f(): return x + y return f1\t#返回函数 \u0026gt;\u0026gt;\u0026gt; f1 = lazy_f(1, 2) \u0026gt;\u0026gt;\u0026gt; f2 = lazy_f(1, 2) \u0026gt;\u0026gt;\u0026gt; f1 == f2 False\t#两次返回的函数并不同 \u0026gt;\u0026gt;\u0026gt; f1() #调用函数时，才真正计算求和结果 3 \u0026gt;\u0026gt;\u0026gt; f2() 3 闭包 当lazy_f返回函数f时，相关参数和变量都保存在返回的函数中，这种称为“闭包（Closure）”的程序结构拥有极大的威力。\n需要注意的是，返回的函数并没有立刻执行，而是直到调用了f()才执行 如\ndef count(): fs = [] for i in range(1, 4): def f(): return i*i fs.append(f) return fs f1, f2, f3 = count() 在实际调用中\n\u0026gt;\u0026gt;\u0026gt; f1() 9 \u0026gt;\u0026gt;\u0026gt; f2() 9 \u0026gt;\u0026gt;\u0026gt; f3() 9  注意：返回函数不要引用任何循环变量，或者后续会发生变化的变量\n 匿名函数 如匿名函数lambda x: x * x\n关键字lambda表示匿名函数，冒号前面的x表示函数参数。\n匿名函数只能有一个表达式，不写return，返回值就是该表达式的结果\nPython对匿名函数的支持有限，只有一些简单的情况下可以使用匿名函数。\n装饰器 函数对像有一个__name__属性，可以返回函数的名字\n\u0026gt;\u0026gt;\u0026gt; now.__name__ \u0026#39;now\u0026#39; 现在，假设我们要增强now()函数的功能，比如，在函数调用前后自动打印日志，但又不希望修改now()函数的定义，这种在代码运行期间动态增加功能的方式，称之为“装饰器（Decorator）”。\n定义一个能打印日志的decorator\ndef log(func): def wrapper(*args, **kw):\t#*args是非关键字参数，用于元组，**kw是关键字参数，用于字典 print(\u0026#39;class %s():\u0026#39; % func.__name__) return func(*args, **kw) return wrapper 借助Python的@语法，把decorator置于函数的定义处：\n@log def now(): print(\u0026#39;2019/6/21\u0026#39;) 调用函数now()，不仅会运行now()本身，还会在其之前打印一行日志\n\u0026gt;\u0026gt;\u0026gt; now() call now(): 2019/6/21 相当于执行了语句：\nnow = log(now) 如果decorator本身需要传入参数，那就需要编写一个返回decorator的高阶函数，写出来会更复杂。比如，要自定义log的文本：\ndef log(text): def decorator(func): def wrapper(*args, **kw): print(\u0026#39;%s%s():\u0026#39; % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator 使用\n@log(\u0026#39;execute\u0026#39;) def now(): print(\u0026#39;2019/6/21\u0026#39;) #相当于now = log(\u0026#39;excute\u0026#39;)(now) 以上两种decorator的定义都没有问题，但还差最后一步。因为我们讲了函数也是对象，它有__name__等属性，但你去看经过decorator装饰之后的函数，它们的__name__已经从原来的'now'变成了'wrapper'：\n\u0026gt;\u0026gt;\u0026gt; now.__name__ \u0026#39;wrapper\u0026#39; 因为返回的那个wrapper()函数名字就是'wrapper'，所以，需要把原始函数的__name__等属性复制到wrapper()函数中，否则，有些依赖函数签名的代码执行就会出错。\n不需要编写wrapper.__name__ = func.__name__这样的代码，Python内置的functools.wraps就是干这个事的，所以，一个完整的decorator的写法如下：\nimport functools def log(func): @functools.wraps(func) def wrapper(*args, **kw): print(\u0026#39;call %s():\u0026#39; % func.__name__) return func(*args, **kw) return wrapper 或者针对带参数的decorator：\nimport functools def log(text): def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): print(\u0026#39;%s%s():\u0026#39; % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator 偏函数 可借助functools.partial创建偏函数：把一个函数的某些参数设为某个默认值，返回一个新的函数，调用这个新函数会更简单\n\u0026gt;\u0026gt;\u0026gt; int2 = functools.partial(int, base = 2) \u0026gt;\u0026gt;\u0026gt; int2(\u0026#39;10000\u0026#39;) 16  当函数的参数个数太多，需要简化时，使用functools.partial可以创建一个新的函数，这个新函数可以固定住原函数的部分参数，从而在调用时更简单。\n ","date":"2019-06-21T10:50:55+08:00","permalink":"https://konosuba.xyz/blog/python%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/","title":"Python函数式编程"},{"content":"算法复杂度  总共N个数据 一次操作记为O(1) N次操作记为O(n) 在大部分oj判题系统中时间限制为10^6 =1s  冒泡排序  操作次数: n+(n-1)+(n-2)+\u0026hellip;+n(n-1)/2  快速排序   递归处理数组，每次将数组按照key值在其左右区分出来：比key小放左边，比key大放右边\n  例: 5 6 2 4 3 8   取首位（5）为key值\n  4 3 2 5 6 8\n  4 3 2 5 6 8\n  ","date":"2019-06-21T10:40:29+08:00","permalink":"https://konosuba.xyz/blog/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/","title":"算法复杂度"},{"content":"set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。\n创建set 传入一个list，重复元素会被自动过滤，显示的顺序并不表示set是有序的\n\u0026gt;\u0026gt;\u0026gt; s = set([1, 1, 2, 2, 3, 3]) \u0026gt;\u0026gt;\u0026gt; s {1, 2, 3} 添加元素 \u0026gt;\u0026gt;\u0026gt; s.add(4) \u0026gt;\u0026gt;\u0026gt; s {1, 2, 3, 4} 删除元素 \u0026gt;\u0026gt;\u0026gt; s.remove(3) \u0026gt;\u0026gt;\u0026gt; s {1, 2, 4} 交并集 set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作\n\u0026gt;\u0026gt;\u0026gt; s1 = set([1, 2, 3]) \u0026gt;\u0026gt;\u0026gt; s2 = set([2, 3, 4]) \u0026gt;\u0026gt;\u0026gt; s1 \u0026amp; s2 {2, 3} \u0026gt;\u0026gt;\u0026gt; s1 | s2 {1, 2, 3, 4} ","date":"2019-06-20T16:18:07+08:00","permalink":"https://konosuba.xyz/blog/python%E4%B8%ADset%E9%9B%86%E5%90%88/","title":"Python中set集合"},{"content":"dict全称dictionary，在其他语言中也称为map，使用**键-值（key-value）**存储，具有极快的查找速度\n创建dict \u0026gt;\u0026gt;\u0026gt; d = {\u0026#39;Michael\u0026#39;: 95, \u0026#39;Bob\u0026#39;: 75, \u0026#39;Tracy\u0026#39;: 85} \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Michael\u0026#39;] 95 内部实现方法 先在字典的索引表里（比如部首表）查这个字对应的页码，然后直接翻到该页，找到这个字。无论找哪个字，这种查找速度都非常快，不会随着字典大小的增加而变慢。\n加入数据 把数据放入dict的方法，除了初始化时指定外，还可以通过key放入：\n\u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Tony\u0026#39;] = 99 \u0026gt;\u0026gt;\u0026gt; d {\u0026#39;Michael\u0026#39;: 95, \u0026#39;Bob\u0026#39;: 75, \u0026#39;Tracy\u0026#39;: 85, \u0026#39;Tony\u0026#39;: 99} 查询key是否存在 使用in \u0026gt;\u0026gt;\u0026gt; \u0026#39;Thomas\u0026#39; in d False \u0026gt;\u0026gt;\u0026gt; \u0026#39;Bob\u0026#39; in d True 使用get() 如果key不存在，返回None，或者自己指定的value\n\u0026gt;\u0026gt;\u0026gt; d.get(\u0026#39;Thomas\u0026#39;) #返回None时Python交互环境不显示 \u0026gt;\u0026gt;\u0026gt; d.get(\u0026#39;Thomas\u0026#39;, -1) -1 删除key 删除一个key，用pop(key)方法，对应的value也会从dict中删除，返回删除的value\n\u0026gt;\u0026gt;\u0026gt; d.pop(\u0026#39;Bob\u0026#39;) 75 \u0026gt;\u0026gt;\u0026gt; d {\u0026#39;Michael\u0026#39;: 95, \u0026#39;Tracy\u0026#39;: 85, \u0026#39;Tony\u0026#39;: 99} 注意 dict内部存放顺序与key放入顺序无关 dict的key必须是不可变对象 实质：哈希表\n和list比较，dict有以下几个特点：  查找和插入的速度极快，不会随着key的增加而变慢； 需要占用大量的内存，内存浪费多。  而list相反：  查找和插入的时间随着元素的增加而增加； 占用空间小，浪费内存很少。  dict相关函数和方法 函数  str(dict) 输出字典，以可打印的字符串表示 type(variable) 返回输入的变量类型  方法  radiansdict.clear() 删除字典内所有元素 radiansdict.copy() 返回一个字典的浅复制 radiansdict.fromkeys() 创建一个新字典，以序列seq中元素做字典的键，val为字典所有键对应的初始值 radiansdict.get(key, default=None) 返回指定键的值，如果值不在字典中返回default值 key in dict 如果键在字典dict里返回true，否则返回false radiansdict.items() 以列表返回可遍历的(键, 值) 元组数组 radiansdict.keys() 返回一个迭代器，可以使用 list() 来转换为列表 radiansdict.setdefault(key, default=None) 和get()类似, 但如果键不存在于字典中，将会添加键并将值设为default radiansdict.update(dict2) 把字典dict2的键/值对更新到dict里 radiansdict.values() 返回一个迭代器，可以使用 list() 来转换为列表 pop(key[,default]) 删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。 否则，返回default值。 popitem() 随机返回并删除字典中的一对键和值(一般删除末尾对)。  ","date":"2019-06-20T15:15:34+08:00","permalink":"https://konosuba.xyz/blog/python%E4%B8%ADdict%E5%AD%97%E5%85%B8/","title":"Python中dict字典"},{"content":"tuple和list非常类似，但是tuple一旦初始化就不能修改\n[toc]\n创建tuple \u0026gt;\u0026gt;\u0026gt; classmates = (\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;) 此时，classmates这个tuple不能改变，它也没有append()，insert()这样的方法。\n其他获取元素的方法和list是一样的，你可以正常地使用classmates[0]，classmates[-1]，但不能将其赋值为另外的元素。\n因为tuple不可变，所以代码更安全。如果可能，能用tuple代替list就尽量用tuple。\n空tuple \u0026gt;\u0026gt;\u0026gt; t = () \u0026gt;\u0026gt;\u0026gt; t () 只有一个元素的tuple 错误写法 不能直接使用括号()!!!\n\u0026gt;\u0026gt;\u0026gt; t = (1) \u0026gt;\u0026gt;\u0026gt; t 1 #定义的不是tuble，而是一个数 正解 加一个逗号，消除歧义\n\u0026gt;\u0026gt;\u0026gt; t = (1,) \u0026gt;\u0026gt;\u0026gt; t (1,) \u0026ldquo;可变\u0026quot;的tuble 当tuble中包含list元素时，仍然可以对list进行修改，tuble仍指向该list\n\u0026gt;\u0026gt;\u0026gt; t = (1, [\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;z\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; t[1][2] = \u0026#39;a\u0026#39; \u0026gt;\u0026gt;\u0026gt; t (1, [\u0026#39;x\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;z\u0026#39;]) 个人理解：tuble相当于一个指针数组，指向每个元素，对元素本身的更改并不会影响tuble的指向\n","date":"2019-06-20T13:46:10+08:00","permalink":"https://konosuba.xyz/blog/python%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8Btuple%E5%85%83%E7%BB%84/","title":"Python常见数据类型——Tuple元组"},{"content":"Python常见数据类型——List列表 list是一种有序的集合，可随时增删元素\n[toc]\n创建list \u0026gt;\u0026gt;\u0026gt; classmates = [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;] \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;] \u0026gt;\u0026gt;\u0026gt; len(classmates) 3 访问某个位置元素 使用索引地址访问\n\u0026gt;\u0026gt;\u0026gt; classmates[0] \u0026#39;A\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates[-1] #返回最后一项元素 \u0026#39;C\u0026#39; 追加元素到末尾 \u0026gt;\u0026gt;\u0026gt; classmates.append(\u0026#39;D\u0026#39;) \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;] 插入元素到指定位置 \u0026gt;\u0026gt;\u0026gt; classmates.insert(1, \u0026#39;Here\u0026#39;) #在指定位置放入元素 \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;A\u0026#39;, \u0026#39;Here\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;] 删除元素 使用pop 指定索引地址删除，返回删除的值\n\u0026gt;\u0026gt;\u0026gt; classmates.pop(0) \u0026#39;A\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;Here\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;] 使用del 指定索引地址删除，无返回值\n\u0026gt;\u0026gt;\u0026gt; del classmates[1] \u0026gt;\u0026gt;\u0026gt;classmates [\u0026#39;Here\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;] 使用remove 删除指定值的第一次出现，无返回值\n\u0026gt;\u0026gt;\u0026gt; classmates.remove(\u0026#39;C\u0026#39;) \u0026gt;\u0026gt;\u0026gt;classmates [\u0026#39;Here\u0026#39;, \u0026#39;D\u0026#39;] list的截取与拼接 截取 将冒号:分别放在索引地址前（后），即可截取该位置之前（之后）的元素\n\u0026gt;\u0026gt;\u0026gt; t = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] \u0026gt;\u0026gt;\u0026gt; t[1:] [\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] #截取后面会包含当前元素 \u0026gt;\u0026gt;\u0026gt; t[:1] [\u0026#39;a\u0026#39;] 拼接 \u0026gt;\u0026gt;\u0026gt;t += [1, 2, 3] [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, 1, 2, 3] list中元素为list list元素可以是另外一个list，类似二元数组\n\u0026gt;\u0026gt;\u0026gt; partner = [1, 2, 3] [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; classmates.append(partner) [\u0026#39;Here\u0026#39;, \u0026#39;D\u0026#39;, [1, 2, 3]] 此时classmates只有3个元素\n\u0026gt;\u0026gt;\u0026gt; len(classmates) 3 \u0026gt;\u0026gt;\u0026gt;len (partner) 3 要访问partner中元素\n\u0026gt;\u0026gt;\u0026gt; classmates[2][1] 2 类似还可以成为三维、四维……数组\nlist中元素的数据类型不同 同一list中可包含不同数据类型元素\n\u0026gt;\u0026gt;\u0026gt; classmates.append(True) [\u0026#39;Here\u0026#39;, \u0026#39;D\u0026#39;, [1, 2, 3], True] 空的list 如果一个list中一个元素也没有，就是一个空的list，它的长度为0\n\u0026gt;\u0026gt;\u0026gt; test = [] \u0026gt;\u0026gt;\u0026gt; len(test) 0 list相关函数\u0026amp;方法 函数   len(list) list元素个数\n  max(list) 返回list元素最大值\n  min(list) 返回list元素最小值\n  list(seq) 将元组tuble转换成list\n  方法  list.append(obj) 在列表末尾添加新的对象 list.count(obj) 统计某个元素在列表中出现的次数 list.extend(seq) 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） list.index(obj) 从列表中找出某个值第一个匹配项的索引位置 list.insert(index, obj) 将对象插入列表 list.pop([index=-1]) 移除列表中的一个元素**（默认最后一个元素）**，并且返回该元素的值 list.remove(obj) 移除列表中某个值的第一个匹配项 list.reverse() 反向列表中元素 list.sort( key=None, reverse=False) 对原列表进行排序 key \u0026ndash; 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序 reverse \u0026ndash; 排序规则，reverse = True 降序， reverse = False 升序（默认） list.clear() 清空列表 list.copy()  ","date":"2019-06-20T13:44:48+08:00","permalink":"https://konosuba.xyz/blog/python%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8Blist%E5%88%97%E8%A1%A8/","title":"Python常见数据类型——List列表"},{"content":"数字图像数据可以用矩阵来表示，因此可以采用矩阵理论和矩阵算法对数字图像进行分析和处理。\n在使用OpenCV时，要特别注意其坐标轴与普通x-y轴的转换，我在实际使用过程中就经常在这上面翻车，还是不熟练\n图为坐标对照图，转自CSDN，具体忘了\n","date":"2019-06-06T00:35:00+08:00","permalink":"https://konosuba.xyz/blog/%E5%9B%BE%E5%83%8F%E5%9F%BA%E7%A1%80-%E5%9B%BE%E5%83%8F%E7%9F%A9%E9%98%B5/","title":"图像基础-图像矩阵"},{"content":" 部分内容引用 CSDN爬金字塔的人\n 计算机中， 通常以矩阵形式存储图像，根据颜色和灰度多少可以分为灰度图像、二值图像、索引图像和RGB图像\n灰度图像   矩阵元素取值范围为[0, 255] （0-黑，255-白），数据类型一般为8位无符号整数【unit8】\n  某些领域（如医学成像）采用【unit16】和【int16】数据类型\n  对于计算灰度的操作（如**傅里叶变换**），使用【double】和【single】类型；若图像是【double】或【single】，灰度图像的值通常被归一化标定位【0-1】范围内，**0代表黑色，1代表白色**，0到1之间的小数表示不同的灰度等级。\n  二值图像可以看成是灰度图像的一个特例。\n  二值图像   一幅二值图像的二维矩阵仅由0、1两个值构成，计算机中二值图像的数据类型通常为1个二进制位\n  在MATLAB中，二值图像具有非常特殊的意义，只有逻辑数据类型【logical】才被认为是二值图像，就算是只包含0和1的数据类的数组（例如【uint8】），在MATLAB中都不认为是二值图像。可以使用logical将其他类型的数组转换为二值图像：B = logical（A）\n  索引图像   包括一个数据矩阵X，一个颜色映像矩阵Map。Map是一个包含三列，若干行的数据阵列，其中每个元素的值均为[0，1]之间的双精度浮点型数据。每一行分别表示红， 绿，蓝的颜色值。\n  在MATLAB中，索引图像是从像素值到颜色映射表值的“直接映射”。像素颜色由数据矩阵X作为索引指向矩阵Map进行索引，例如，值1指向矩阵Map中的第一行，值2指向第二行，以此类推。\n  一般索引图像只能显示256种颜色（由数据矩阵X的取值范围决定），与灰度图像不同的是，灰度图像的颜色表的值是从0到255连续的值，所以灰度图像的数据我们即可以看成是实际的像素值，也可以看成是索引值。\n  索引图的优点是存储所需容量小，且索引图像一般用于存放色彩要求比较简单的图像，如Windows中色彩构成比较简单的壁纸多采用索引图像存放，如果图像的色彩比较复杂，就要用到RGB真彩色图像。\n  RGB图像   RGB图像每一个像素的颜色值（由RGB三原色表示）直接存放在图像矩阵中\n  一副大小为MN的RGB图像需要3个MN大小的矩阵表示，每一个矩阵代表一个颜色通道。RGB图像的数据类型一般为【unit】（或【double】），通常用于表示和存放真彩色图像（2^24种颜色），也可存灰度图像（三个通道的值都一样）\n  在MATLAB中用cat操作将3通道合成彩色图像：rab_image = cat(3, R, G, B);\n  MATLAB中用下面这些命令可以提取出三个通道的图像：\n  R = rgb_image（：，：，1）; G = rgb_image（：，：，2）; B = rgb_image（：，：，3）; ","date":"2019-06-06T00:00:49+08:00","permalink":"https://konosuba.xyz/blog/%E5%9B%BE%E5%83%8F%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/","title":"图像基础-图像分类"}]