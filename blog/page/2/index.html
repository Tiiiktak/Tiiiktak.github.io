<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
    <title>Posts - Tiiktak&#39;s</title>
    
    <meta name="description" content="Hey You">
    <meta name="author" content="">
    
    <link href="https://konosuba.xyz/css/github-gist.min.css" rel="stylesheet">
    <link href="https://konosuba.xyz/css/style.css" rel="stylesheet">
    
    <link rel="apple-touch-icon" href="https://konosuba.xyz/img/apple-touch-icon.png">
    <link rel="icon" href="https://konosuba.xyz/img/favicon.ico">
    
    <meta name="generator" content="Hugo 0.55.6" />
    
    <link rel="alternate" type="application/atom+xml" href="https://konosuba.xyz/index.xml" title="Tiiktak&#39;s">
    
    
    
  </head>
  <body class="list">
    <header class="header">
      <div class="wrap">
        
        <p class="logo"><a href="https://konosuba.xyz/">Tiiktak&#39;s</a></p>
        
        
        <button class="menu-toggle" type="button"></button>
        
      </div>
    </header>
    
    <nav class="nav">
      <ul class="menu">
        
        <li>
          <a href="/about/">About</a>
        </li>
        
      </ul>
    </nav>
    
    <main class="main">



<header class="page-header">
  <h1>
  Posts
  </h1>
</header>






<article class="post-entry">
  <header class="entry-header">
    <h2>Pytorch中的损失函数Loss Function</h2>
  </header>
  <section class="entry-content">
   <p>由于Pytorch中使用mini-batch进行计算，因此其损失函数的计算结果会对mini-batch取平均
常见的Pytorch中内置的损失函数有：
nn.L1Loss 计算input与output的差的绝对值，input与output应该是同一维度，得到的loss也是相应维度
nn.NLLLoss  Negative Log Likelihood
 class torch.nn.NLLLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction=&#39;mean&#39;)  常用于多分类任务。在NLLLoss输入input之前，我们需要对input进行log_softmax处理(即将input转换成概率分布的形式，并且取对数，底数为e)
计算公式
loss(input, class) = -input[class]  NLLLoss中如果传递了weight参数，会对损失进行加权，公式就变成了
loss(input, class) = -weight[class] * input[class]  nn.MSELoss  Mean Square Error
 计算input与ouput之间的均方差
nn.CrossEntropyLoss 多分类用的交叉熵损失合函数，将LogSoftMax和nn.NLLLoss集成到一个类中，nn.CrossEntropyLoss可以自动对input进行logSoftMax操作，可以理解为CrossEntropyLoss()=log_softmax() &#43; NLLLoss()
传入weight参数后
一般多分类的情况会使用这个损失函数
nn.BCELoss  Binary Cross Entropy
 计算input与output之间的二进制交叉熵
添加weight后
用的时候需要在该层前面加上 Sigmoid 函数...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.15</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/pytorch%E4%B8%AD%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0loss-function/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Pytorch_数据集的创建和加载</h2>
  </header>
  <section class="entry-content">
   <p>PyTorch通过torch.utils.data对一般常用的数据加载进行了封装，可以很容易地实现多线程数据预读和批量加载。
可以通过dataset定义数据集，并使用Datalorder载入和遍历数据集
Dataset Dataset是一个抽象类，为了能够方便的读取，需要将要使用的数据包装为Dataset类。
自定义的Dataset需要继承它并且实现两个成员方法：
 __getitem__() 该方法定义用索引(0 到 len(self))获取一条数据或一个样本 __len__() 该方法返回数据集的总长度  下面使用kaggle上的一个竞赛bluebook for bulldozers自定义一个数据集，用里面的数据字典来做说明（因为条数少）
from torch.utils.data import Dataset import pandas as pd #定义一个数据集 class BulldozerDataset(Dataset): # 实现初始化方法，在初始化的时候将数据读载入 def __init__(self, csv_file): self.df=pd.read_csv(csv_file) # 返回df的长度 def __len__(self): return len(self.df) # 根据 idx 返回一行数据 def __getitem__(self, idx): return self.df.iloc[idx].SalePrice  至此，我们的数据集已经定义完成了，我们可以实例话一个对象访问他
ds_demo = BulldozerDataset(&#39;median_benchhmark.csv&#39;) print(len(ds_demo)) # 11573 print(ds_demo[0]) # 24000.0  Dataloader DataLoader为我们提供了对Dataset的读取操作，常用参数有：batch_size(每个batch的大小)、 shuffle(是否进行shuffle操作)、 num_workers(加载数据的时候使用几个子进程)。下面做一个简单的操作
dl = torch.utils.data.DataLoader(ds_demo, batch_size=10, shuffle=True, num_workers=0)  DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.15</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/pytorch_%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E5%8A%A0%E8%BD%BD/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Pytorch_torchvision</h2>
  </header>
  <section class="entry-content">
   <p>torchvision.models torchvision不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用，或者在进行迁移学习 torchvision.models模块的 子模块中包含以下模型结构。 - AlexNet - VGG - ResNet - SqueezeNet - DenseNet
torchvision.datasets 这其中所有的数据集都是torch.utils.data.Dataset的子类，它们都具有__getitem__和__len__实现的方法。因此，它们都可以传递给torch.utils.data.DataLoader，它使用torch.multiprocessing并行加载多个样本。
torchvision.transforms 提供了一般的图像转换操作类，用作数据处理和数据增强
其中都是常见的图像转换，可以通过Compose将他们链接在一起
from torchvision import transforms as transforms transform = transforms.Compose([ transforms.RandomCrop(32, padding=4), #先四周填充0，在把图像随机裁剪成32*32 transforms.RandomHorizontalFlip(), #图像一半的概率翻转，一半的概率不翻转 transforms.RandomRotation((-45,45)), #随机旋转 transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.229, 0.224, 0.225)), #R,G,B每层的归一化用到的均值和方差 ])  此外还有torchvision.transforms.functional模块，可对转换进行细粒度控制，这对于要构建一个更复杂的 transformation pipeline（例如在segmentation tasks分段任务中）很有帮助
torchvision.transforms.Normalize(mean, std, inplace=False) 用均值和标准差对张量图像进行归一化。
给定n个通道的均值: (M1,...,Mn) 和标准差:(S1,..,Sn), 这个转换将归一化输入torch.*Tensor的每个通道。例如: input[channel] = (input[channel] - mean[channel]) / std[channel]
 Note: 这种变换的作用不适当，即它不会改变输入张量
 torchvision.utils torchvision....</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.14</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/pytorch_torchvision/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Pytorch学习笔记_4_训练一个分类器</h2>
  </header>
  <section class="entry-content">
   <p>关于数据 一般来说，对于图像、文本、音频或视频数据，可以使用标准的Python包来将这些数据加载为numpy array，之后可以将这些array转换为torch.*Tensor
 对于图像，Pillow、OpenCV包 音频，scipy、librosa包 文本，可以使用原始Python和Cython加载，或NLKT和SpaCy  特别的，对于视觉任务，有一个包torchvision，其中包含了处理类似Imagnet, CIFAR10, MNIST等常见数据集的方法，以及图像转换器，如torchvision.datasets和torch.utils.data.DataLoader
torchvision包不仅提供了巨大的便利，也避免了代码的重复。
在这里使用CIFAR10数据集，它有如下10个类别 ：‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。
CIFAR-10的图像都是 3x32x32 大小的，即，3颜色通道，32x32像素。
训练一个图像分类器  使用torchvision加载和归一化CIFAR10训练集和测试集 定义一个卷积神经网络 定义损失函数 用训练集训练网络 用测试集测试网络  1.读取和归一化 CIFAR10 使用torchvision可以非常容易得加载CIFAR10
import torch import torchvision import torchvision.transforms as transforms  torchvision的输出是 [0,1]的PILImage图像，把它转化为归一化范围为[-1, 1]的张量
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 下载数据并加载到loader中 trainset = torchvision.datasets.CIFAR10(root=&#39;./data&#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = torchvision....</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.13</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_4_%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E5%88%86%E7%B1%BB%E5%99%A8/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Pytorch_linear</h2>
  </header>
  <section class="entry-content">
   <p> Linear 对输入数据应用线性变换：y = xA^T &#43; b
torch.nn.Linear(in_features, out_features, bias=True)  参数  in_features 每个输入样本的大小 out_features 每个输出样本的大小 bias 若为False，layer不会学习附加偏差b  shape  输入: (N, ∗, H_in)，其中 ∗ 代表任意数量的附加维度，H_in = in_features
 输出: (N, *, H_out)，除了最后一个维度，其余都与输入相同，H_out = out_features
  ...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.12</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/pytorch_linear/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Pytorch_nn.Conv2d</h2>
  </header>
  <section class="entry-content">
   <p> Conv2d torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode=&#39;zeros&#39;)   in_channels 输入数据通道数 out_channels 输出数据通道数 kennel_size 卷积核大小，int或tuple stride 步长 padding 每个维度零填充的数量 dilation 内核点之间的距离，也称à trous algorithm groups 控制inputs与outputs间的连接 &gt; * groups=1，所有输入都卷积到输出 &gt; * groups=2，并排设置两个conv层，每个层查看一半的输入通道，并生成一半的输出通道，然后将两者连接起来 &gt; * groups=in_channels，每个输入通道都有它自己的filter，size为[out_channels/in_channels]  ...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.12</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/pytorch_nn.conv2d/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Python面向对象_super()函数</h2>
  </header>
  <section class="entry-content">
   <p>super() super()是用于调用父类（超类）的一个方法
用于解决多重继承问题：直接用类名调用父类方法在使用单继承时没有问题，但若使用多继承，会涉及到查找顺序（MRO）、重复调用（钻石继承）等问题
 MRO 就是类的方法解析顺序表, 其实也就是继承父类方法时的顺序表。
 语法 super(type[, object-or-type])  参数  type 类
 object-or-type 类，一般是self
  在 Python3 中：super().xxx
在 Python2 中：super(Class, self).xxx
两者等价
示例 class Bird: def __init__(self): self.hungry = True def eat(self): if self.hungry: print(&#39;Ahahahah&#39;) else: print(&#39;No thanks!&#39;) class SongBird(Bird): def __init__(self): self.sound = &#39;Squawk&#39; def sing(self): print(self.sound) sb = SongBird() sb.sing() # 能正常输出&#39;Squawk&#39; sb.eat() # 报错，因为 SongBird 中没有 hungry 特性  使用super解决：...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.12</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1_super%E5%87%BD%E6%95%B0/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Pytorch学习笔记_3_构建一个神经网络</h2>
  </header>
  <section class="entry-content">
   <p>Neural Networks  神经网络可以通过使用torch.nn包来创建
 nn依赖于autograd来定义模型并求导。
 一个nn.Module类包含各个层和一个forward(input)前向传播方法，该方法返回output
  例如这个分类数字图像的网络：
这是个简单的前馈神经网络，它接受一个输入，然后一层接一层的传递，最后输出计算结果
一个神经网络的典型训练过程：
 定义包含一些可学习的参数（或权重）的神经网络 在数据集上迭代 通过神经网络处理输入 计算损失函数（预测值与实际值的差值大小） 将梯度反向传播回网络的参数 更新网络参数，主要使用一个简单的更新法则：weight = weight - learning_rate * gradient   另参见：konosuba.xyz/blog/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4
 定义网络 import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): # 构造方法 super().__init__() # 复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数 # 卷积层 self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) # fc(full_connect)全连接函数，均为线性函数 y = Wx &#43; b self....</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.12</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_3_%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Pytorch学习笔记_2_Autograd自动求导机制</h2>
  </header>
  <section class="entry-content">
   <p>Autograd 自动求导机制 PyTorch 中所有神经网络的核心是 autograd 包。
autograd 包为张量上的所有操作提供了自动求导。它是一个在运行时定义的框架，可以通过代码的运行来决定反向传播的过程，并且每次迭代可以是不同的。
通过一些示例来了解
Tensor 张量 torch.tensor是这个包的核心类。
 设置.requires_grad为True，会追踪所有对于该张量的操作。计算完成后调用.backward()，可以自动计算所有的梯度，并自动累计到.grad属性中   事实上即使.requires_grad为True并不意味着.grad一定不为None
  可以调用.detach()将该张量与计算历史记录分离，并禁止跟踪它将来的计算记录
 为防止跟踪历史记录（和使用内存），可以将代码块包装在with torch.no_grad():中。这在评估模型时特别有用，因为模型可能具有requires_grad = True的可训练参数，但是我们不需要梯度计算。
  Function类 Tensor 和 Function 互相连接并生成一个非循环图，它表示和存储了完整的计算历史。
每个张量都有一个.grad_fn属性，对张量进行操作后，grad_fn会引用一个创建了这个Tensor类的Function对象（除非这个张量是用户手动创建的，此时，这个张量的 grad_fn 是 None）
 leaf Tensors 叶张量
Tensor中有一属性is_leaf，当它为True有两种情况：
 按照惯例，requires_grad = False 的 Tensor
 requires_grad = True 且由用户创建的 Tensor。这意味着它们不是操作的结果且grad_fn = None
  只有leaf Tensors叶张量在反向传播时才会将本身的grad传入backward()的运算中。要想得到non-leaf Tensors非叶张量在反向传播时的grad，可以使用retain_grad()
 如果需要计算导数，可以在Tensor上调用.backward()：若Tensor是一个标量（即包含一个元素数据）则不需要为backward()指定任何参数， 但是如果它有更多的元素，需要指定一个gradient 参数来匹配张量的形状。
x = torch.ones(2, 2, requires_grad=True) print(x) # Output: # tensor([[1....</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.11</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_2_autograd%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E6%9C%BA%E5%88%B6/"></a>
</article>

<article class="post-entry">
  <header class="entry-header">
    <h2>Pytorch学习笔记_1_tensor张量</h2>
  </header>
  <section class="entry-content">
   <p>Tensors Tensors与Numpy中的ndarrays类似
torch.new_* 与 torch.*_like 前者创建的对象会保持原有的属性（如dtype），但shape不同
&gt;&gt;&gt; x = torch.zeros(5, 3, dtype=torch.double) &gt;&gt;&gt; x.new_ones(2, 3) tensor([[1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) &gt;&gt;&gt; x.new_ones(2, 3, dtype=torch.long) tensor([[1, 1, 1], [1, 1, 1]])  后者可以创建shape相同，属性不同的对象
&gt;&gt;&gt; x = torch.zeros(5, 3, dtype=torch.double) &gt;&gt;&gt; torch.ones_like(x) tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) &gt;&gt;&gt; torch.ones_like(x, dtype=torch.long) tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]])  获得size 使用size方法与Numpy的shape属性返回的相同，张量也支持shape属性...</p>
  </section>
  <footer class="entry-footer">
    <time>2020.2.11</time>
  </footer>
  <a class="entry-link" href="https://konosuba.xyz/blog/pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_1_tensor%E5%BC%A0%E9%87%8F/"></a>
</article>




<footer class="page-footer">
  <nav class="pagination">
    
    <a class="prev" href="/blog/">← Prev Page</a>
    
    
    <a class="next" href="/blog/page/3/">Next Page →</a>
    
  </nav>
</footer>


</main>
<footer class="footer">
  <span>&copy; 2020 <a href="https://konosuba.xyz/">Tiiktak&#39;s</a></span>
  <span>&middot;</span>
  <span>Powered by <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>️</span>
  <span>&middot;</span>
  <span>Theme️ <a href="https://github.com/nanxiaobei/hugo-paper" rel="noopener" target="_blank">Paper</a></span>
</footer>
<script src="https://konosuba.xyz/js/instantclick.min.js" data-no-instant></script>
<script data-no-instant>InstantClick.init();</script>
<script src="https://konosuba.xyz/js/highlight.min.js" data-no-instant></script>
<script data-no-instant>
  let body;
  function menuToggleListener() {
    body.classList.toggle('blur');
  }
  function setMenuToggleListener() {
    const menuToggle = document.querySelector('.menu-toggle');
    if (!menuToggle) return;
    body = document.querySelector('body');
    menuToggle.addEventListener('click', menuToggleListener);
  }

  hljs.initHighlightingOnLoad();
  setMenuToggleListener();

  InstantClick.on('change', function () {
    document.querySelectorAll('pre code').forEach((block) => {
      hljs.highlightBlock(block);
    });
    setMenuToggleListener();
  });
</script>
</body>
</html>

