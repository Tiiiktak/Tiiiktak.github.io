<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
    <title>Pytorch学习笔记_4_训练一个分类器 - Tiiktak&#39;s</title>
    
    <meta name="description" content="关于数据 一般来说，对于图像、文本、音频或视频数据，可以使用标准的Python包来将这些数据加载为numpy array，之后可以将这些array转换为torch.*Tensor
 对于图像，Pillow、OpenCV包 音频，scipy、librosa包 文本，可以使用原始Python和Cython加载，或NLKT和SpaCy  特别的，对于视觉任务，有一个包torchvision，其中包含了处理类似Imagnet, CIFAR10, MNIST等常见数据集的方法，以及图像转换器，如torchvision.datasets和torch.utils.data.DataLoader
torchvision包不仅提供了巨大的便利，也避免了代码的重复。
在这里使用CIFAR10数据集，它有如下10个类别 ：‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。
CIFAR-10的图像都是 3x32x32 大小的，即，3颜色通道，32x32像素。
训练一个图像分类器  使用torchvision加载和归一化CIFAR10训练集和测试集 定义一个卷积神经网络 定义损失函数 用训练集训练网络 用测试集测试网络  1.读取和归一化 CIFAR10 使用torchvision可以非常容易得加载CIFAR10
import torch import torchvision import torchvision.transforms as transforms  torchvision的输出是 [0,1]的PILImage图像，把它转化为归一化范围为[-1, 1]的张量
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 下载数据并加载到loader中 trainset = torchvision.datasets.CIFAR10(root=&#39;./data&#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = torchvision.">
    <meta name="author" content="">
    
    <link href="https://konosuba.xyz/css/github-gist.min.css" rel="stylesheet">
    <link href="https://konosuba.xyz/css/style.css" rel="stylesheet">
    
    <link rel="apple-touch-icon" href="https://konosuba.xyz/img/apple-touch-icon.png">
    <link rel="icon" href="https://konosuba.xyz/img/favicon.ico">
    
    <meta name="generator" content="Hugo 0.55.6" />
    
    <link rel="alternate" type="application/atom+xml" href="https://konosuba.xyz/index.xml" title="Tiiktak&#39;s">
    
    
    
  </head>
  <body class="single">
    <header class="header">
      <div class="wrap">
        
        <p class="logo"><a href="https://konosuba.xyz/">Tiiktak&#39;s</a></p>
        
        
        <button class="menu-toggle" type="button"></button>
        
      </div>
    </header>
    
    <nav class="nav">
      <ul class="menu">
        
        <li>
          <a href="/about/">About</a>
        </li>
        
      </ul>
    </nav>
    
    <main class="main">


<article class="post-single">
  <header class="post-header">
    <h1 class="post-title">Pytorch学习笔记_4_训练一个分类器</h1>
    <div class="post-meta">2020.2.13</div>
  </header>
  <div class="post-content">

<h1 id="关于数据">关于数据</h1>

<p>一般来说，对于图像、文本、音频或视频数据，可以使用标准的Python包来将这些数据加载为<code>numpy array</code>，之后可以将这些<code>array</code>转换为<code>torch.*Tensor</code></p>

<ul>
<li>对于图像，<code>Pillow</code>、<code>OpenCV</code>包</li>
<li>音频，<code>scipy</code>、<code>librosa</code>包</li>
<li>文本，可以使用原始<code>Python</code>和<code>Cython</code>加载，或<code>NLKT</code>和<code>SpaCy</code></li>
</ul>

<p>特别的，对于视觉任务，有一个包<code>torchvision</code>，其中包含了处理类似Imagnet, CIFAR10, MNIST等常见数据集的方法，以及图像转换器，如<code>torchvision.datasets</code>和<code>torch.utils.data.DataLoader</code></p>

<p><code>torchvision</code>包不仅提供了巨大的便利，也避免了代码的重复。</p>

<p>在这里使用CIFAR10数据集，它有如下10个类别 ：‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。</p>

<p>CIFAR-10的图像都是 3x32x32 大小的，即，3颜色通道，32x32像素。</p>

<p><img src="https://i.loli.net/2020/02/13/XdwFTbis2NgImfl.png" alt="cifar10" /></p>

<h1 id="训练一个图像分类器">训练一个图像分类器</h1>

<ol>
<li>使用<code>torchvision</code>加载和归一化CIFAR10训练集和测试集</li>
<li>定义一个卷积神经网络</li>
<li>定义损失函数</li>
<li>用训练集训练网络</li>
<li>用测试集测试网络</li>
</ol>

<h2 id="1-读取和归一化-cifar10">1.读取和归一化 CIFAR10</h2>

<p>使用<code>torchvision</code>可以非常容易得加载CIFAR10</p>

<pre><code class="language-python">import torch
import torchvision
import torchvision.transforms as transforms
</code></pre>

<p><code>torchvision</code>的输出是 [0,1]的PILImage图像，把它转化为归一化范围为[-1, 1]的张量</p>

<pre><code class="language-python">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

# 下载数据并加载到loader中
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
'''
Output:
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
Extracting ./data/cifar-10-python.tar.gz to ./data
Files already downloaded and verified
'''
</code></pre>

<p>我们展示一些训练图像</p>

<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy

def imshow(img):
    img = img / 2 + 0.5 # 未归一化
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2,0)))

# 将数据转换为迭代器
dataiter = iter(trainloader)
images, labels = dataiter.next()

# 展示图象
imshow(torchvision.utils.make_grid(images))
# 展示图像标签
print(''.join('%5s' % classes[labels[j]] for j in range(4)))
</code></pre>

<p><img src="https://i.loli.net/2020/02/14/Tr3mXz987UR4Y6P.png" alt="traindata" /></p>

<h2 id="2-定义一个卷积神经网络">2.定义一个卷积神经网络</h2>

<p>从之前的[神经网络一节]()复制神经网络代码，并修改为输入3通道图像。</p>

<pre><code class="language-python">import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()
</code></pre>

<h2 id="3-定义损失函数和优化器">3.定义损失函数和优化器</h2>

<p>使用交叉熵作为损失函数，使用带动量的随机梯度下降优化</p>

<pre><code class="language-python">import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)
</code></pre>

<h2 id="4-训练网络">4.训练网络</h2>

<p>我们只需要在数据迭代器上循环，将数据输入给网络，并优化</p>

<pre><code class="language-python">for epoch in range(2):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data

        # 梯度置零
        optimizer.zero_grad()

        # 获得输出-&gt;计算损失-&gt;反向传播-&gt;优化
        outputs = net(input)
        loss = critertion(outputs, labels) 
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 2000 == 1999:
            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
'''
Output:
[1,  2000] loss: 2.216
[1,  4000] loss: 1.863
[1,  6000] loss: 1.669
[1,  8000] loss: 1.565
[1, 10000] loss: 1.524
[1, 12000] loss: 1.440
[2,  2000] loss: 1.396
[2,  4000] loss: 1.350
[2,  6000] loss: 1.349
[2,  8000] loss: 1.293
[2, 10000] loss: 1.312
[2, 12000] loss: 1.270
Finished Training
'''
</code></pre>

<blockquote>
<p>快速保存我们训练的模型:</p>

<pre><code class="language-python">&gt; PATH = './cifar_net.pth'
&gt; torch.save(net.state_dict(), PATH)
&gt; ```

## 5.用测试集测试网络

我们在整个训练集上进行了2次训练，但是我们需要检查网络是否从数据集中学习到有用的东西。 通过预测神经网络输出的类别标签与实际情况标签进行对比来进行检测。 如果预测正确，我们把该样本添加到正确预测列表。 

第一步，显示测试集中的图片并熟悉图片内容。

```python
dataiter = iter(testloader)
images, labels = dataiter.next()

# 显示图片
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))
</code></pre>
</blockquote>

<p><img src="https://i.loli.net/2020/02/14/bXLxa3WwH2cD7rC.png" alt="testdata" /></p>

<p>再来看看神经网络预测的结果</p>

<pre><code class="language-python">ouputs = net(images)

# 输出是10个标签的概率，选取概率最高的那个标签
_, predicted = torch.max(outputs, 1) # 返回每一行中最大值的元素 _ 及其索引 predicted

print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))
'''
Output:
Predicted:    cat   car   car  ship
'''
</code></pre>

<p>再看看网络在测试集上的结果：</p>

<pre><code class="language-python">correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))
'''
Output:
Accuracy of the network on the 10000 test images: 54 %
'''
</code></pre>

<p>再分别看看不同标签的学习情况：</p>

<pre><code class="language-python">class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1


for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))
'''
Output:
Accuracy of plane : 56 %
Accuracy of   car : 73 %
Accuracy of  bird : 42 %
Accuracy of   cat : 33 %
Accuracy of  deer : 34 %
Accuracy of   dog : 62 %
Accuracy of  frog : 57 %
Accuracy of horse : 62 %
Accuracy of  ship : 52 %
Accuracy of truck : 73 %
'''
</code></pre>

<h1 id="在gpu上训练">在GPU上训练</h1>

<p>把一个神经网络移动到GPU上训练就像把一个Tensor转换GPU上一样简单。并且这个操作会递归遍历有所模块，并将其参数和缓冲区转换为CUDA张量。</p>

<pre><code class="language-python">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)

# 确认我们的电脑支持CUDA，然后显示CUDA信息：

print(device)
# Output:
# cuda:0
</code></pre>

<p>假定<code>device</code>是CUDA设备。</p>

<p>然后这些方法将递归遍历所有模块并将模块的参数和缓冲区 转换成CUDA张量：</p>

<pre><code class="language-python">net.to(device)
</code></pre>

<p>记住：<code>inputs</code>, <code>targets</code> 和 <code>images</code> 也要转换。</p>

<pre><code class="language-python">inputs, labels = inputs.to(device), labels.to(device)
</code></pre>

<p>为什么我们没注意到GPU的速度提升很多？那是因为网络非常的小。</p>

<p><strong>实践:</strong> 尝试增加你的网络的宽度（第一个<code>nn.Conv2d</code>的第2个参数，第二个<code>nn.Conv2d</code>的第一个参数，它们需要是相同的数字），看看你得到了什么样的加速。</p>
</div>
  <footer class="post-footer">
    
  </footer>
  
  
  
  <div id="disqus_thread"></div>
  <script>
    var disqus_shortname = 'tiiktak';
    (function() {
      var d = document, s = d.createElement('script');
      s.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>
    Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
  
  
  
</article>

</main>
<footer class="footer">
  <span>&copy; 2020 <a href="https://konosuba.xyz/">Tiiktak&#39;s</a></span>
  <span>&middot;</span>
  <span>Powered by <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>️</span>
  <span>&middot;</span>
  <span>Theme️ <a href="https://github.com/nanxiaobei/hugo-paper" rel="noopener" target="_blank">Paper</a></span>
</footer>
<script src="https://konosuba.xyz/js/instantclick.min.js" data-no-instant></script>
<script data-no-instant>InstantClick.init();</script>
<script src="https://konosuba.xyz/js/highlight.min.js" data-no-instant></script>
<script data-no-instant>
  let body;
  function menuToggleListener() {
    body.classList.toggle('blur');
  }
  function setMenuToggleListener() {
    const menuToggle = document.querySelector('.menu-toggle');
    if (!menuToggle) return;
    body = document.querySelector('body');
    menuToggle.addEventListener('click', menuToggleListener);
  }

  hljs.initHighlightingOnLoad();
  setMenuToggleListener();

  InstantClick.on('change', function () {
    document.querySelectorAll('pre code').forEach((block) => {
      hljs.highlightBlock(block);
    });
    setMenuToggleListener();
  });
</script>
</body>
</html>

