<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Tiiktak&#39;s</title>
    <link>https://konosuba.xyz/blog/</link>
    <description>Recent content in Blogs on Tiiktak&#39;s</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>cn</language>
    <lastBuildDate>Tue, 30 Mar 2021 18:33:16 +0800</lastBuildDate><atom:link href="https://konosuba.xyz/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用vnc查看Ubuntu服务器的远程桌面</title>
      <link>https://konosuba.xyz/blog/vnc_ubuntu_server/</link>
      <pubDate>Tue, 30 Mar 2021 18:33:16 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/vnc_ubuntu_server/</guid>
      <description>1. 安装桌面 2. 安装gnome-session-flashback： sudo apt-get install gnome-session-flashback3. 安装VNC Server sudo apt-get install tigervnc-standalone-server tigervnc-xorg-extension4. VNC配置桌面环境 vim ~/.vnc/xstartup#!/bin/sh unset SESSION_MANAGER#unset DBUS_SESSION_BUS_ADDRESS #测试中发现如果去掉该行注释 桌面不会出现export XKL_XMODMAP_DISABLE=1export XDG_CURRENT_DESKTOP=&amp;quot;GNOME-Flashback:GNOME&amp;quot;export XDG_MENU_PREFIX=&amp;quot;gnome-flashback-&amp;quot;[ -x /etc/vnc/xstartup ] &amp;amp;&amp;amp; exec /etc/vnc/xstartup[ -r $HOME/.Xresources ] &amp;amp;&amp;amp; xrdb $HOME/.Xresourcesxsetroot -solid grey #设置背景色vncconfig -iconic &amp;amp;gnome-terminal &amp;amp; #连接后会直接打开一个terminal窗口nautilus &amp;amp; #连接后会直接打开一个文件窗口gnome-session --session=gnome-flashback-metacity --disable-acceleration-check &amp;amp;sudo chmod +x ~/.vnc/xstartup5. Start vncserver :2 -localhost no #2为端口号，no表示非局域网内账户也可访问vncserver -kill :2 #关闭  参考：Ubuntu 20.</description>
    </item>
    
    <item>
      <title>树莓派4B安装Pytorch, torchvision</title>
      <link>https://konosuba.xyz/blog/raspberripi_pytorch_install/</link>
      <pubDate>Thu, 11 Feb 2021 12:14:03 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/raspberripi_pytorch_install/</guid>
      <description>Install Pytorch  Raspberry Pi 4B Linux raspberrypi 4.19.75-v7l+ #1270 SMP Tue Sep 24 18:51:41 BST 2019 armv7l GNU/Linux 2G RAM 16G DISK  增加交换内存   关闭内存交换: sudo dphys-swapfile swapoff
  修改配置文件 sudo vim /etc/dphys-swapfile，设置CONF_SWAPSIZE=4096
 这里虽然设置为4096，但free -m 查看仍然只有2G交换内存
   开启内存交换：sudo dphys-swapfile swapon
  检查：free -m，若swap无变换可尝试重启
  Pytorch依赖项 sudo apt install libopenblas-dev libblas-dev m4 cmake cython python3-yaml libatlas-base-devsudo apt-get install cython3 libatlas-base-dev m4 libblas-dev cmakesudo apt-get install python3-dev python3-setuptools python3-wheel python3-pillow python3-numpypip3 install numpy pyyamlFor raspberry pi 4 there may be an issue with the gcc and g++ version.</description>
    </item>
    
    <item>
      <title>树莓派4B安装ncnn</title>
      <link>https://konosuba.xyz/blog/raspberrypi_ncnn_install/</link>
      <pubDate>Wed, 10 Feb 2021 22:14:03 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/raspberrypi_ncnn_install/</guid>
      <description>1. clone ncnn code git clone https://github.com/Tencent/ncnn.git cd ncnn git submodule update --init 2. build cd ncnn mkdir -p build cd build sudo apt install build-essential git cmake libprotobuf-dev protobuf-compiler libvulkan-dev vulkan-utils libopencv-dev cmake -DCMAKE_BUILD_TYPE=Release -DNCNN_VULKAN=ON -DNCNN_SYSTEM_GLSLANG=ON -DNCNN_BUILD_EXAMPLES=ON -DCMAKE_TOOLCHAIN_FILE=../toolchains/pi3.toolchain.cmake -DPI3=ON ..  遇到如下问题：
CMake Warning at CMakeLists.txt:163 (message):GLSLANG_TARGET_DIR must be defined! NCNN_SYSTEM_GLSLANG will be turned off.CMake Error at CMakeLists.txt:188 (message):The submodules were not downloaded! Please update submodules with &amp;quot;gitsubmodule update --init&amp;quot; and try again.</description>
    </item>
    
    <item>
      <title>使用FPN实现内网穿透，公网访问内网服务器</title>
      <link>https://konosuba.xyz/blog/frp_ssh/</link>
      <pubDate>Mon, 11 Jan 2021 19:47:20 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/frp_ssh/</guid>
      <description>fpn  https://github.com/fatedier/frp
 公网服务器配置 公网服务器运行服务端程序
需要frps 与frps.ini两个文件即可，其中.ini为配置文件：
[common]bind_port = 7000	# 与客户端进行绑定的端口设置自启动 sudo vim /etc/systemd/system/frps.service	# 服务名即为frps修改文件内容如下：
[Unit]Description=frps daemonAfter=syslog.target network.targetWants=network.target[Service]Type=simpleExecStart={path/to/frps} -c {path/to/frps.ini}	# 注意使用绝对路径Restart= alwaysRestartSec=1min[Install]WantedBy=multi-user.target之后
#启动frpssystemctl daemon-reloadsystemctl start frps#设置为开机启动systemctl enable frps内网客户端配置 实验室服务器作为客户端
需要frpc与frpc.ini两个文件，其中.ini为配置文件：
[common]server_addr = &amp;lt;服务器公网ip&amp;gt;server_port = 7000	# 与frps.ini 文件中 bind_port 相同[ssh]type = tcplocal_ip = 127.</description>
    </item>
    
    <item>
      <title>Python虚拟环境 venv</title>
      <link>https://konosuba.xyz/blog/python_venv/</link>
      <pubDate>Fri, 08 Jan 2021 17:12:47 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python_venv/</guid>
      <description>创建虚拟环境 先cd到项目文件夹
python -m venv &amp;lt;虚拟环境名&amp;gt;将新建一个与虚拟环境同名文件夹
激活虚拟环境 source &amp;lt;虚拟环境名&amp;gt;/bin/activate命令行前方显示(&amp;lt;虚拟环境名&amp;gt;)
退出虚拟环境 deactivate</description>
    </item>
    
    <item>
      <title>MMDetection单机多卡训练出现问题</title>
      <link>https://konosuba.xyz/blog/mmdet_multiple_gpu_error/</link>
      <pubDate>Mon, 28 Dec 2020 15:52:48 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/mmdet_multiple_gpu_error/</guid>
      <description>使用的命令：
CUDA_VISIBLE_DEVICES=0,1,2,3 ./tools/dist_train.sh ${CONFIG_FILE} 4 --resume-from ${CHECKPOINT_FILE} 出现问题：
 模型train 1 epoch后挂掉，报错信息：  RuntimeError: replicas_[0].size() == rebuilt_param_indices_.size() INTERNAL ASSERT FAILED at &amp;#34;/pytorch/torch/csrc/distributed/c10d/reducer.cpp&amp;#34;:1326, please report a bug to PyTorch. rebuilt parameter indices size is not same as original model parameters size.321 versus 629160  pytorch github issue:https://github.com/pytorch/pytorch/issues/47050 mmcv issue: https://github.com/open-mmlab/mmcv/issues/636#issuecomment-722436575 解决方案：安装1.6版本pytorch，并重装mmcv  pip uninstall mmcv-full pip install mmcv-full python setup.py install </description>
    </item>
    
    <item>
      <title>在Linux中使用Clash</title>
      <link>https://konosuba.xyz/blog/clash_linux_tutorial/</link>
      <pubDate>Mon, 28 Dec 2020 15:49:53 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/clash_linux_tutorial/</guid>
      <description>安装  下载amd64文件：https://github.com/Dreamacro/clash/releases/ gzip -f -d linux-amd64-clash.gz 下载配置文件config.yaml到~/.config/clash 下载mmdb文件到~/.config/clash  配置（每次使用前）  ./clash启动 浏览器进入127.0.0.1:9090，Clash控制面板 选择一个节点 进入Ubuntu设置，网络设置，代理 Method设为Manual HTTP Proxy、HTTPs Proxy设置为127.0.0.1:7890 Socks Host设置为127.0.0.1:7891  wget配置代理  修改/etc/wgetrc，其中  https_proxy = http://127.0.0.1:7890/ http_proxy = http://127.0.0.1:7890/ ftp_proxy = http://127.0.0.1:7890/ 使用时，wget --proxy=on https://xxxx即可  </description>
    </item>
    
    <item>
      <title>Mpich2_安装 Ubuntu 20.04LTS</title>
      <link>https://konosuba.xyz/blog/mpich2_ubuntu/</link>
      <pubDate>Tue, 17 Nov 2020 09:20:26 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/mpich2_ubuntu/</guid>
      <description> Ubuntu 20.04 LTS    sudo aptitude install mpich
  mpiexec --version
 image-20201117092421973 
  new code
#include &amp;#34;mpi.h&amp;#34;#include &amp;lt;stdio.h&amp;gt; int main(void) { int rankID; int sizeNum; MPI_Init(0, 0); MPI_Comm_size(MPI_COMM_WORLD, &amp;amp;sizeNum); MPI_Comm_rank(MPI_COMM_WORLD, &amp;amp;rankID); printf(&amp;#34;Hello world! %d of total = %d\n&amp;#34;, rankID, sizeNum); MPI_Finalize(); return 0; }   mpicc demo_1.c -o demo_1
  mpirun -np 8 ./demo_1
  </description>
    </item>
    
    <item>
      <title>MSMPI Visual Studio 2019 配置</title>
      <link>https://konosuba.xyz/blog/msmpi_install/</link>
      <pubDate>Mon, 16 Nov 2020 22:14:03 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/msmpi_install/</guid>
      <description>Windows 10 Visual Studio 2019 MSMPI v10.1.2  step1. 安装MSMPI 前往官网下载.msi &amp;amp; .exe两个文件，按提示安装即可
安装过程会自动添加环境变量，可在PATH中看到
step2. 配置 VS2019 新建一个空项目，新建一个属性表
包含目录、库目录
  包含目录里面添加：C:\Program Files (x86)\Microsoft SDKs\MPI\Include;
  库目录的里面添加：C:\Program Files (x86)\Microsoft SDKs\MPI\Lib\x64;
  【C/C+ 附加包含目录】：添加$(MSMPI_INC);$(MSMPI_INC)\x64
  【链接器-常规-附加库目录】：添加$(MSMPI_LIB64)
  【链接器-输入-附加依赖项】：添加msmpi.lib
  step3. 测试 #include &amp;lt;iostream&amp;gt; #include &amp;lt;mpi.h&amp;gt;  int main(int argc, char* argv[]) { MPI_Init(&amp;amp;argc, &amp;amp;argv); int RankID; MPI_Comm_rank(MPI_COMM_WORLD, &amp;amp;RankID); if (0 == RankID) { int SendNum = 16; MPI_Send(&amp;amp;SendNum, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); } else if (1 == RankID) { int RecvNum = 0; MPI_Recv(&amp;amp;RecvNum, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); std::cout &amp;lt;&amp;lt; &amp;#34;Receive from rank 0: &amp;#34; &amp;lt;&amp;lt; RecvNum &amp;lt;&amp;lt; std::endl; } MPI_Finalize(); return 0; }  image-20201116223527189</description>
    </item>
    
    <item>
      <title>【课程作业】项目管理课程原型设计</title>
      <link>https://konosuba.xyz/blog/project_manage_course_prototype_design/</link>
      <pubDate>Thu, 08 Oct 2020 13:58:14 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/project_manage_course_prototype_design/</guid>
      <description>这是我的《软件过程与项目管理》 的期末作业，我们小组设计了一款校内出行APP，其中软件原型设计部分由我负责，使用PS和XD制作，在这里做个展示:laughing:
主视觉 各页面 HOME HOME-弹窗 HOME-Tips MORE MORE-包车 ME </description>
    </item>
    
    <item>
      <title>MMDetection中使用Mask-RCNN训练BDD100K数据集</title>
      <link>https://konosuba.xyz/blog/bdd100k_mmdet_mask-rcnn/</link>
      <pubDate>Thu, 08 Oct 2020 13:40:10 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/bdd100k_mmdet_mask-rcnn/</guid>
      <description>1. Convert label to COCO format 使用官方提供的工具bdd100k2coco.py
 注意：使用bdd100k2coco分支下的文件，master中的该文件无法正常使用
 在使用前，还需要对该文件进行部分修改：
# 将69行修改为	 image[&amp;#34;file_name&amp;#34;] = frame[&amp;#34;name&amp;#34;]+&amp;#34;.jpg&amp;#34; # 在73行之后增加 frame = frame[&amp;#34;frames&amp;#34;][0] 之后按如下方式运行
python bdd100k2coco.py -i {JSON文件夹路径} -o {输出一个coco json文件} -m {转换方式det or track，使用det即可} 调用两次分别将train、val数据集的label转换
2. Set COCO-like directory tree 按如下目录结构保存我们的数据集
data ├── annotations │ ├── instances_train2017.json # 训练集json │ ├── instances_val2017.json	# 验证集json ├── train2017 │ └── abcdefg-1234567.jpg │ └── ... ├── test2017 │ └── abcdefg-1234567.jpg │ └── ... ├── val2017 │ └── abcdefg-1234567.</description>
    </item>
    
    <item>
      <title>MMDetection安装过程记录</title>
      <link>https://konosuba.xyz/blog/mmdet_install/</link>
      <pubDate>Mon, 05 Oct 2020 13:37:51 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/mmdet_install/</guid>
      <description>记录自本人安装过程，环境建议：
 Linux or macOS (Windows is not currently officially supported) Python 3.6+ PyTorch 1.3+ CUDA 9.2+ (If you build PyTorch from source, CUDA 9.0 is also compatible) GCC 5+  1. torch &amp;amp; torchvision 我使用的是 torch 1.5.1 + torchvision 0.6.1
pip install torch==1.5.1 torchvision==0.6.1 [-i https://pypi.douban.com/simple]
 https://pytorch.org/get-started/previous-versions/
 2. mmcv pip install mmcv-full
3. mmdetection git clone https://github.com/open-mmlab/mmdetection.git cd mmdetection pip install -r requirements/build.txt pip install -v -e .</description>
    </item>
    
    <item>
      <title>查看当前使用的Python的安装路径</title>
      <link>https://konosuba.xyz/blog/show_python_installation_path/</link>
      <pubDate>Fri, 25 Sep 2020 19:22:57 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/show_python_installation_path/</guid>
      <description>如题，代码如下：
import sys python_path = sys.executable print(python_path) 如图：</description>
    </item>
    
    <item>
      <title>python库opencv,py-opencv,libopencv的区别</title>
      <link>https://konosuba.xyz/blog/difference_between_opencv_pyopencv_libopencv/</link>
      <pubDate>Tue, 07 Jul 2020 23:52:11 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/difference_between_opencv_pyopencv_libopencv/</guid>
      <description>通常我们在Python中安装OpenCV都是直接用pip install opencv-python
今天想用Anaconda Navigator安装的时候，在面板中搜索到有libopencv, opencv, py-opencv共三个包，而且三者的描述都是同样的’Computer vision and machine learning software library‘，瞬间迷惑:laughing:
找到介绍如下：
 OpenCV is computer vision a library written using highly optimized C/C++ code. It makes use of multiprocessing in the background. It has a collection of a large number of algorithms tested and verifiend by the developers. The best thing about this is it&amp;rsquo;s FREE under the BSD license. libopencv is only a metapackage. These packages do not contain actual software, they simply depend on other packages to be installed.</description>
    </item>
    
    <item>
      <title>树莓派4B安装opencv以及错误解决</title>
      <link>https://konosuba.xyz/blog/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%AE%89%E8%A3%85opencv/</link>
      <pubDate>Mon, 27 Apr 2020 11:25:47 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%AE%89%E8%A3%85opencv/</guid>
      <description>更新于2020/4/27 更新：换了个树莓派4B，安装opencv的时候遇到了一些之前没碰到的问题，在这里记录一下
 主要参考opencv官网文档和博客树莓派+Opencv（一）图像处理
树莓派4B上安装参考：树莓派4B 安装opencv完整教程基于python3（各种错误解决）
下载安装依赖项 sudo apt-get install build-essential sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev 在4B上安装时遇到libgtk2.0-dev安装失败的问题：
这是因为依赖项版本太高了，需要降级安装。所以可以使用命令sudo aptitude install libgtk2.0-dev来进行安装
在安装过程中，首先会给出一个方案提示是否接受，第一个给出的方案是保留原依赖项，我们要输入n否定它，之后给出第二个方案是降级安装，输入Y使用该方案
 其中aptitude是一个类似apt-get的包管理工具，但是它能更好处理依赖问题，支持降级安装
 下载源码 从GitHub下载：
opencv
opencv_contrib
两个都下载.zip压缩包即可
解压源码并进入文件夹 unzip opencv-4.3.0.zip unzip opencv_contrib-4.3.0.zip cd opencv-4.3.0 创建一个build文件夹用于编译 mkdir build cd build 运行cmake-gui  这一步其实也可以直接使用cmake配合各类参数，不过我觉得图形化界面方便一点
 cmake-gui 选择源码路径和编译路径后点击Configure
之后在中间的选择框中找到项目BUILD_TESTS，把它的复选框取消
 这一步是因为后面编译过程中，总是由于opencv_test_xxx这类项目导致编译失败，因此我在这里将它取消
 之后点击Generate生成，最后输出如图所示则可以进行下一步</description>
    </item>
    
    <item>
      <title>AlexNet分类Fashion-MNIST(Pytorch实现)</title>
      <link>https://konosuba.xyz/blog/fashion_mnist_alexnet/</link>
      <pubDate>Sun, 08 Mar 2020 23:03:09 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/fashion_mnist_alexnet/</guid>
      <description>这个notebook也同时发表在Kaggle上
Fashion MNIST数据集    Label Class     0 T-shirt/top   1 Trouser   2 Pullover   3 Dress   4 Coat   5 Sandal   6 Shirt   7 Sneaker   8 Bag   9 Ankle boot    准备工作 import os import torch import torch.nn.functional as F import torch.nn as nn import torch.optim as optim import numpy as np import pandas as pd from PIL import Image import matplotlib.</description>
    </item>
    
    <item>
      <title>循环神经网络RNN以及几种经典模型</title>
      <link>https://konosuba.xyz/blog/rnn/</link>
      <pubDate>Wed, 19 Feb 2020 22:47:20 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/rnn/</guid>
      <description>RNN简介 现实世界中，很多元素都是相互连接的，比如室外的温度是随着气候的变化而周期性的变化的、我们的语言也需要通过上下文的关系来确认所表达的含义。但是机器要做到这一步就相当得难了。因此，就有了现在的循环神经网络，他的本质是：拥有记忆的能力，并且会根据这些记忆的内容来进行推断。因此，他的输出就依赖于当前的输入和记忆。
网络结构及原理 循环神经网络的基本结构特别简单，就是将网络的输出保存在一个记忆单元中，这个记忆单元和下一次的输入一起进入神经网络中。
一个最简单的循环神经网络在输入时的结构示意图：
RNN 可以被看做是同一神经网络的多次赋值，每个神经网络模块会把消息传递给下一个，我们将这个图的结构展开:
根据循环神经网络的结构也可以看出它在处理序列类型的数据上具有天然的优势。因为网络本身就是 一个序列结构，这也是所有循环神经网络最本质的结构。
我们可以用下面的公式来表示循环神经网络的计算方法：
总结图：
Pytorch中 pytorch 中使用 nn.RNN 类来搭建基于序列的循环神经网络，它的构造函数有以下几个参数：
 input_size：输入数据X的特征值的数目。 hidden_size：隐藏层的神经元数量，也就是隐藏层的特征数量。 num_layers：循环神经网络的层数，默认值是 1。 bias：默认为 True，如果为 false 则表示神经元不使用 bias 偏移参数。 batch_first：如果设置为 True，则输入数据的维度中第一个维度就是 batch 值，默认为 False。默认情况下第一个维度是序列的长度， 第二个维度才是batch，第三个维度是特征数目。 dropout：如果不为空，则表示最后跟一个 dropout 层抛弃部分数据，抛弃数据的比例由该参数指定  RNN 中最主要的参数是 input_size 和 hidden_size，这两个参数务必要搞清楚。其余的参数通常不用设置，采用默认值就可以了。
rnn = torch.nn.RNN(20,50,2) input = torch.randn(100 , 32 , 20) h_0 =torch.randn(2 , 32 , 50) output,hn=rnn(input ,h_0) print(output.size(),hn.size()) &amp;#39;&amp;#39;&amp;#39; torch.Size([100, 32, 50]) torch.Size([2, 32, 50]) &amp;#39;&amp;#39;&amp;#39;  一文搞懂RNN（循环神经网络）基础篇</description>
    </item>
    
    <item>
      <title>卷积神经网络CNN以及几种经典模型</title>
      <link>https://konosuba.xyz/blog/cnn/</link>
      <pubDate>Tue, 18 Feb 2020 18:43:39 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/cnn/</guid>
      <description>简介  CNN -&amp;gt; Convolutional Neural Network
 卷积神经网络是由一个或多个卷积层和顶端的全连通层（也可以使用1x1的卷积层作为最终的输出）组成的一种前馈神经网络
基本概念 局部感受野(Local Receptive Fields) 一般的神经网络往往会把图像的每一个像素点连接到全连接的每一个神经元中，而卷积神经网络则是把每一个隐藏节点只连接到图像的某个局部区域，从而减少参数训练的数量。
例如，一张1024×720的图像，使用9×9的感受野，则只需要81个权值参数。对于一般的视觉也是如此，当观看一张图像时，更多的时候关注的是局部。
共享权值(Shared Weights) 在卷积神经网络的卷积层中，神经元对应的权值是相同的，由于权值相同，因此可以减少训练的参数量。共享的权值和偏置也被称作卷积核或滤波器
池化(Pooling) 由于待处理的图像往往都较大，而实际处理时没必要直接对原图进行分析，最主要的是要能够有效获得图像的特征。因此可以采用类似图像压缩的思想，对图像进行卷积之后，通过一个下采样过程来调整图像的大小
 什么是下采样？ 上采样、下采样到底是个啥
 结构组成 我们通过卷积的计算操作来提取图像局部的特征，每一层都会计算出一些局部特征，这些局部特征再汇总到下一层，这样一层一层的传递下去，特征由小变大，最后在通过这些局部的特征对图片进行处理，这样大大提高了计算效率，也提高了准确度。
卷积层 提取特征
卷积计算  动图来源于：stanford.edu, Feature extraction using convolution
  NOTE: 深度学习中的卷积与信号处理中的卷积略有不同，深度学习中的卷积略去了翻转的步骤（因为起初卷积核是随机生成的，没有方向）
  输入矩阵大小 n 卷积核大小 f 边界填充 (p)adding，指在原矩阵周围填充的层数 步长 (s)tride  计算公式
卷积结果大小：(n - f + 2p) / s + 1向下取整
多个卷积核 在每一个卷积层我们会设置多个卷积核，代表多个不同的特征，这些特征就是需要传递到下一层的输出，训练的过程就是训练不同的核
激活函数 引入非线性关系
由于卷积的操作是线性的，所以需要使用进行激活，通常使用Relu
池化层 减少参数数量
通过减少卷积层之间的连接，降低运算复杂程度。
池化层一般放在卷积层后面，所以池化层池化的是卷积层的输出
一般使用的有最大池化max-pooling和平均池化mean-pooling</description>
    </item>
    
    <item>
      <title>Pytorch中的激活函数</title>
      <link>https://konosuba.xyz/blog/pytorch_activation_function/</link>
      <pubDate>Sat, 15 Feb 2020 18:43:29 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_activation_function/</guid>
      <description>介绍神经网络的时候已经说到，神经元会对化学物质的刺激进行，当达到一定程度的时候，神经元才会兴奋，并向其他神经元发送信息。神经网络中的激活函数就是用来判断我们所计算的信息是否达到了往后面传输的条件。
为什么激活函数都是非线性的 因为如果使用线性的激活函数，那么input跟output之间的关系始终为线性的，这样完全可以不使用网络结构，直接使用线性组合即可。
所以需要激活函数来引入非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中，增加了神经网络模型泛化的特性。
一般只有在输出层有极小的可能性使用线性激活函数，在隐含层都使用非线性激活函数.
常见的激活函数 # 初始化一些信息 import torch import torch.nn.functional as F import matplotlib.pyplot as plt import numpy as np x= torch.linspace(-10,10,60) Sigmoid 函数 g(z) = a = 1 / (1 + e^(-z)) g&amp;#39;(z) = a&amp;#39; = a (1 - a) 在sigmod函数中我们可以看到，其输出是在(0,1)这个开区间，它能够把输入的连续实值变换为0和1之间的输出，如果是非常大的负数，那么输出就是0；如果是非常大的正数输出就是1，起到了抑制的作用。
ax = plt.gca() ax.spines[&amp;#39;right&amp;#39;].set_color(&amp;#39;none&amp;#39;) ax.spines[&amp;#39;top&amp;#39;].set_color(&amp;#39;none&amp;#39;) ax.xaxis.set_ticks_position(&amp;#39;bottom&amp;#39;) ax.spines[&amp;#39;bottom&amp;#39;].set_position((&amp;#39;data&amp;#39;, 0)) ax.yaxis.set_ticks_position(&amp;#39;left&amp;#39;) ax.spines[&amp;#39;left&amp;#39;].set_position((&amp;#39;data&amp;#39;, 0)) plt.ylim((0, 1)) sigmod=torch.sigmoid(x) plt.plot(x.numpy(),sigmod.numpy()) 但是sigmod由于需要进行指数运算（这个对于计算机来说是比较慢，相比relu），再加上函数输出不是以0为中心的（这样会使权重更新效率降低），当输入稍微远离了坐标原点，函数的梯度就变得很小了（几乎为零）。
在神经网络反向传播的过程中不利于权重的优化，这个问题叫做梯度饱和，也可以叫梯度弥散。这些不足，所以现在使用到sigmod基本很少了，基本上只有在做二元分类（0，1）时的输出层才会使用。
Tanh 函数 tanh是双曲正切函数，输出区间是在(-1,1)之间，而且整个函数是以0为中心的
ax = plt.gca() ax.spines[&amp;#39;right&amp;#39;].set_color(&amp;#39;none&amp;#39;) ax.spines[&amp;#39;top&amp;#39;].set_color(&amp;#39;none&amp;#39;) ax.xaxis.set_ticks_position(&amp;#39;bottom&amp;#39;) ax.</description>
    </item>
    
    <item>
      <title>Pytorch中的梯度下降及优化</title>
      <link>https://konosuba.xyz/blog/pytorch_gradient_descent/</link>
      <pubDate>Sat, 15 Feb 2020 17:46:54 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_gradient_descent/</guid>
      <description>在PyTorch中使用Mini-batch这种方法进行训练
Mini-batch的梯度下降法 对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候处理速度会很慢，而且也不可能一次的载入到内存或者显存中
所以我们会把大数据集分成小数据集，一部分一部分的训练，这个训练子集即称为Mini-batch。
对于普通的梯度下降法，一个epoch只能进行一次梯度下降；而对于Mini-batch梯度下降法，一个epoch可以进行Mini-batch的个数次梯度下降。
普通的batch梯度下降法和Mini-batch梯度下降法代价函数的变化趋势，如下图所示：
 如果训练样本的大小比较小时，能够一次性的读取到内存中，那我们就不需要使用Mini-batch 如果训练样本的大小比较大时，一次读入不到内存或者现存中，那我们必须要使用 Mini-batch来分批的计算 Mini-batch size的计算规则如下，在内存允许的最大情况下使用2的N次方个size  torch.optim torch.optim是一个实现了各种优化算法的库。大部分常用优化算法都有实现
torch.optim.SGD  Stochastic Gradient Descent
 随机梯度下降算法，带有动量(momentum)的算法作为一个可选参数可以进行设置
 可以把动量看作惯性：当你跑起来，由于惯性的存在你跑起来会比刚起步加速的时候更轻松，当你跑过头，想调头往回跑，惯性会让你拖着你。 在普通的梯度下降法的方向相同，则会加速。反之，则会减速。 加了动量的优势：
 加速收敛 提高精度（减少收敛过程中的振荡）   SGD(params, lr=&amp;lt;required parameter&amp;gt;, momentum=0, dampening=0, weight_decay=0, nesterov=False) torch.optim.RMSprop  Root Mean Square Prop
 均方根传递。也是一种可以加快梯度下降的算法，利用RMSprop算法，可以减小某些维度梯度更新波动较大的情况，使其梯度下降的速度变得更快
相较于gradient descent with momentum，RMSprop的思想是:
 对于梯度震动较大的项，在下降时，减小其下降速度； 对于震动幅度小的项，在下降时，加速其下降速度。  torch.optim.Adam Adam 优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法
它能基于训练数据迭代地更新神经网络权重
详细介绍
e.d.
# 这里的lr，betas，还有eps都是用默认值即可，所以Adam是一个使用起来最简单的优化方法 optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.</description>
    </item>
    
    <item>
      <title>Pytorch中的损失函数Loss Function</title>
      <link>https://konosuba.xyz/blog/pytorch_loss_function/</link>
      <pubDate>Sat, 15 Feb 2020 15:33:34 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_loss_function/</guid>
      <description>由于Pytorch中使用mini-batch进行计算，因此其损失函数的计算结果会对mini-batch取平均
常见的Pytorch中内置的损失函数有：
nn.L1Loss 计算input与output的差的绝对值，input与output应该是同一维度，得到的loss也是相应维度
nn.NLLLoss  Negative Log Likelihood
 class torch.nn.NLLLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction=&amp;#39;mean&amp;#39;) 常用于多分类任务。在NLLLoss输入input之前，我们需要对input进行log_softmax处理(即将input转换成概率分布的形式，并且取对数，底数为e)
计算公式
loss(input, class) = -input[class] NLLLoss中如果传递了weight参数，会对损失进行加权，公式就变成了
loss(input, class) = -weight[class] * input[class] nn.MSELoss  Mean Square Error
 计算input与ouput之间的均方差
nn.CrossEntropyLoss 多分类用的交叉熵损失合函数，将LogSoftMax和nn.NLLLoss集成到一个类中，nn.CrossEntropyLoss可以自动对input进行logSoftMax操作，可以理解为CrossEntropyLoss()=log_softmax() + NLLLoss()
传入weight参数后
一般多分类的情况会使用这个损失函数
nn.BCELoss  Binary Cross Entropy
 计算input与output之间的二进制交叉熵
添加weight后
用的时候需要在该层前面加上 Sigmoid 函数</description>
    </item>
    
    <item>
      <title>Pytorch_数据集的创建和加载</title>
      <link>https://konosuba.xyz/blog/pytorch_dataset_dataloader/</link>
      <pubDate>Sat, 15 Feb 2020 01:08:09 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_dataset_dataloader/</guid>
      <description>PyTorch通过torch.utils.data对一般常用的数据加载进行了封装，可以很容易地实现多线程数据预读和批量加载。
可以通过dataset定义数据集，并使用Datalorder载入和遍历数据集
Dataset Dataset是一个抽象类，为了能够方便的读取，需要将要使用的数据包装为Dataset类。
自定义的Dataset需要继承它并且实现两个成员方法：
 __getitem__() 该方法定义用索引(0 到 len(self))获取一条数据或一个样本 __len__() 该方法返回数据集的总长度  下面使用kaggle上的一个竞赛bluebook for bulldozers自定义一个数据集，用里面的数据字典来做说明（因为条数少）
from torch.utils.data import Dataset import pandas as pd #定义一个数据集 class BulldozerDataset(Dataset): # 实现初始化方法，在初始化的时候将数据读载入 def __init__(self, csv_file): self.df=pd.read_csv(csv_file) # 返回df的长度 def __len__(self): return len(self.df) # 根据 idx 返回一行数据 def __getitem__(self, idx): return self.df.iloc[idx].SalePrice 至此，我们的数据集已经定义完成了，我们可以实例话一个对象访问他
ds_demo = BulldozerDataset(&amp;#39;median_benchhmark.csv&amp;#39;) print(len(ds_demo)) # 11573 print(ds_demo[0]) # 24000.0 Dataloader DataLoader为我们提供了对Dataset的读取操作，常用参数有：batch_size(每个batch的大小)、 shuffle(是否进行shuffle操作)、 num_workers(加载数据的时候使用几个子进程)。下面做一个简单的操作
dl = torch.utils.data.DataLoader(ds_demo, batch_size=10, shuffle=True, num_workers=0) DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据
idata=iter(dl) print(next(idata)) # Output: # tensor([24000.</description>
    </item>
    
    <item>
      <title>Pytorch_torchvision</title>
      <link>https://konosuba.xyz/blog/pytorch_torchvision/</link>
      <pubDate>Fri, 14 Feb 2020 00:19:28 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_torchvision/</guid>
      <description>torchvision.models torchvision不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用，或者在进行迁移学习 torchvision.models模块的 子模块中包含以下模型结构。
 AlexNet VGG ResNet SqueezeNet DenseNet  torchvision.datasets 这其中所有的数据集都是torch.utils.data.Dataset的子类，它们都具有__getitem__和__len__实现的方法。因此，它们都可以传递给torch.utils.data.DataLoader，它使用torch.multiprocessing并行加载多个样本。
torchvision.transforms 提供了一般的图像转换操作类，用作数据处理和数据增强
其中都是常见的图像转换，可以通过Compose将他们链接在一起
from torchvision import transforms as transforms transform = transforms.Compose([ transforms.RandomCrop(32, padding=4), #先四周填充0，在把图像随机裁剪成32*32 transforms.RandomHorizontalFlip(), #图像一半的概率翻转，一半的概率不翻转 transforms.RandomRotation((-45,45)), #随机旋转 transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.229, 0.224, 0.225)), #R,G,B每层的归一化用到的均值和方差 ]) 此外还有torchvision.transforms.functional 模块，可对转换进行细粒度控制，这对于要构建一个更复杂的 transformation pipeline（例如在segmentation tasks分段任务中）很有帮助
torchvision.transforms.Normalize(mean, std, inplace=False) 用均值和标准差对张量图像进行归一化。
给定n个通道的均值: (M1,...,Mn) 和标准差: (S1,..,Sn), 这个转换将归一化输入torch.*Tensor的每个通道。例如: input[channel] = (input[channel] - mean[channel]) / std[channel]
 Note: 这种变换的作用不适当，即它不会改变输入张量
 torchvision.utils torchvision.utils.make_grid(tensor, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0) 创建图像网格，即将若干幅图像拼成一幅图像</description>
    </item>
    
    <item>
      <title>Pytorch学习笔记_4_训练一个分类器</title>
      <link>https://konosuba.xyz/blog/pytorch_4/</link>
      <pubDate>Thu, 13 Feb 2020 18:37:46 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_4/</guid>
      <description>关于数据 一般来说，对于图像、文本、音频或视频数据，可以使用标准的Python包来将这些数据加载为numpy array，之后可以将这些array转换为torch.*Tensor
 对于图像，Pillow、OpenCV包 音频，scipy、librosa包 文本，可以使用原始Python和Cython加载，或NLKT和SpaCy  特别的，对于视觉任务，有一个包torchvision，其中包含了处理类似Imagnet, CIFAR10, MNIST等常见数据集的方法，以及图像转换器，如torchvision.datasets和torch.utils.data.DataLoader
torchvision包不仅提供了巨大的便利，也避免了代码的重复。
在这里使用CIFAR10数据集，它有如下10个类别 ：‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。
CIFAR-10的图像都是 3x32x32 大小的，即，3颜色通道，32x32像素。
训练一个图像分类器  使用torchvision加载和归一化CIFAR10训练集和测试集 定义一个卷积神经网络 定义损失函数 用训练集训练网络 用测试集测试网络  1.读取和归一化 CIFAR10 使用torchvision可以非常容易得加载CIFAR10
import torch import torchvision import torchvision.transforms as transforms torchvision的输出是 [0,1]的PILImage图像，把它转化为归一化范围为[-1, 1]的张量
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 下载数据并加载到loader中 trainset = torchvision.datasets.CIFAR10(root=&amp;#39;./data&amp;#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = torchvision.</description>
    </item>
    
    <item>
      <title>Pytorch_linear</title>
      <link>https://konosuba.xyz/blog/pytorch_linear/</link>
      <pubDate>Wed, 12 Feb 2020 23:13:53 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_linear/</guid>
      <description>Linear 对输入数据应用线性变换：y = xA^T + b
torch.nn.Linear(in_features, out_features, bias=True) 参数  in_features 每个输入样本的大小 out_features 每个输出样本的大小 bias 若为False，layer不会学习附加偏差b  shape   输入: (N, ∗, H_in)，其中 ∗ 代表任意数量的附加维度，H_in = in_features
  输出: (N, *, H_out)，除了最后一个维度，其余都与输入相同，H_out = out_features
  </description>
    </item>
    
    <item>
      <title>Pytorch_nn.Conv2d</title>
      <link>https://konosuba.xyz/blog/pytorch_conv2d/</link>
      <pubDate>Wed, 12 Feb 2020 22:22:18 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_conv2d/</guid>
      <description>Conv2d torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode=&amp;#39;zeros&amp;#39;)  in_channels 输入数据通道数 out_channels 输出数据通道数 kennel_size 卷积核大小，int或tuple stride 步长 padding 每个维度零填充的数量 dilation 内核点之间的距离，也称à trous algorithm groups 控制inputs与outputs间的连接    groups=1，所有输入都卷积到输出 groups=2，并排设置两个conv层，每个层查看一半的输入通道，并生成一半的输出通道，然后将两者连接起来 groups=in_channels，每个输入通道都有它自己的filter，size为[out_channels/in_channels]   </description>
    </item>
    
    <item>
      <title>Python面向对象_super()函数</title>
      <link>https://konosuba.xyz/blog/python_super/</link>
      <pubDate>Wed, 12 Feb 2020 17:12:47 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python_super/</guid>
      <description>super() super()是用于**调用父类（超类）**的一个方法
用于解决多重继承问题：直接用类名调用父类方法在使用单继承时没有问题，但若使用多继承，会涉及到查找顺序（MRO）、重复调用（钻石继承）等问题
 MRO 就是类的方法解析顺序表, 其实也就是继承父类方法时的顺序表。
 语法 super(type[, object-or-type]) 参数   type 类
  object-or-type 类，一般是self
  在 Python3 中：super().xxx
在 Python2 中：super(Class, self).xxx
两者等价
示例 class Bird: def __init__(self): self.hungry = True def eat(self): if self.hungry: print(&amp;#39;Ahahahah&amp;#39;) else: print(&amp;#39;No thanks!&amp;#39;) class SongBird(Bird): def __init__(self): self.sound = &amp;#39;Squawk&amp;#39; def sing(self): print(self.sound) sb = SongBird() sb.sing() # 能正常输出&amp;#39;Squawk&amp;#39; sb.eat() # 报错，因为 SongBird 中没有 hungry 特性 使用super解决：</description>
    </item>
    
    <item>
      <title>Pytorch学习笔记_3_构建一个神经网络</title>
      <link>https://konosuba.xyz/blog/pytorch_3/</link>
      <pubDate>Wed, 12 Feb 2020 11:13:23 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_3/</guid>
      <description>Neural Networks   神经网络可以通过使用torch.nn包来创建
  nn依赖于autograd来定义模型并求导。
  一个nn.Module类包含各个层和一个forward(input)前向传播方法，该方法返回output
  例如这个分类数字图像的网络：
这是个简单的前馈神经网络，它接受一个输入，然后一层接一层的传递，最后输出计算结果
一个神经网络的典型训练过程：
 定义包含一些可学习的参数（或权重）的神经网络 在数据集上迭代 通过神经网络处理输入 计算损失函数（预测值与实际值的差值大小） 将梯度反向传播回网络的参数 更新网络参数，主要使用一个简单的更新法则：weight = weight - learning_rate * gradient   另参见：konosuba.xyz/blog/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4
 定义网络 import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): # 构造方法 super().__init__() # 复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数 # 卷积层 self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) # fc(full_connect)全连接函数，均为线性函数 y = Wx + b self.</description>
    </item>
    
    <item>
      <title>Pytorch学习笔记_2_Autograd自动求导机制</title>
      <link>https://konosuba.xyz/blog/pytorch_2/</link>
      <pubDate>Tue, 11 Feb 2020 17:25:19 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_2/</guid>
      <description>Autograd 自动求导机制 PyTorch 中所有神经网络的核心是 autograd 包。
autograd 包为张量上的所有操作提供了自动求导。它是一个在运行时定义的框架，可以通过代码的运行来决定反向传播的过程，并且每次迭代可以是不同的。
通过一些示例来了解
Tensor 张量 torch.tensor是这个包的核心类。
 设置.requires_grad为True，会追踪所有对于该张量的操作。计算完成后调用.backward()，可以自动计算所有的梯度，并自动累计到.grad属性中   事实上即使.requires_grad为True并不意味着.grad一定不为None
   可以调用.detach()将该张量与计算历史记录分离，并禁止跟踪它将来的计算记录
  为防止跟踪历史记录（和使用内存），可以将代码块包装在with torch.no_grad(): 中。这在评估模型时特别有用，因为模型可能具有requires_grad = True的可训练参数，但是我们不需要梯度计算。
  Function类 Tensor 和 Function 互相连接并生成一个非循环图，它表示和存储了完整的计算历史。
每个张量都有一个.grad_fn属性，对张量进行操作后，grad_fn会引用一个创建了这个Tensor类的Function对象（除非这个张量是用户手动创建的，此时，这个张量的 grad_fn 是 None）
 leaf Tensors 叶张量
  Tensor中有一属性is_leaf，当它为True有两种情况：
   按照惯例，requires_grad = False 的 Tensor    requires_grad = True 且由用户创建的 Tensor。这意味着它们不是操作的结果且grad_fn = None    只有leaf Tensors叶张量在反向传播时才会将本身的grad传入backward()的运算中。要想得到non-leaf Tensors非叶张量在反向传播时的grad，可以使用retain_grad()</description>
    </item>
    
    <item>
      <title>Pytorch学习笔记_1_tensor张量</title>
      <link>https://konosuba.xyz/blog/pytorch_1/</link>
      <pubDate>Tue, 11 Feb 2020 14:46:14 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/pytorch_1/</guid>
      <description>Tensors Tensors与Numpy中的ndarrays类似
torch.new_* 与 torch.*_like 前者创建的对象会保持原有的属性（如dtype），但shape不同
&amp;gt;&amp;gt;&amp;gt; x = torch.zeros(5, 3, dtype=torch.double) &amp;gt;&amp;gt;&amp;gt; x.new_ones(2, 3) tensor([[1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) &amp;gt;&amp;gt;&amp;gt; x.new_ones(2, 3, dtype=torch.long) tensor([[1, 1, 1], [1, 1, 1]]) 后者可以创建shape相同，属性不同的对象
&amp;gt;&amp;gt;&amp;gt; x = torch.zeros(5, 3, dtype=torch.double) &amp;gt;&amp;gt;&amp;gt; torch.ones_like(x) tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) &amp;gt;&amp;gt;&amp;gt; torch.ones_like(x, dtype=torch.long) tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]) 获得size 使用size方法与Numpy的shape属性返回的相同，张量也支持shape属性</description>
    </item>
    
    <item>
      <title>神经网络模型的学习曲线</title>
      <link>https://konosuba.xyz/blog/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/</link>
      <pubDate>Fri, 07 Feb 2020 01:04:44 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/</guid>
      <description>学习曲线：样本数量与误差 绘制 样本数量m 与 训练误差、交叉验证误差 的关系曲线
高偏差（欠拟合）high bias 高方差（过拟合）high variance </description>
    </item>
    
    <item>
      <title>【应用机器学习】正则化与偏差、方差</title>
      <link>https://konosuba.xyz/blog/%E6%AD%A3%E5%88%99%E5%8C%96%E4%B8%8E%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE/</link>
      <pubDate>Fri, 07 Feb 2020 00:56:29 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E6%AD%A3%E5%88%99%E5%8C%96%E4%B8%8E%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE/</guid>
      <description>在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。
但是我们可能会正则化的程度太高或太小了，即我们在选择λ的值时也需要思考与之前选择多项式模型次数类似的问题。
我们选择一系列的想要测试的λ值，比如这里选择 0-10之间的值，通常呈现2倍关系（如：0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10 共12个）。
我们同样把数据分为训练集、交叉验证集和测试集。
选择λ的方法   使用训练集训练出12个不同程度正则化的模型
  用12个模型分别对交叉验证集计算的出交叉验证误差
  选择得出交叉验证误差最小的模型
  运用步骤3中选出模型对测试集计算得出推广误差
  我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：
 当λ较小时，训练集误差较小（过拟合）而交叉验证集误差较大
  随着λ的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加
 </description>
    </item>
    
    <item>
      <title>【应用机器学习】诊断偏差与方差</title>
      <link>https://konosuba.xyz/blog/%E8%AF%8A%E6%96%AD%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/</link>
      <pubDate>Fri, 07 Feb 2020 00:51:21 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E8%AF%8A%E6%96%AD%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/</guid>
      <description>当你运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。
我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：
  对于训练集，当 d 较小时，模型拟合程度更低，误差较大；随着d 的增长，拟合程度提高，误差减小。
  对于交叉验证集，当 d 较小时，模型拟合程度低，误差较大；但是随着 d 的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。
  判断高偏差（欠拟合）或高方差（过拟合）   训练集误差和交叉验证集误差近似时：偏差/欠拟合
  交叉验证集误差远大于训练集误差时：方差/过拟合
  解决欠拟合与过拟合 欠拟合：
 增加网络结构，如增加隐藏层数目； 训练更长时间； 寻找合适的网络架构，使用更大的NN结构；  过拟合 ：
 使用更多的数据； 正则化（ regularization）； 寻找合适的网络结构；  </description>
    </item>
    
    <item>
      <title>【应用机器学习】模型选择和训练、验证、测试集</title>
      <link>https://konosuba.xyz/blog/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/</link>
      <pubDate>Fri, 07 Feb 2020 00:41:34 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/</guid>
      <description>1. 重新划分数据集 其中60%作为训练集，20%作为交叉验证集（cross validation），20%作为测试集
2. 可以计算出三类数据的误差函数 3. 使用交叉验证集选择模型 选出交叉验证误差最小的一个模型
4. 利用测试集计算出推广误差 </description>
    </item>
    
    <item>
      <title>【应用机器学习】评估一个假设</title>
      <link>https://konosuba.xyz/blog/%E8%AF%84%E4%BC%B0%E4%B8%80%E4%B8%AA%E5%81%87%E8%AE%BE/</link>
      <pubDate>Fri, 07 Feb 2020 00:34:04 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E8%AF%84%E4%BC%B0%E4%B8%80%E4%B8%AA%E5%81%87%E8%AE%BE/</guid>
      <description>检验是否过拟合 将数据分成训练集和测试集 通常用70%的数据作为训练集，用剩下30%的数据作为测试集。
很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行洗牌，然后再分成训练集和测试集。
使用训练集对模型进行训练 可以得到一系列参数 theta
使用测试集对模型进行测试 使用测试集数据对模型进行测试，有两种方式计算误差
线性回归模型 利用测试集数据计算代价函数J
逻辑回归模型 除前述方法，还可使用一种 错误分类(misclassification error)(也称0/1错误分类 zero one misclassification error) 的方法</description>
    </item>
    
    <item>
      <title>训练神经网络的基本步骤</title>
      <link>https://konosuba.xyz/blog/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4/</link>
      <pubDate>Fri, 07 Feb 2020 00:09:57 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4/</guid>
      <description>1. 选择一种网络结构 即选择神经元之间的连通模式
  输入层与输出层单元个数由具体特征决定
  隐藏层通常默认为1层；若为多层，则每个隐藏层单元个数应相等。通常隐藏层单元数越多越好
  隐藏层单元数应与输入特征数相匹配
  2. 随机初始化权重 通常把权重值初始化为接近0的很小的数
3. 执行前向传播FP算法 获得对应于每一个 xi 的 h_theta(xi)​
4. 通过代码计算出代价函数 J(theta) 5. 执行反向传播算法 获得 J(theta) 对于 theta 的偏导​，即
 步骤 3-5
   6. 进行梯度检查   比较 通过反向传播得到的偏导数 与 通过数值计算得到的估计值
  确保两种方法得到基本接近的两个值​
  注意在检查完毕后关闭梯度检查
  7. 利用最优化算法与反向传播算法最小化 J(theta) 比如，使用最小梯度法</description>
    </item>
    
    <item>
      <title>正则化 Regularization</title>
      <link>https://konosuba.xyz/blog/%E6%AD%A3%E5%88%99%E5%8C%96/</link>
      <pubDate>Mon, 13 Jan 2020 17:29:56 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E6%AD%A3%E5%88%99%E5%8C%96/</guid>
      <description>过拟合的问题 到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到**过拟合(over-fitting)**的问题，可能会导致它们效果很差。
可以使用一种**正则化(regularization)**的技术来改善或减少过度拟合的问题
在回归问题中   第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；
  第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：
  当我们用第三个模型预测新数据，可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎是最合适的。
在分类问题中 就以多项式理解， x的次数越高，拟合的越好，但相应的预测的能力就可能变差。
处理过拟合问题
 丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA） 正则化。 保留所有的特征，但是减少参数的大小（magnitude）  代价函数 我们从之前的事例可以看出，正是那些高次项导致了过拟合的产生，所以我们可以通过让这些高次项的系数接近于0，我们就能很好的拟合。
所以正则化的基本方法就是在一定程度上减小高次项系数即参数theta的值
即在设定代价函数时，为高次项的系数设置一些惩罚，通过这样代价函数选择出的theta对预测结果的影响就比之前要小许多。
但如果我们不知道要对哪一个参数进行惩罚，我们可以对所以特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。于是得到了一个较为简单的能防止过拟合问题的假设
其中λ称为正则化参数（Regularization Parameter）。注：根据惯例，我们不对theta0进行惩罚。
经过正则化处理的模型与原模型的可能对比如图：
如果选择的正则化参数λ过大，则会把所有的参数都最小化了，导致模型变成 h(x) = theta0 ，也就是上图中红色直线所示的情况，造成欠拟合。
对于正则化，我们要取一个合理的λ的值，这样才能更好的应用正则化。 回顾一下代价函数，为了使用正则化，让我们把这些概念应用到到线性回归和逻辑回归中去，那么我们就可以让他们避免过度拟合了。
正则化线性回归 正则化线性回归的代价函数为：
如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对theta0进行正则化，所以梯度下降算法将分两种情形：
分类 L1正则化（Lasso回归） 损失函数基础上加上权重参数的绝对值
L2正则化（岭回归） 损失函数基础上加上权重参数的平方和
需要说明的是：L1 相比于 L2 会更容易获得稀疏解
WHY-&amp;gt;Click</description>
    </item>
    
    <item>
      <title>逻辑回归Logistic Regression</title>
      <link>https://konosuba.xyz/blog/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Mon, 13 Jan 2020 16:07:34 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</guid>
      <description>分类问题 在分类问题中，我们需要预测的变量y是离散的值，我们将学习一种叫做逻辑回归 (Logistic Regression) 的算法
在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。
将因变量(dependent variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量y ∈ 0,1 ，其中 0 表示负向类，1 表示正向类。
如果我们要用线性回归算法来解决一个分类问题，对于分类，y取值为 0 或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于 1，或者远小于0，即使所有训练样本的标签y都等于 0 或 1。尽管我们知道标签应该取值0 或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。
所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到 1 之间
逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上真的是一种分类算法
假说表示 我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0和1之间。
逻辑回归模型的假设是：h_theta(x) = g(theta&#39;X) 其中:X代表特征向量，g代表逻辑函数（logistic function)是一个常用的S形函数（Sigmoid function），公式为：g(z) = 1 / (1 + exp(-z)
Python代码实现
import numpy as np def sigmoid(z): return 1 / (1 + np.exp(-z)) 该函数图像为
合起来，我们得到逻辑回归模型的假设：
对模型的理解：g(z) = 1 / (1 + exp(-z)
h_theta(x)的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性（estimated probablity）即h_theta(x) = P(y=1 | x;theta)</description>
    </item>
    
    <item>
      <title>Java入门</title>
      <link>https://konosuba.xyz/blog/java%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sun, 12 Jan 2020 21:00:17 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/java%E5%85%A5%E9%97%A8/</guid>
      <description>Java 开发环境配置 首先我们需要下载java开发工具包JDK，下载地址
下载对应版本
之后安装一路下一步即可
安装成功后配置环境变量
参照这个即可
配置完成后，在cmd输入java -version、java、javac，没有报错，则配置成功
基础语法 Java是一门面向对象的语言，因此它就有类与对象、方法、实例变量
 对象：对象是类的一个实例，有状态和行为。例如，一条狗是一个对象，它的状态有：颜色、名字、品种；行为有：摇尾巴、叫、吃等。 类：类是一个模板，它描述一类对象的行为和状态。 方法：方法就是行为，一个类可以有很多方法。逻辑运算、数据修改以及所有动作都是在方法中完成的。 实例变量：每个对象都有独特的实例变量，对象的状态由这些实例变量的值决定。  基本语法  大小写敏感 类名首字母大写，&amp;ldquo;驼峰式&amp;quot;命名 源文件名必须与类名相同 所有的 Java 程序由 public static void main(String []args) 方法开始执行  Hello World public class HelloWorld { public static void main(String []args) { System.out.println(&amp;#34;Hello World&amp;#34;); //自动换行  } } 标识符  所有的标识符都应该以字母（A-Z 或者 a-z）,美元符（$）、或者下划线（_）开始 非法标识符举例：123abc、-salary  变量 主要有以下几种变量
 局部变量 类变量（静态变量） 成员变量（非静态变量）  常量 定义变量的时候，如果加上final修饰符，这个变量就变成了常量
常量在定义时进行初始化后就不可再次赋值，再次赋值会导致编译错误。
Java 源程序与编译型运行区别 </description>
    </item>
    
    <item>
      <title>MATLAB学习_函数</title>
      <link>https://konosuba.xyz/blog/matlab%E5%87%BD%E6%95%B0/</link>
      <pubDate>Sat, 11 Jan 2020 15:35:44 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/matlab%E5%87%BD%E6%95%B0/</guid>
      <description>自定义函数 MATLAB可以在单独的.m文件中定义函数
比如有一文件myadd.m，文件中内容为
functiony =myadd(a, b)% 这里可以写函数的使用说明，前面以%开头 % 在工作区中，help myadd将显示此处的说明 y = a + b; end %可以略去 第一行function y = myadd(a, b) 告诉 MATLAB，这个函数将返回一个值，并且返回的这个值将被存放于变量y里。
另外，还可以得知这个函数有两个参数a和b，以及定义的函数体，即 y = a + b
 myadd是函数名。以m文件定义的函数必须保存为函数名的形式
  要使用 myadd函数，该函数必须在 Matlab 的搜索路径中。
 调用方式 只需在MATLAB中直接使用函数名调用，MATLAB会自动在其搜索路径中找到对应.m文件，例如
&amp;gt;&amp;gt; c = myadd(1, 2) c = 3 MORE MATLAB中允许定义的函数返回值是多个值或多个参数，只需在定义函数时写为
[y1, y2...] = function_name(x1, x2...)</description>
    </item>
    
    <item>
      <title>MATLAB学习_控制语句:for,while,if</title>
      <link>https://konosuba.xyz/blog/matlab%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5/</link>
      <pubDate>Sat, 11 Jan 2020 15:02:35 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/matlab%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5/</guid>
      <description>for循环 首先我们定义一个向量v = zeros(10, 1)
接着我们写一个 “for&amp;quot; 循环，让v等于 1 到 10。设v(i)等于 2 的i次方，循环最后写上“end”。
&amp;gt;&amp;gt; for i = 1:10 v(i) = 2^i; end &amp;gt;&amp;gt; v v = 2 4 8 16 32 64 128 256 512 1024 同样也可以使用break，continue语句
while &amp;gt;&amp;gt; i = 1 &amp;gt;&amp;gt; while true, v(i) = 999; i = i+1; if i == 6, break; end; end; &amp;gt;&amp;gt; i i = 6 if-else &amp;gt;&amp;gt; if i == 5, disp(&amp;#34;hello&amp;#34;); elseif i == 4, disp(&amp;#34;world&amp;#34;); else disp(&amp;#34;hello, world&amp;#34;); end; hello, world &amp;gt;&amp;gt; </description>
    </item>
    
    <item>
      <title>MATLAB学习_数据绘图</title>
      <link>https://konosuba.xyz/blog/matlab%E7%BB%98%E5%9B%BE/</link>
      <pubDate>Sat, 11 Jan 2020 10:28:08 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/matlab%E7%BB%98%E5%9B%BE/</guid>
      <description>当开发学习算法时，往往几个简单的图，可以让你更好地理解算法的内容，并且可以完整地检查下算法是否正常运行，是否达到了算法的目的。
二维绘图 我们先来快速生成一些数据用来绘图。
&amp;gt;&amp;gt; t = [0:0.01:0.98]; &amp;gt;&amp;gt; y1 = sin(2*pi*4*t); 如果我们想要绘制正弦函数，只需输入plot(t, y1)，如图
横轴是变量t，纵轴是y1，也就是我们刚刚所输出的正弦函数。
让我们设置y2
&amp;gt;&amp;gt; y2 = cos(2*pi*4*t); &amp;gt;&amp;gt; plot(t, y2) 如果要同时表示正弦和余弦曲线。
我们要做的就是，输入：plot(t, y1)，得到正弦函数，之后使用函数hold on，它的功能是将新的图像绘制在旧的之上
再输入：plot(t, y2)，MATLAB会自动用不同颜色绘制新的曲线，我们也可以指定颜色，比如plot(t, y2, &#39;r&#39;)，r表示使用红色绘制y2
 &amp;lsquo;r&amp;rsquo; 为线条设定。每个设定可包含表示线条颜色、样式和标记的字符。标记是在绘制的每个数据点上显示的符号，例如，+、o 或 * ；
  例如，&amp;lsquo;g:*&amp;rsquo; 请求绘制使用 * 标记的绿色点线。&amp;lsquo;r&amp;ndash;&amp;lsquo;请求红色虚线
 还可以使用命令xlabel(&#39;time&#39;)标记X轴，输入ylabel(&#39;value&#39;)标记Y轴的值。
同时我们也可以标记这两条函数曲线，用命令 legend(&#39;sin&#39;,&#39;cos&#39;)将这个图例放在右上方，表示这两条曲线表示的内容。最后输入title(&#39;myplot&#39;)，在图像的顶部显示这幅图的标题。
使用close命令可以关掉图像
 可以为图像标号
   使用figure(1); plot(t, y1);将显示第一张图，绘制了y1-t     使用figure(2); plot(t, y2);将显示第一张图，绘制了y2-t   subplot命令，我们使用subplot(1,2,1)，它将图像分为一个1*2的格子，也就是前两个参数，然后它使用第一个格子，也就是最后一个参数1的意思。
之后键入plot(t, y1)，y1-t图显示在第一个格子；
使用subplot(1, 2, 2); plot(t, y2)，y2-t图显示在第二个格子</description>
    </item>
    
    <item>
      <title>MATLAB学习_字符与字符串</title>
      <link>https://konosuba.xyz/blog/matlab%E5%AD%97%E7%AC%A6%E4%B8%B2/</link>
      <pubDate>Sat, 11 Jan 2020 10:13:09 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/matlab%E5%AD%97%E7%AC%A6%E4%B8%B2/</guid>
      <description>字符串 创建 t = &amp;#34;Hello, world&amp;#34;; 如果文本包含双引号，请在定义中使用两个双引号。
q = &amp;#34;Something &amp;#34;&amp;#34;quoted&amp;#34;&amp;#34; and something else.&amp;#34; t 和 q 为数组。它们的数据类型是 string。
&amp;gt;&amp;gt; whos t Name Size Bytes Class Attributes t 1x1 166 string  注意: 使用双引号创建字符串数组是在 R2017a 中引入的。
 行末添加 使用+运算符
&amp;gt;&amp;gt; t + &amp;#34;!&amp;#34; ans = &amp;#34;Hello, world!&amp;#34; 求长度 与数值数组类似，字符串数组可以有多个元素。
&amp;gt;&amp;gt; A = [&amp;#34;a&amp;#34;,&amp;#34;bb&amp;#34;,&amp;#34;ccc&amp;#34;; &amp;#34;dddd&amp;#34;,&amp;#34;eeeeee&amp;#34;,&amp;#34;fffffff&amp;#34;] A = 2×3 string 数组 &amp;#34;a&amp;#34; &amp;#34;bb&amp;#34; &amp;#34;ccc&amp;#34; &amp;#34;dddd&amp;#34; &amp;#34;eeeeee&amp;#34; &amp;#34;fffffff&amp;#34; 使用 strlength 函数求数组中每个字符串的长度。
&amp;gt;&amp;gt; strlength(A) ans = 1 2 3 4 6 7 字符 有时，字符表示的数据并不对应到文本，您可以将此类数据存储在数据类型为char 的字符数组中。字符数组使用单引号。</description>
    </item>
    
    <item>
      <title>MATLAB学习_操作数据</title>
      <link>https://konosuba.xyz/blog/matlab%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Fri, 10 Jan 2020 17:55:20 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/matlab%E6%93%8D%E4%BD%9C/</guid>
      <description>文件操作 导入文件 当我们打开 MATLAB 时，我们通常已经在一个默认路径中，这个路径是 MATLAB 的安装位置，使用 pwd 命令可以显示出 MATLAB 当前所处路径。
使用cd命令，可以修改当前路径
使用&amp;rsquo;ls&amp;rsquo;命令，可以列出当前路劲中所有文件
要在MATLAB中导入数据文件，可以使用load命令，如：
&amp;gt;&amp;gt; load myData.dat % 或load(&amp;#39;myData.dat&amp;#39;) 之后可以直接输入myData，MATLAB便会打印文件中的数据，此时该文件名便作为一个新变量名
导出文件 退出 MATLAB 后，工作区变量不会保留。使用 save 命令保存数据以供将来使用，
save myfile.mat 通过保存，系统会使用 .mat 扩展名将工作区保存在当前工作文件夹中一个名为 MAT 文件的压缩文件中。
变量操作 “工作区”中包含了在MATLAB创建或从数据文件或其他程序导入的变量
例如先在工作区中创建变量A和B
A = eye(3) B = rand(2, 3) 使用who可以查看当前工作区中所有变量
&amp;gt;&amp;gt; who 您的变量为: A B 还有一个whos，能更详细的查看
&amp;gt;&amp;gt; whos Name Size Bytes Class Attributes A 3x3 72 double B 2x3 48 double 此外，在GUI窗口中也能查看
可以使用clear命令清除工作区中所有变量
数据操作 此时矩阵 A = [1 2; 3 4; 5 6] 是一个 3×2 的矩阵</description>
    </item>
    
    <item>
      <title>MATLAB学习_矩阵与向量操作</title>
      <link>https://konosuba.xyz/blog/matlab%E7%9F%A9%E9%98%B5/</link>
      <pubDate>Fri, 10 Jan 2020 15:35:53 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/matlab%E7%9F%A9%E9%98%B5/</guid>
      <description>矩阵与向量的创建在上一篇文章中已经提到，所以这里直接进行操作和运算
运算 现有一矩阵a:
&amp;gt;&amp;gt; a = [1 2 3; 4 5 6; 7 8 10] a = 1 2 3 4 5 6 7 8 10 矩阵与常数相加
&amp;gt;&amp;gt; a + 10 ans = 11 12 13 14 15 16 17 18 20 &amp;gt;&amp;gt; sin(a) ans = 0.8415 0.9093 0.1411 -0.7568 -0.9589 -0.2794 0.6570 0.9894 -0.5440 转置矩阵 &amp;gt;&amp;gt;a&amp;#39; ans = 1 4 7 2 5 8 3 6 10 逆矩阵 &amp;gt;&amp;gt; inv(a) ans = -0.</description>
    </item>
    
    <item>
      <title>YAML与TOML</title>
      <link>https://konosuba.xyz/blog/yaml_and_toml/</link>
      <pubDate>Thu, 09 Jan 2020 20:34:31 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/yaml_and_toml/</guid>
      <description>YAML YAML 是 &amp;ldquo;YAML Ain&amp;rsquo;t a Markup Language&amp;rdquo;（YAML 不是一种标记语言）的递归缩写。有趣的是，在开发的这种语言时，YAML 的意思其实是：&amp;ldquo;Yet Another Markup Language&amp;rdquo;（仍是一种标记语言）。
YAML 的语法和其他高级语言类似，并且可以简单表达清单、散列表，标量等数据形态。它使用空白符号缩进和大量依赖外观的特色，特别适合用来表达或编辑数据结构、各种配置文件、倾印调试内容、文件大纲
YAML 的配置文件后缀为 .yml
基本语法  大小写敏感 使用缩进表示层级关系 缩进不允许使用tab，只允许空格 缩进的空格数不重要，只要相同层级的元素左对齐即可 &amp;lsquo;#&amp;lsquo;表示注释  数据类型  对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 纯量（scalars）：单个的、不可再分的值  对象 对象键值对使用冒号结构表示 key: value，冒号后面要加一个空格。
TOML TOML的全称是 &amp;ldquo;Tom&amp;rsquo;s Obvious, Minimal Language&amp;rdquo;，因为它的作者是 GitHub　联合创始人　Tom Preston-Werner 。
TOML 的目标是成为一个极简的配置文件格式，TOML 被设计成可以无歧义地被映射为哈希表，从而被多种语言解析。
基本语法  大小写敏感 同样使用缩进表示层级关系 缩进可以使用空格，也可以使用Tab 可以在数组中换行 &amp;lsquo;#&amp;lsquo;表示注释  对象 对象键值对使用等号的结构 key = value
字符串 字符串和 JSON 的定义一致，只有一点除外：　TOML 要求使用　UTF-8 编码。</description>
    </item>
    
    <item>
      <title>多变量线性回归</title>
      <link>https://konosuba.xyz/blog/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Tue, 07 Jan 2020 19:48:31 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>多变量梯度下降 与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：
其中：
我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。 多变量线性回归的批量梯度下降算法为：
我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。
Python 代码示例：
def computeCost(X, y, theta): inner = np.power(((X * theta.T) - y), 2) return np.sum(inner) / (2 * len(X)) 梯度下降法实践1-特征缩放 在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛
以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。
解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。如图：
最简单的方法是令：x_n = (x_n - miu_n) / s_n ，其中miu_n是平均值，s_n是标准差
梯度下降法实践2—学习率 梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。
也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好
梯度下降算法的每次迭代受到学习率的影响，如果学习率过小，则达到收敛所需的迭代次数会非常高；如果学习率过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。
通常可以考虑尝试这些学习率：
alpha = 0.01, 0.03, 0.1, 0.3, 1, 3, 10
特征和多项式回归 对于房价预测问题
其中，x1 = frontage(临街宽度)，x2 = depth(纵向深度)，x = frontage * depth = area，则：h(x) = theta0 + theta1*x1 + theta2*x2^2</description>
    </item>
    
    <item>
      <title>降低损失：梯度下降法</title>
      <link>https://konosuba.xyz/blog/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</link>
      <pubDate>Tue, 07 Jan 2020 17:16:04 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</guid>
      <description>梯度下降 梯度下降是一个用来求函数最小值的算法，在这里我们将使用梯度下降算法来求出代价函数（损失函数）J(w1, w2)的最小值
假设我们有时间和计算资源来计算权重值w1的所有可能值的损失。对于回归问题，所产生的损失与w1的图形始终是碗状图，如下所示：
图中的最低点，即斜率正好为 0的位置。这个最小值就是损失函数收敛之处。
过程 开始时我们为(w1, w2)选择一个起始值（起点）。然而起点并不重要；因此很多算法就直接将它们设为0或随机选择一个值。
通过这个参数组合计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。
在这里使用梯度下降法算法计算损失曲线在起点处的梯度。梯度是偏导数的矢量；它可以让我们了解哪个方向距离目标“更近”或“更远”
梯度始终指向损失函数中增长最为迅猛的方向。梯度下降法算法会沿着负梯度的方向走一步，以便尽快降低损失。
为了确定损失函数曲线上的下一个点，梯度下降法算法会将梯度大小的一部分与起点相加：
然后，梯度下降法会重复此过程，逐渐接近最低点。
局部最小值  想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。
  这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。
 我们持续这么做直到我们得到一个局部最小值（local minimum），然而因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），如果选择不同的初始参数组合，可能会找到不同的局部最小值。
 这个问题在以前的机器学习中可能会遇到，因为机器学习中的特征比较少，所以导致很可能陷入到一个局部最优解中出不来 但是到了深度学习，动辄百万甚至上亿的特征，出现这种情况的概率几乎为0，所以我们可以不用考虑这个问题。
 批量梯度下降 批量梯度下降法是最原始的形式，它是指在每一次迭代时使用所有样本来进行梯度的更新
公式为：
其中alpha是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。
在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新theta0和theta1，当j = 0和j = 1时，会产生更新，所以你将更新J(theta0)和J(theta1)。
实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新theta0和theta1，我的意思是在这个等式中，我们要这样更新：
theta0:=theta0，并更新theta1:=theta1
实现方法是：你应该计算公式右边的部分，通过那一部分计算出theta0和theta1的值，然后同时更新theta0和theta1。
学习率 Alpha 让我们来看看如果太小或太大会出现什么情况：
  如果太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。
  如果太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果太大，它会导致无法收敛，甚至发散。
  假设你将theta1初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得theta1不再改变，也就是新的theta1等于原来的theta1，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率alpha保持不变时，梯度下降也可以收敛到局部最低点。
 在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小。
这就是梯度下降算法，你可以用它来最小化任何代价函数，不只是线性回归中的代价函数。</description>
    </item>
    
    <item>
      <title>单变量线性回归</title>
      <link>https://konosuba.xyz/blog/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Tue, 07 Jan 2020 16:09:48 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>线性回归 线性回归是解决回归问题最基本的一个方法。其实质就是找到一条直线能尽可能多的使已知的离散值分布在其周围（二维坐标系中）
就像这样：
或者是在三维坐标中，找到一个面来逼近
在这里我们只讨论最简单的单变量线性回归
单变量线性回归 单变量线性回归问题只含有一个特征（输入变量），因此可以把目标直线表达式写为：
h(x) = y = wx + b
其中， x代表特征/输入变量，h代表目标变量/输出变量
我们需要有一个包含许多对(x, y)的训练集，之后把它喂给我们的学习算法，学习算法输出一个函数，通常表示为小写h表示，代表hypothesis(假设)，表示一个函数
因此h根据输入的x值来得出y值，y值就是我们想要根据x知道的答案。因此，h是一个从y到x的函数映射。
代价函数 又称为“损失函数”
在前面的函数h中，我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度。
模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）
我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。 即使得代价函数最小
这个代价函数可以根据最小二乘法得到
我们绘制一个等高线图，三个坐标分别w (图中theta0)、h (图中theta1)和代价函数 (图中J(theta0, theta1))
代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。
  参考资料： 吴恩达《机器学习》课程笔记
 </description>
    </item>
    
    <item>
      <title>分类(classification)与回归(regression)的区别与关系</title>
      <link>https://konosuba.xyz/blog/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Mon, 06 Jan 2020 15:45:03 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92/</guid>
      <description>分类与回归是监督学习中的两个主要任务，它们即对应了监督学习中“学习”的部分
分类模型与回归模型的本质其实一样。分类模型可将回归模型的输出离散化，回归模型也可将分类模型的输出连续化
 例如：
Linear Recognition 线性回归 使用 y = wx + b 的形式，y就是模型的输出，是一个连续值，所以可以用于处理回归问题
Logistic Recognition 逻辑回归 一般作为分类问题的首选算法，logistic回归只是用到了回归算法，但是其输出的结果是决策边界，是不连续的，所以它其实是分类，而不是回归
二分类 将 y = wx + b 利用激活函数（常用sigmoid函数）映射到 (0,1) 中。再选定一个阈值，将输出分为两类。
多分类 先得到n组w不同的 y = wx +b ，之后进行归一化（例如使用Softmax函数），从而得到在n个类上的概率，即可解决多分类问题
 回归问题的应用场景 回归问题通常是用来预测一个值，如预测房价、未来的天气情况等等。例如一个产品的实际价格为500元，通过回归分析预测值为499元，我们认为这是一个比较好的回归分析。
一个比较常见的回归算法是线性回归算法（LR）。
另外，回归分析用在神经网络上，其最上层是不需要加上softmax函数的，而是直接对前一层累加即可。回归是对真实值的一种逼近预测。
分类问题的应用场景 分类问题是用于将事物打上一个标签，通常结果为离散值。
例如判断一幅图片上的动物是一只猫还是一只狗，分类通常是建立在回归之上，分类的最后一层通常要使用softmax函数进行判断其所属类别。
分类并没有逼近的概念，最终正确结果只有一个，错误的就是错误的，不会有相近的概念。
最常见的分类方法是逻辑回归，或者叫逻辑分类。
总结 一个小测验：假设你经营着一家公司，你想开发学习算法来处理这两个问题：
  你有一大批同样的货物，想象一下，你有上千件一模一样的货物等待出售，这时你想预测接下来的三个月能卖多少件？
  你有许多客户，这时你想写一个软件来检验每一个用户的账户。对于每一个账户，你要判断它们是否曾经被盗过？
  那这两个问题，它们属于分类问题、还是回归问题?
  问题一是一个回归问题，因为你知道，如果我有数千件货物，我会把它看成一个实数，一个连续的值。因此卖出的物品数，也是一个连续的值。
  问题二是一个分类问题，因为我会把预测的值，用 0 来表示账户未被盗，用 1 表示账户曾经被盗过。所以我们根据账号是否被盗过，把它们定为0 或 1，然后用算法推测一个账号是 0 还是 1，因为只有少数的离散值，所以我把它归为分类问题。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;解决假币问题</title>
      <link>https://konosuba.xyz/blog/%E5%81%87%E5%B8%81%E9%97%AE%E9%A2%98/</link>
      <pubDate>Mon, 30 Dec 2019 20:35:42 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E5%81%87%E5%B8%81%E9%97%AE%E9%A2%98/</guid>
      <description>题目 一个袋子里有30个银币，其中一枚是假币，并且假币和真币一模一样，肉眼很难分辨，目前只知道假币比真币重量轻一点。请问，如何区分出假币？
分析 首先为每个银币编号，然后将所有的银币等分为两份，放在天平的两边。这样就将区分30个银币的问题变为区别两堆银币的问题。
因为假币分量较轻，因此天平较轻的一侧中一定包含假币。再将较轻的一侧中银币等分为两份，重复上述做法。直到剩下两枚银币，便可用天平直接找出假银币。类似于二分法
代码 由于这个是自己做的一个练习题，没有使用OJ判题，所以自己利用随机数生成银币的重量和假币相关信息
#include &amp;lt;iostream&amp;gt;#include &amp;lt;algorithm&amp;gt;#include &amp;lt;ctime&amp;gt;using namespace std; void generate_seq(int coin[]) { srand(time(0)); int coin_weight = rand() % 100; int fake_weight = rand() % coin_weight; int fake_add = rand() % 30; for (int i = 1; i &amp;lt;= 30; i++) { if (i == fake_add) coin[i] = fake_weight; else coin[i] = coin_weight; } cout &amp;lt;&amp;lt; &amp;#34;fake_add=&amp;#34; &amp;lt;&amp;lt; fake_add &amp;lt;&amp;lt; endl; cout &amp;lt;&amp;lt; &amp;#34;fake_weight=&amp;#34; &amp;lt;&amp;lt; fake_weight &amp;lt;&amp;lt; endl; } void show_seq(int coin[]) { for (int i = 1; i &amp;lt;= 30; i++) { cout &amp;lt;&amp;lt; coin[i] &amp;lt;&amp;lt; &amp;#34; &amp;#34;; } cout &amp;lt;&amp;lt; endl; } int find_fake(int coin[], int begin, int end) { if (begin == end) return begin; double mid = (begin + end) / 2; int weight_a = 0, weight_b = 0; if ((end - begin + 1) % 2 == 0) //可等分  { for (int i = begin; i &amp;lt;= (int)mid; i++) weight_a += coin[i]; for (int i = (int)mid + 1; i &amp;lt;= end; i++) weight_b += coin[i]; cout &amp;lt;&amp;lt; begin &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; end &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; mid &amp;lt;&amp;lt; endl; cout &amp;lt;&amp;lt; weight_a &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; weight_b &amp;lt;&amp;lt; endl; if (weight_a &amp;lt; weight_b) find_fake(coin, begin, (int)mid); else find_fake(coin, (int)mid+1, end); }else //不可等分，中间留一个mid  { for (int i = begin; i &amp;lt; mid; i++) weight_a += coin[i]; for (int i = mid + 1; i &amp;lt;= end; i++) weight_b += coin[i]; cout &amp;lt;&amp;lt; begin &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; end &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; mid &amp;lt;&amp;lt; endl; cout &amp;lt;&amp;lt; weight_a &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; weight_b &amp;lt;&amp;lt; endl; if (weight_a &amp;lt; weight_b) find_fake(coin, begin, (int)mid - 1); else if (weight_a &amp;gt; weight_b) find_fake(coin, (int)mid + 1, end); else return mid; } } int main() { //产生随机数列  int coin[31]; generate_seq(coin); //打印数列  show_seq(coin); //找  int fake_add = find_fake(coin, 1, 30); cout &amp;lt;&amp;lt; &amp;#34;fake_add=&amp;#34; &amp;lt;&amp;lt; fake_add &amp;lt;&amp;lt; endl; cout &amp;lt;&amp;lt; &amp;#34;fake_weight=&amp;#34; &amp;lt;&amp;lt; coin[fake_add] &amp;lt;&amp;lt; endl; return 0; } </description>
    </item>
    
    <item>
      <title>百度搜索资源平台用crul做链接主动推送</title>
      <link>https://konosuba.xyz/blog/crul_baidu_post/</link>
      <pubDate>Tue, 03 Dec 2019 21:33:22 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/crul_baidu_post/</guid>
      <description>引 最近在百度站长平台加入了这个博客，由于之前在Google上都是直接提交sitemap地址，但是在百度索引sitemap实在太慢了，所以还是选择使用它推荐的crul主动推送方式，在这做个记录
在Windows上安装配置crul 进入curl的官网下载最新的Windows版的binary the curl project安装包
下载完成后解压到任意目录下
之后进入系统属性-&amp;gt;高级系统设置-&amp;gt;高级-&amp;gt;环境变量-&amp;gt;系统变量
新建一个变量，命名为curl，变量值选择之前解压的文件夹-&amp;gt;bin文件夹-&amp;gt;curl.exe
一路保存
之后打开cmd，敲入curl，输出如图，则配置成功
使用curl推送链接 由于使用curl推送链接需要一个只有链接地址的文件，然而sitemap很明显不符合这个条件，所以需要先利用这个在线工具将网站中的链接提取出来
如图，将图中右侧框中的链接复制到一个新建的txt文档，命名为urls.txt
然后在cmd中进入txt文件所在目录，执行百度搜索资源平台给的推送命令，例如：
如果有类似以下的输出，则说明推送成功！
{ &amp;#34;remain&amp;#34;:4999998, &amp;#34;success&amp;#34;:2, &amp;#34;not_same_site&amp;#34;:[], &amp;#34;not_valid&amp;#34;:[] } 在服务器自动推送 很明显，现在这种必须要每次手动推送，很耗费能量，所以之后会试着在网站服务器端配置自动推送，这样才是真正的自动推送嘛</description>
    </item>
    
    <item>
      <title>Tesseract-OCR样本训练方法</title>
      <link>https://konosuba.xyz/blog/tesseract%E8%AE%AD%E7%BB%83/</link>
      <pubDate>Wed, 20 Nov 2019 19:29:52 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/tesseract%E8%AE%AD%E7%BB%83/</guid>
      <description>我们通常使用jTessBoxEditor训练工具进行训练，由于该工具是用Java开发的，所以在安装这个软件之前要保证电脑中有Java环境，这里就不介绍了。
安装jTessBoxEditor 可以在这里下载到最新版安装包
把下载得到的压缩包解压到任意位置，双击其中的train.bat文件，等待一会，弹出窗口就可以开始训练了
制作训练样本 生成tif文件 打开软件，选择Tools-&amp;gt;Merge TIFF，文件类型选择ALL Image Files，选择所有要训练的样本图片，打开
之后会又弹出窗口，文件名需要自己设定，注意要按照格式设置：
[lang].[fontname].exp[num].tif
其中lang为语言名称，fontname为字体名称，num为序号。这三项都可以自己定义
这里我们设置为captcha.font.exp0.tif，文件类型TIFF，保存
生成box文件 将之前生成的captcha.font.exp0.tif复制到Tesseract-OCR的安装目录
打开cmd进入安装目录，执行命令
tesseract.exe num.font.exp0.tif num.font.exp0 batch.nochop makebox 将.box文件和.tif文件放在同一文件夹
手动调整 打开jTessBoxEditor工具，点击Box Editor-&amp;gt;Open，选择打开之前生成的.box文件
软件中便会显示Tesseract自动标记识别的字符，接下来就需手动调整每一张的字符框和识别结果
全部修改完成后，选择Save保存即可
训练 先新建一个名为font_properties的文件，注意，只是文件，没有后缀！打开后，内容输入
captcha 0 0 0 0 0 这里全取值为0，表示字体不是粗体、斜体等等
之后在命令行分别运行命令：
shapeclustering.exe -F font_properties -U unicharset captcha.font.exp0.tr mftraining.exe -F font_properties -U unicharset captcha.font.exp0.tr cntraining.exe captcha.font.exp0.tr 之后给文件 inttemp，normproto，pffmtable，shapetable，unicharset 添加前缀captcha.，也就是我们的字体名
生成语言库 命令
combine_tessdata.exe captcha. 会生成一个captcha.traineddata文件，将其复制到Tesseract-OCR安装目录中的tessdata文件夹即可
使用训练结果 在调用tesseract或pytesseract时，只需添加参数lang=&amp;ldquo;captcha&amp;rdquo;（我们的字体名），程序就会自动调用啦</description>
    </item>
    
    <item>
      <title>Tesseract-OCR安装与python中使用</title>
      <link>https://konosuba.xyz/blog/tesseract%E5%AE%89%E8%A3%85/</link>
      <pubDate>Wed, 20 Nov 2019 18:15:12 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/tesseract%E5%AE%89%E8%A3%85/</guid>
      <description>安装Tesseract-OCR 在官网下载最新的Windows安装包，双击运行
根据需要选择，一路Next，直到这个页面
在Additional language data(download)中选择要下载的其他语言的数据，之后程序会自动下载。一直到安装成功
配置环境变量 进入高级系统设置，选择高级-&amp;gt;环境变量
选中系统变量中Path-&amp;gt;编辑
新建一项，地址为Tesseract-OCR的安装目录即可（例如C:\Program Files\Tesseract-OCR）
可以通过在控制台中输入tesseract命令来检查是否配置成功，输出如图即表示成功
配置Python 直接使用pip install pytesseract进行安装
pytesseract 功能  get_tesseract_version　返回系统中安装的Tesseract版本。 image_to_string　将图像上的Tesseract OCR运行结果返回到字符串 image_to_boxes　返回包含已识别字符及其框边界的结果 image_to_data　返回包含框边界，置信度和其他信息的结果 image_to_osd　返回包含有关方向和脚本检测的信息的结果  参数 image_to_data(image, lang=None, config=&#39;&#39;, nice=0, output_type=Output.STRING)  image object　图像对象 lang String，Tesseract　语言代码字符串 config String　任何其他配置为字符串，例如：config=&#39;&amp;ndash;psm 6&#39; nice Integer　修改Tesseract运行的处理器优先级。Windows不支持。 output_type　类属性，指定输出的类型，默认为string。  简单实例 识别一张图像中字符并直接输出
import pytesseract im = &amp;#34;C:/Users/1/Desktop/test.jpg&amp;#34; result = pytesseract.image_to_string(im) print(result) 这样识别到的字符就会转化成字符串输出</description>
    </item>
    
    <item>
      <title>利用MLS移动最小二乘法对图像变形</title>
      <link>https://konosuba.xyz/blog/mls/</link>
      <pubDate>Thu, 07 Nov 2019 13:58:04 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/mls/</guid>
      <description>这是我的【项目笔记】利用OpenCV的MLS图像扭曲变形实现中的第一部分
  本文主要对MLS进行了一定讲解
 先简单了解一下什么是最小二乘法
最小二乘法 当我们在测量某个值y时，由于误差的存在，可能多次测量的结果不尽相同
我们把多次测量得到的不同结果yi画在同一坐标系中
同时将猜测的实际值y也画在坐标系中
每个yi和y都有一个差值| y - yi |，称为误差
记所有误差的平方和
由于实际值y是我们猜测的，所以它的值可以变化，同时误差的平方和ε也会随之改变
于是高斯或是法国科学家勒让德就提出使误差的平方和最小的 y 就是真值，这是基于，如果误差是随机的，应该围绕真值上下波动
这就是最小二乘法，即
此外，经证明得出误差的分布服从正态分布（不愧是天下第一分布），这里就不证明了
总的来说，对于被选择的参数，应该使算出的函数曲线与观测值之差的平方和最小。用函数表示为：
最小化问题的精度，依赖于所选择的函数模型
移动最小二乘法 移动最小二乘法与传统的最小二乘法相比，有两个比较大的改进：
  拟合函数的建立不同。这种方法建立拟合函数不是采用传统的多项式或其它函数，而是由一个系数向量 a(x)和基函数 p(x)构成， 这里 a(x)不是常数，而是坐标 x 的函数。     引入紧支（ Compact Support）概念。认为点x处的值 y只受 x附近子域内节点影响，这个子域称作点 x 的影响区域， 影响区域外的节点对 x的取值没有影响。在影响区域上定义一个权函数w(x)，如果权函数在整个区域取为常数，就得到传统的最小二乘法。    节选自《基于移动最小二乘法的曲线曲面拟合-曾清红》
 利用MLS变换图像 这一部分，我主要参考了论文《Image Deformation Using Moving Least Squares》中的内容
考虑由用户设定锚点来对图像变形进行控制的情况，首先进行准备工作，推导出公式
准备工作 设p为一组控制点，q是它对应的变形位置
对于图像中的某一点v，有最小的仿射变换lv(x)，使
成立。其中pi和qi是行向量，权值wi满足
各点权重wi 由于对于每个v都有不同的wi的值，称之为移动最小二乘最小化（a Moving Least Squares minimization）。对于每个v都有不同的lv(x)</description>
    </item>
    
    <item>
      <title>【项目笔记】利用OpenCV的MLS图像扭曲变形实现</title>
      <link>https://konosuba.xyz/blog/image_warp_opencv_paper/</link>
      <pubDate>Wed, 23 Oct 2019 23:25:14 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/image_warp_opencv_paper/</guid>
      <description>引 这学期开学的时候实验室接了个项目，要做一个类似Adobe Illustrator中的“操纵扭曲”功能的Demo
 就像这样
 需求分析 可见需要实现的功能核心就是通过鼠标的拖拽对图像进行扭曲变形，这里的变形主要可以分为两类：
  鼠标拖拽导致的普通变形
  在某一固定锚点基础上的旋转式变形
  确定方案 明确了这个后我便开始查阅资料，发现这篇paper 《Image Deformation Using Moving Least Squares》 中利用了MLS移动最小二乘来实现图像变形，其实现的效果和我们的目标极为相似，于是我也决定利用该算法来实现这个Demo
由于要利用鼠标拖拽进行操作，便选择使用Qt来进行图形化界面设计，然鹅我以前也没有用过Qt，因此学习了一些Qt基本知识
开始吧 明确了方案和目标后，便开始了漫长的学习+实践：
  程序结构框架确定
  核心算法实现
  旋转式变形的实现
  在进行到这里之后，发现程序无法实现对某个关节的单独拉伸，于是我们考虑寻找图像中的骨骼，在关节的交点添加一些锚点进行固定
 图形骨骼查找  实现效果 最终项目完成，实现了这些功能，如图是个小小的演示
 本文将会持续更新</description>
    </item>
    
    <item>
      <title>【转载】谷歌小姐姐搞出魔法画板：你随便画，补不齐算AI输</title>
      <link>https://konosuba.xyz/blog/reprint_magic_sketchpad/</link>
      <pubDate>Sun, 20 Oct 2019 00:45:31 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/reprint_magic_sketchpad/</guid>
      <description>最近在研究手绘图形识别相关的内容，想起了这篇去年的文章，研究的内容也大致差不多，考虑使用Google的循环神经网络，于是转载过来记录一下
原文发表于2018-12-19
这两天，一个“魔法画板”在国外传疯了。
AI圈内外的灵魂画手们玩到根本停不下来，创造的惊喜画作能装满好几个美术馆。
这个画板背后，可不是一个普通的画画AI。它，会脑补。
随便画一笔，就能得到一只猫：
画个圆圈，变成猫：
画个三角，变成猫：
画个方块，变成猫：
真是万物皆可喵喵。
当然，你也可以不让它画猫，改成画狗。只要你设定了一个绘画的目标，之后随便画一笔，AI就能脑补出余下的画面。
这个“魔法”，是来自谷歌的吸猫少女Monica Dinculescu用Sketch RNN开发的。
因为她爱猫成痴，不仅自己头像是和自家喵子的合影，连个人主页域名都叫Meowni.ca，我们就叫她喵妮卡好了。
所以，受到创作者的影响，这个AI默认属性为吸猫爱好者，但除了猫之外，AI也会脑补许多其他内容，脑洞很大。
发布之后，众人竞相玩耍，好评如潮，2000多人点赞。
有人让AI画了满屏的骷髅，说，好美啊！
谷歌大佬David Ha也表示，他已经试过用各种基本形状来教导AI画羊了。
不止有魔力，还可以加戏 喵妮卡给应用起名为魔法画板 (Magic Sketchpad) ，也名副其实。
毕竟，只要画一笔，妈咪妈咪哄！一整张图就出现在眼前。
△ 你想要什么样的美人鱼？
而且，只要按一下选择栏左边的刷新按钮，AI就会根据刚才那一笔，不断为你展现新的画法。
一共有100多种东西可以画，青蛙，秋千，直升飞机，连龙猫里的猫巴士都有。
我是一只豆豆眼的猫头鹰：
我是一只很鬼魅的仙人掌：
为了这100多种选项，都能找到合适的色彩来诠释，画板还提供了18种颜色的画笔。
这样一来，就有数不清的排列组合。有大胆想法的小伙伴们，可以在魔法画板上尽情加戏了。
在你开始表演之前，量子位先抛抛砖：
鲸鱼喷出的不一定是水，也有可能是花。
牙刷上方温柔的曲线不一定是牙膏，也有可能是蜗牛。
另外，如果你还没想到，除了排列组合之外，还可以鬼畜啊。
一头鲸鱼喷水没什么，十几头鲸一起喷，就很有节奏感了 (误) 。
一个人做瑜伽太孤单了，十几个人一起做，姿态各不相同，清明瑜伽图岂不美哉？
不过虽然好玩，量子位似乎还是发现了一个bug，像猫巴士 (Catbus) 这种组合选项：画方成车，画圆成猫，无法兼顾。那么，怎样才能一步生成下面这样的效果呢？
想要体验一下的盆友，传送门照例在文末~
人家是有背景的 可能你已经发觉了，它的画风很像的谷歌推出的Quick, Draw!，中文名为“猜画小歌”。
是的，他们是一家人。
喵妮卡在推特上说了，她的魔法画板使用的就是Quick, Draw!数据集。
这个数据集里面，有5000万张画，分为345个类别。每一张画，都记录了画画的整个过程：画笔运动的方向，何时提笔，何时停止绘画。
如果你玩过猜画小歌，那这个数据集里，也有你的一份贡献。
既然使用的是Quick, Draw!数据集，模型基本上没有什么悬念。
正是Sketch-RNN。这是一个用Quick, Draw！数据集训练出来循环神经网络（RNN）。目标是让AI以类似人类的方式来画画，并概括出抽象的概念。
模型有这样的能力，做出来魔法画板也就没有那么难了。
你随手画个圈，就是为Sketch-RNN输入了一个序列，它可以根据这个序列和你选择要画的东西，预测接下来的序列：也就是补完这幅画。
虽然画风奇特，但画啥就有点像啥。
具体的实现代码，喵妮卡也全部放出来了。（传送门在文末。）
三种额外玩法 除了这个万物皆可喵的网页之外，喵妮卡所在的Google Magenta团队还用Sketch-RNN创作了几个不同的涂鸦应用。
9×N种预测，总能猜中你的心 你涂鸦的每一笔，都被我预料到了。
无论你画了个啥，我都能猜出你接下来准备如何下笔。
并且，我有无数种方案，只要点击predict，就可以出现新的9种图案。
而且我还能选择不同的美术风格，通过调整temperature，数值越接近1，我的画风越抽象、越狂放不羁；</description>
    </item>
    
    <item>
      <title>第一个TensorFlow模型：摄氏度转换为华氏度</title>
      <link>https://konosuba.xyz/blog/tensorflow%E5%B0%86%E6%91%84%E6%B0%8F%E5%BA%A6%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%8D%8E%E6%B0%8F%E5%BA%A6/</link>
      <pubDate>Fri, 11 Oct 2019 20:33:51 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/tensorflow%E5%B0%86%E6%91%84%E6%B0%8F%E5%BA%A6%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%8D%8E%E6%B0%8F%E5%BA%A6/</guid>
      <description>今天开始在看Udacity上的TensorFlow入门课程，其中构建的第一个神经网络模型就是将摄氏度转换成华氏度，于是在这里记录一下
公式 已知摄氏度转换成华氏度有数学公式：
f = c * 1.8 + 32 而我们就要在不告知模型这个公式的前提下，通过告知一系列对应的摄氏度与华氏度样例，来训练它以实现摄氏度转华氏度这一功能
import dependencies 导入依赖项 需要引入TensorFlow与NumPy库构建神经网络
from __future__ import absolute_import, division, print_function, unicode_literals import tensorflow as tf import numpy as np 还需要引入logging以记录日志
import logging logger = tf.get_logger() #返回tf的日志实例 logger.setLevel(logging.ERROR) Set up training data 建立训练数据 由于在这里我们使用的是监督式机器学习，所以准备两组链表celsius_q和fahrenheit_a分别代表摄氏温度与对应华氏温度，用来训练模型
celsius_q = np.array([-40, -10, 0, 8, 15, 22, 38], dtype=float) fahrenheit_a = np.array([-40, 14, 32, 46, 59, 72, 100], dtype=float) for i,c in enumerate(celsius_q): print(&amp;#34;{} degrees Celsius = {} degrees Fahrenheit&amp;#34;.</description>
    </item>
    
    <item>
      <title>Python中eval()与format()</title>
      <link>https://konosuba.xyz/blog/python%E4%B8%ADeval%E4%B8%8Eformat/</link>
      <pubDate>Thu, 10 Oct 2019 20:37:31 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E4%B8%ADeval%E4%B8%8Eformat/</guid>
      <description>今天在做mooc课程《Python语言程序设计》的练习题时，遇到一道题，硬生生纠结了半个小时，结果发现答案居然只是短短的两行，这功力不够果然还是不行啊，用C的思维去写Python怕是要纠结死🤔
先看看题
题目 数值运算
描述 获得用户输入的一个字符串，格式如下：
M OP N 其中，M和N是任何数字，OP代表一种操作，表示为如下四种：+, -, *, /（加减乘除）
根据OP，输出M OP N‬的运算结果，统一保留小数点后两位
注意：M和OP、OP和N之间可以存在多个空格，不考虑输入错误情况
示例输入‪ 10 + 100 1 / 20 示例输出 110.00 0.05 解答 我最开始的想法是读入字符串，然后根据空格分为M、OP和N，之后再转换为int型进行计算
然而，我却完全忘记了Python有着eval()的存在&amp;hellip;.
eval() |eval()函数用来执行一个字符串表达式，并返回表达式的值 ‬‪‬‪‬‪‬‮‬‪‬‭‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‫
eval(expression[, globals[, locals]])  参数
  expression &amp;ndash; 表达式
  globals &amp;ndash; 变量作用域，全局命名空间，若被提供，必须是一个字典对象
  locals &amp;ndash; 变量作用域，局部命名空间，若被提供，可以是任何映射对象
 可见，使用eval()后，就不需要我们自己对用户输入的算式进行处理，只需要直接调用，函数会自动帮我们计算结果
之后根据题意，我们还要将运算结果保留两位小数，这时format()就派上了用场
format() 这是一种格式化字符串的函数，基本语法是使用{}和: ‪‬‪‬‪‬‪‬‪‬‮‬‭‬‪‬‪‬‪‬‪‬‪‬‪‬‮ |format()‫‬‪‬‪函数‬‪‬‪‬可以接受不限个参数，位置可以不按顺序
&amp;gt;&amp;gt;&amp;gt; &amp;#34;{} {}&amp;#34;.format(&amp;#34;hello&amp;#34;, &amp;#34;world&amp;#34;) # 不设置指定位置，按默认顺序 &amp;#39;hello world&amp;#39; &amp;gt;&amp;gt;&amp;gt; &amp;#34;{0} {1}&amp;#34;.</description>
    </item>
    
    <item>
      <title>ML学习速率</title>
      <link>https://konosuba.xyz/blog/%E5%AD%A6%E4%B9%A0%E9%80%9F%E7%8E%87/</link>
      <pubDate>Thu, 26 Sep 2019 11:12:23 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E5%AD%A6%E4%B9%A0%E9%80%9F%E7%8E%87/</guid>
      <description>在梯度下降算法中，我们用梯度乘以一个称为学习速率（有时也称为步长）的标量，以确定下一个点的位置。例如，如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。
超参数是编程人员在机器学习算法中用于调整的旋钮。大多数机器学习编程人员会花费相当多的时间来调整学习速率。如果学习速率过小，就会花费太长的学习时间：
相同的 U 形曲线。很多点都相互非常接近，它们的轨迹朝着 U 形底部缓慢前进。
相反，如果学习速率过大，下一个点将永远在 U 形曲线的底部随意弹跳，就好像量子力学实验出现了严重错误一样：
相同的 U 形曲线。这条曲线包含的点非常少。点的轨迹会跳过 U 形底部，然后再次跳回。
每个回归问题都存在一个“恰好”的学习速率，这个值与损失函数的平坦程度有关。例如，若已知损失函数的梯度较小，则可以放心地试着采用更大的学习速率，以补偿较小的梯度并获得更大的步长。
相同的 U 形曲线。点的轨迹大约需要 8 步达到最低点。</description>
    </item>
    
    <item>
      <title>Python文本进度条</title>
      <link>https://konosuba.xyz/blog/python%E6%96%87%E6%9C%AC%E8%BF%9B%E5%BA%A6%E6%9D%A1/</link>
      <pubDate>Thu, 19 Sep 2019 20:59:58 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E6%96%87%E6%9C%AC%E8%BF%9B%E5%BA%A6%E6%9D%A1/</guid>
      <description> Update：使用python库tqdm轻松实现
 一个小程序，用Python在控制台中打印进度条，主要使用time库对时间进行控制，利用了\r转义符使光标回到当前行首的特性，通过多次打印进度条实现动画效果
代码 import time scale = 50 # 进度条长度 print(&amp;#34;&amp;gt;&amp;gt;执行开始\n&amp;#34;) start = time.perf_counter() # 开始时刻 for i in range(scale+1): a = &amp;#39;|&amp;#39; * i b = &amp;#39;.&amp;#39; * (scale - i) c = (i / scale) * 100 dur = time.perf_counter() - start # 当前用时 print(&amp;#34;\r{:^3.0f}% [{}&amp;gt;&amp;gt;{}] {:.2f}s&amp;#34;.format(c, a, b, dur), end=&amp;#39;&amp;#39;) # 打印进度条 time.sleep(0.1) # 休息时间，调整速度 print(&amp;#34;\n\n&amp;gt;&amp;gt;执行结束&amp;#34;) 效果 </description>
    </item>
    
    <item>
      <title>为什么要定义Mat_类</title>
      <link>https://konosuba.xyz/blog/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AE%9A%E4%B9%89mat_%E7%B1%BB/</link>
      <pubDate>Wed, 18 Sep 2019 21:09:06 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AE%9A%E4%B9%89mat_%E7%B1%BB/</guid>
      <description>内容摘自《OpenCV入门教程》
 在读取矩阵元素时，以及获取矩阵某行的地址时，需要指定数据类型。这样首先需要不停地写&amp;lt;uchar&amp;gt;，让人感觉很繁琐，在繁琐和烦躁中容易犯错。
如下面代码中的错误，用at()获取矩阵元素时错误的使用了double类型。这种错误不是语法错误，因此在编译时编译器不会提醒。在程序运行时，at()函数获取到的不是期望的(i,j)位置处的元素，数据已经越界，但是运行时也未必会报错。这样的错误使得你的程序忽而看上去正常，忽而弹出“段错误”，特别是在代码规模很大时，难以查错。
如果使用Mat_类，那么就可以在变量声明时确定元素的类型， 访问元素时不再需要指定元素类型，即使得代码简洁，又减少了出错的可能性。
上面代码可以用Mat_实现，实现代码如下面例程里的第二个双重for循环。
#include &amp;lt;iostream&amp;gt;#include &amp;#34;opencv2/opencv.hpp&amp;#34;#include &amp;lt;stdio.h&amp;gt;using namespace std; using namespace cv; int main(int argc,char* argv[]) { Mat M(600, 800, CV_8UC1); for(int i = 0; i &amp;lt; M.rows; ++i) { //获取指针时需要指定类型  uchar *p = M.ptr&amp;lt;uchar&amp;gt;(i); for(int j = 0; j &amp;lt; M.cols; ++j) { double d1 = (double)((i + j) % 255); //用at读像素时，需要指定类型  M.at&amp;lt;uchar&amp;gt;(i, j) = d1; double d2 = M.at&amp;lt;uchar&amp;gt;(i, j); } } //在变量声明时，指定矩阵元素类型  Mat_&amp;lt;uchar&amp;gt; M1 = (Mat_&amp;lt;uchar&amp;gt;&amp;amp;)M; for(int i = 0; i &amp;lt; M1.</description>
    </item>
    
    <item>
      <title>Python split()函数</title>
      <link>https://konosuba.xyz/blog/python_split%E5%87%BD%E6%95%B0/</link>
      <pubDate>Mon, 16 Sep 2019 20:13:56 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python_split%E5%87%BD%E6%95%B0/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({ google_ad_client: &#34;ca-pub-9673215637005333&#34;, enable_page_level_ads: true });  原型 str.split(str=&amp;#34;&amp;#34;, num=string.count(str)) |split()函数通过指定分隔符对字符串进行切片
参数 若参数str无指定值。默认为所有的空字符，包括空格、\n、\t等
若参数num有指定值，则分割num+1个子字符串，若无指定值，默认-1，即分隔所有
返回值 返回分割后的字符串列表</description>
    </item>
    
    <item>
      <title>Zen of Python -Python之禅</title>
      <link>https://konosuba.xyz/blog/zen_of_python/</link>
      <pubDate>Sat, 07 Sep 2019 21:07:51 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/zen_of_python/</guid>
      <description>在浏览Python官方文档时无意发现了这个彩蛋，只需在终端中import this
The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren&#39;t special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess.</description>
    </item>
    
    <item>
      <title>Python文件操作</title>
      <link>https://konosuba.xyz/blog/python%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Sat, 07 Sep 2019 20:31:38 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/</guid>
      <description>Python内置了读写文件的函数，用法与C兼容
读文件 open() 使用内置的open()函数，传入文件名和标识符：
&amp;gt;&amp;gt;&amp;gt; f = open(&amp;#39;test.txt&amp;#39;, &amp;#39;r&amp;#39;) 若文件不存在，open()函数会抛出一个IOError的错误，并给出错误码和详细信息
Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; FileNotFoundError: [Errno 2] No such file or directory: &amp;#39;test.txt&amp;#39; read() 打开成功后，使用read()一次性读取文件的全部内容，Python将内容读到内存中，用str对象存储
readline() |readline()可以每次读取一行的内容
readlines() |readlines()一次读取所有内容并按行返回list
close() 使用完毕后，需要调用close()关闭文件
with语句 为避免忘记调用close()，Python引入with语句自动调用close()
with open(&amp;#39;test.txt&amp;#39;, &amp;#39;r&amp;#39;) as f: print(f.read()) 写文件 与读文件类似，唯一区别是传入标识符&#39;w&#39;或&#39;wb&#39;表示写文本文件或写二进制文件
所有标识符定义及其意义见官方文档
file-like Object (file object文件对象) 在Python中，像open()函数返回的这种有read()或write()方法的对象统称为file-like Object（或file object）
共有三种类别的文件对象：原始二进制文件, 缓冲二进制文件 以及 文本文件，创建文件对象的规范方式是使用open()函数。</description>
    </item>
    
    <item>
      <title>Python调试</title>
      <link>https://konosuba.xyz/blog/python%E8%B0%83%E8%AF%95/</link>
      <pubDate>Sat, 07 Sep 2019 19:08:46 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E8%B0%83%E8%AF%95/</guid>
      <description>Python中可以使用断言assert,logging等来进行调试
断言 def fun(s): n = int(s) assert n != 0, &amp;#39;n is zero!&amp;#39; return 10 / n def main(): fun(&amp;#39;0&amp;#39;) 若assert后面的语句不为True，则assert会抛出异常AssertionError，并显示后一句&#39;n is zero&#39;:
Traceback (most recent call last): File &amp;#34;hello.py&amp;#34;, line 12, in &amp;lt;module&amp;gt; main() File &amp;#34;hello.py&amp;#34;, line 9, in main fun(&amp;#39;0&amp;#39;) File &amp;#34;hello.py&amp;#34;, line 4, in fun assert n != 0, &amp;#39;n is zero!&amp;#39; AssertionError: n is zero! 在我们不需要使用assert时可以在启动Python解释器时，添加-O(大写字母O)参数来关闭断言：
..path:&amp;gt; python -O hello.py Traceback (most recent call last): File &amp;#34;hello.</description>
    </item>
    
    <item>
      <title>Python错误处理</title>
      <link>https://konosuba.xyz/blog/python%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</link>
      <pubDate>Fri, 06 Sep 2019 19:14:26 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</guid>
      <description>在Python中也同样使用try...except...finally...的错误处理机制
try except try: print(&amp;#39;try...&amp;#39;) r = 10/0 print(&amp;#39;result:&amp;#39;, r) except ZeroDivisionError as e: print(&amp;#39;except:&amp;#39;, e) finally: print(&amp;#39;finally...&amp;#39;) print(&amp;#39;END&amp;#39;) 当认为某一块代码有错误时，就可以用try来运行该段代码，若执行出错，则后续代码不会执行，而会跳转到except块，执行完except后，若后续有finally片段，则执行finally块
上面的代码中有一个除0的错误，运行结果:
try... except: division by zero finally... END 当计算r后，捕捉到ZeroDivisionError错误，执行	except语句段，之后执行finally
else 可以在except后面加上else，当没有错误发生时将执行else语句块
try: print(&amp;#39;try...&amp;#39;) r = 10/5 print(&amp;#39;result:&amp;#39;, r) except ZeroDivisionError as e: print(&amp;#39;except:&amp;#39;, e) else: print(&amp;#39;no error&amp;#39;) print(&amp;#39;END&amp;#39;) 结果:
try... result: 2.0 no error END  Python的错误是一个class，所有错误类型都继承自BaseException，故使用except时需注意它会也会捕获该类型的子类。
  常见错误类型及继承关系（中文）：官方文档
  ## 优势 使用```try...except```捕获错误还有一个巨大的好处，就是可以跨越多层调用，比如函数```main()```调用```fun()```，```fun()```调用```bar()```，结果```bar()```出错了，这时，只要```main()```捕获到了，就可以处理 ​```py def fun(s): return 10/int(s) def bar(s): return fun(s) * 2 def main(): try: print(&#39;try.</description>
    </item>
    
    <item>
      <title>利用opencv与Socket实现树莓派获取摄像头视频和灰度重心发送到电脑</title>
      <link>https://konosuba.xyz/blog/%E5%88%A9%E7%94%A8opencv%E4%B8%8Esocket%E5%AE%9E%E7%8E%B0%E6%A0%91%E8%8E%93%E6%B4%BE%E8%8E%B7%E5%8F%96%E6%91%84%E5%83%8F%E5%A4%B4%E8%A7%86%E9%A2%91%E5%92%8C%E7%81%B0%E5%BA%A6%E9%87%8D%E5%BF%83%E5%8F%91%E9%80%81%E5%88%B0%E7%94%B5%E8%84%91/</link>
      <pubDate>Tue, 09 Jul 2019 15:32:53 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E5%88%A9%E7%94%A8opencv%E4%B8%8Esocket%E5%AE%9E%E7%8E%B0%E6%A0%91%E8%8E%93%E6%B4%BE%E8%8E%B7%E5%8F%96%E6%91%84%E5%83%8F%E5%A4%B4%E8%A7%86%E9%A2%91%E5%92%8C%E7%81%B0%E5%BA%A6%E9%87%8D%E5%BF%83%E5%8F%91%E9%80%81%E5%88%B0%E7%94%B5%E8%84%91/</guid>
      <description>使用树莓派原装CSI摄像头录制视频并利用灰度重心法获取重心，将图像和重心数据通过Socket实时传输到电脑上
因为需要实现程序一启动便打开摄像头计算数据，同时启动Socket服务器等待客户端连接，所以利用C++11中的thread库通过多线程实现程序
树莓派-服务端 #include &amp;lt;iostream&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;cstring&amp;gt;#include &amp;lt;string&amp;gt;#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/socket.h&amp;gt;#include &amp;lt;netinet/in.h&amp;gt;#include &amp;lt;arpa/inet.h&amp;gt;#include &amp;lt;thread&amp;gt;#include &amp;lt;opencv2/opencv.hpp&amp;gt;using namespace cv; using namespace std; #define USEPORT 1234 #define T 20 Mat FRAME; Point PCENTER; //灰度重心法函数 Point gray_center(Mat&amp;amp; img) { Mat img_gray; cvtColor(img, img_gray, COLOR_BGR2GRAY, 0); Point Center; double sumval = 0; MatIterator_&amp;lt;uchar&amp;gt; it, end; for (int i = 0; i &amp;lt; img_gray.cols; i++) { for (int j = 0; j &amp;lt; img_gray.rows; j++) { double s = img_gray.</description>
    </item>
    
    <item>
      <title>Socket通信原理(3)</title>
      <link>https://konosuba.xyz/blog/socket%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%863/</link>
      <pubDate>Mon, 08 Jul 2019 15:38:20 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/socket%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%863/</guid>
      <description>本文主要内容为树莓派与PC在局域网内的基于TCP的Socket通信，由于树莓派是Linux系统，而PC是Windows系统，所以要注意一些区别
这里将树莓派作为服务器端，PC作为客户端，连接后服务端向客户端发送信息
服务端-树莓派 socket_server_sms.cpp #include &amp;lt;iostream&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;cstring&amp;gt;#include &amp;lt;string&amp;gt;#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/socket.h&amp;gt;#include &amp;lt;netinet/in.h&amp;gt;#include &amp;lt;arpa/inet.h&amp;gt;using namespace std; #define USEPORT 1234  int main() { //****创建套接字 	int serverSock = socket(AF_INET, SOCK_STREAM, 0); //Windows中，AF_INET==PF_INET 	//Linux中，不同的版本这两者有微小差别.对于BSD是AF,对于POSIX是PF 	if (serverSock &amp;lt; 0) { cout &amp;lt;&amp;lt; &amp;#34;socket creation failed&amp;#34; &amp;lt;&amp;lt; endl; exit(-1); } cout &amp;lt;&amp;lt; &amp;#34;socket creation successfully&amp;#34; &amp;lt;&amp;lt; endl; //****绑定ip和端口 	struct sockaddr_in serverAddr; memset(&amp;amp;serverAddr, 0, sizeof(serverAddr)); serverAddr.sin_family = AF_INET; serverAddr.sin_port = htons(USEPORT); //INADDR_ANY绑定所有IP 	serverAddr.</description>
    </item>
    
    <item>
      <title>Socket通信原理(2)</title>
      <link>https://konosuba.xyz/blog/socket%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%862/</link>
      <pubDate>Mon, 08 Jul 2019 13:21:57 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/socket%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%862/</guid>
      <description>本文主要是在计算机本地使用基于TCP协议的Socket建立服务端与客户端的连接与基本通信
 系统：Windows 10
  软件：Visual studio 2019
  语言：C++
  Socket通信实现步骤   创建ServerSocket和Socket
  打开连接到的Socket的输入/输出流
  按照协议对Socket进行读/写操作
  关闭输入/输出流和Socket
  本文的程序由服务端发送信息到客户端，若用户输入quit则结束客户端与服务端程序
服务端Server 由于Windows下的socket程序依赖Winsock.dll或ws2_32.dll，所以必须提前加载
#include &amp;lt;iostream&amp;gt;#include &amp;lt;string&amp;gt;#include &amp;lt;winsock2.h&amp;gt; //包含socket的头文件#pragma comment (lib, &amp;#34;ws2_32.lib&amp;#34;)	//加载 ws2_32.dll #pragma warning(disable:4996) using namespace std; int main() { //****初始化WSA 	WSADATA wsaData;	//初始化WSAStartup()函数(规范的版本号，指向WSADATA结构体的指针)，向操作系统说明要使用哪个库的文件 	//-&amp;gt;MSKEWORD(2,2)主版本号2，副版本号2 	if (WSAStartup(MAKEWORD(2, 2), &amp;amp;wsaData) != 0)	{	return 0; } //****创建套接字 	SOCKET servSock = socket(PF_INET, SOCK_STREAM, 0); //参数1，IP地址类型,PF_INET6-&amp;gt;IPv6，PF_INET-&amp;gt;IPv4 	//参数2，数据传输方式,SOCK_STREAM 和 SOCK_DGRAM 	//参数3，传输协议,IPPROTO_TCP 和 IPPTOTO_UDP,写0系统会自动计算处使用那种协议 	//判断无效套接字 	if (servSock == INVALID_SOCKET) { cout &amp;lt;&amp;lt; &amp;#34;socket error!</description>
    </item>
    
    <item>
      <title>Socket通信原理(1)</title>
      <link>https://konosuba.xyz/blog/socket%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%861/</link>
      <pubDate>Sun, 07 Jul 2019 11:24:59 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/socket%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%861/</guid>
      <description>最近在捣鼓树莓派，实验室要用树莓派做图像处理后回传数据到计算机，所以开始学习socket相关知识，这一篇文章主要是计算机网络通信基础。
TCP/IP、UDP 在开始之前，先听两个笑话😏
TCP
&amp;gt; “嗨，我想听一个 TCP 的笑话。” //第一次握手 &amp;gt; “你好，你想听 TCP 的笑话么？” //第二次握手 &amp;gt; “嗯，我想听一个 TCP 的笑话。” //第三次握手 &amp;gt; “好的，我会给你讲一个TCP 的笑话。” &amp;gt; “好的，我会听一个TCP 的笑话。” &amp;gt; “你准备好听一个TCP 的笑话么？” &amp;gt; “嗯，我准备好听一个TCP 的笑话” &amp;gt; “OK，那我要发 TCP 笑话了。大概有 10 秒，20 个字。” &amp;gt; “嗯，我准备收你那个 10 秒时长，20 个字的笑话了。” &amp;gt; “抱歉，你的链接超时了。你好，你想听 TCP 的笑话么？” UDP
&amp;gt; 我给你们讲个UDP的笑话吧！ &amp;gt; 我给你们讲个UDP的笑话吧！ &amp;gt; 我给你们讲个UDP的笑话吧！ &amp;gt; 我给你们讲个UDP的笑话吧！ 学完之后，发现这两个笑话很好的表示出了两种协议的通信方式，来看看
TCP/IP，即传输控制协议/网间协议，是互联网相关各类协议族的总称，比如：TCP，UDP，IP，FTP，HTTP，ICMP，SMTP 等都属于 TCP/IP 族内的协议。UDP是与TCP相对应的协议，属于TCP/IP协议族中的一种
OSI七层模型 OSI是一个理想的模型，一般的网络系统只涉及其中的几层，在七层模型中，每一层都提供一个特殊 的网络功能。
从网络角度观察：
  下面四层（物理层、数据链路层、网络层和传输层）主要提供数据传输和交换功能， 即以节点到节点之间的通信为主
  第四层作为上下两部分的桥梁，是整个网络体系结构中最关键的部分</description>
    </item>
    
    <item>
      <title>树莓派配置摄像头</title>
      <link>https://konosuba.xyz/blog/%E6%A0%91%E8%8E%93%E6%B4%BE%E9%85%8D%E7%BD%AE%E6%91%84%E5%83%8F%E5%A4%B4/</link>
      <pubDate>Mon, 01 Jul 2019 15:27:39 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E6%A0%91%E8%8E%93%E6%B4%BE%E9%85%8D%E7%BD%AE%E6%91%84%E5%83%8F%E5%A4%B4/</guid>
      <description>注意：树莓派插电时千万不要插拔摄像头！据说十有八九摄像头会GG，我差点就中招了
安装驱动 首先使用ls指令查看是否加载到了对应的video device设备：
ls -al /etc 没有看到设备开始安装驱动
添加驱动设备到文件夹 sudo vim /etc/modules 在文件末尾添加
bcm2835-v412 修改raspberry的启动配置 进入管理中心开启pi camera
sudo raspi-config 选择interfacing option
开启Camera后重启
检查/dev ls -al /dev/ | grep video 有video设备则成功
使用树莓派摄像头 使用raspistill指令
测试 raspistill -o image.jpg  在使用hdml线连接lcd屏和树莓派时运行，显示屏会显示几秒钟摄像头的实时画面，但使用VNC连接时并不会有实时画面
 raspistill相关  -v：查看调试信息 -w：图像宽度 -h：图像高度 -rot：图像旋转角度，仅支持0，90，180，270度 -o：图像输出地址，若文件名为&#39;-&#39;，将输出发送至标准输出设备 -t：获取图像前等待时间，默认为5000，即5秒 -tl：多久执行一次图像抓取  生成.h246文件 raspistill -o mykeychain.h264 -t 10000 -w 1280 -h 720 错误 在第一次成功调用后，之后再次调用时多次报错：
mmal: No data received from sensor. Check all connections, including the Sunny one on the camera board 网上说导致该问题的原因有：</description>
    </item>
    
    <item>
      <title>灰度重心法</title>
      <link>https://konosuba.xyz/blog/%E7%81%B0%E5%BA%A6%E9%87%8D%E5%BF%83%E6%B3%95/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E7%81%B0%E5%BA%A6%E9%87%8D%E5%BF%83%E6%B3%95/</guid>
      <description>概念 对于亮度不均匀的目标（如光斑，光条纹），灰度重心法可按目标光强分布求出光强权重质心坐标作为跟踪点，也叫密度质心算法。
将灰度值分布中的质心记作光条纹的中心
对于M * N大小的图像f，像素的灰度值凡是超过阈值T的均参与重心处理，于是重心坐标为：
灰度重心法公式 型心法 只可用于二值图像
灰度重心法version 1 灰度重心法version 2 使用Visual Studio 2019测试 根据灰度重心法version 1找光斑中心
代码：
#define T 20 //根据实际情况设定固定阈值 Point grayCenter(Mat&amp;amp; img) { Mat img_gray; cvtColor(img, img_gray, COLOR_BGR2GRAY, 0); Point Center; //中心点 	int i, j; double sumval = 0; MatIterator_&amp;lt;uchar&amp;gt; it, end; //获取图像各点灰度值总和 	for (it = img_gray.begin&amp;lt;uchar&amp;gt;(), end = img_gray.end&amp;lt;uchar&amp;gt;(); it != end; it++) { ((*it) &amp;gt; T) ? sumval += (*it) : NULL; //小于阈值，取0 	} Center.</description>
    </item>
    
    <item>
      <title>Shell学习</title>
      <link>https://konosuba.xyz/blog/shell%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 26 Jun 2019 15:38:32 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/shell%E5%AD%A6%E4%B9%A0/</guid>
      <description>Shell脚本 是一种为shell编写的脚本程序
使用文本编辑器既能编写，拓展名不影响脚本执行
实例：
#!/bin/bash echo &amp;#34;Hello World&amp;#34;  #!告诉系统这个脚本需要什么解释器执行
 运行脚本 作为可执行程序 将代码保存后，给文件添加可执行权限+x
chmod +x ./test.sh # ./test.sh #执行脚本 作为解释器参数 直接运行解释器，将文件作为其参数 这种方式不需要在文件开头指定解释器信息
/bin/sh test.sh Shell变量 定义变量 your_name=&amp;#34;Tom&amp;#34; **注意：**等号不能有空格
使用变量 在变量前加美元符号$ 还可在变量外添加大括号{}
echo $your_name echo ${your_name} 只读变量 使用readonly命令将变量定义为只读变量，值不能被改变
url=&amp;#34;baidu.com&amp;#34; readonly url 删除变量 使用unset变量删除变量
unset url Shell字符串 可用单引号，或双引号，也可不用引号
单引号  单引号内任何字符都会原样输出，单引号字符串中变量无效 单引号字符串中不能出现单独一个的单引号，但可成对出现  双引号  双引号里可以有变量 双引号里可以出现转义字符  拼接字符串 text1=&amp;#39;123&amp;#39; text2=&amp;#39;456&amp;#39; echo ${text1}${text2} #输出123456 字符串长度 str1=&amp;#34;abcd&amp;#34; echo ${#str1} #输出4 提取子字符串 从字符串第2个字符开始截取4个字符：</description>
    </item>
    
    <item>
      <title>Vim学习</title>
      <link>https://konosuba.xyz/blog/vim%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 26 Jun 2019 10:33:16 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/vim%E5%AD%A6%E4%B9%A0/</guid>
      <description>vim分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode），底线命令（Last line mode）
命令模式 此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。
常用命令：
 i 切换到输入模式，以输入字符 x 删除当前光标所在处的字符 : 切换到底线命令模式，以在最底一行输入命令  命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令
输入模式 常用：
 Esc 退出输入模式，切换到命令模式 Insert 切换光标为输入/替换模式，光标变成竖线/下划线  底线命令模式 基本命令：
 q 退出程序 w 保存文件  vim按键 移动光标 要进行多次移动，例如向下移动30行，可使用30↓的组合按键
 [Ctrl]+[f] 下一页 [Ctrl]+[b] 上一页 [Ctrl]+[d] 向下半页 [Ctrl]+[u] 向上半页 0 移动到该行最前面字符处 $ 移动到该行最后字符处 G 移动到档案最后一行 nG 一赌东道档案第n行 gg 移动到档案第一行  搜索替换  /word 向光标之下寻找名称为word的字符串 ？word 向光标之上寻找名称为word的字符串 n 重复前一个搜寻的动作 N 反向进行前一个搜寻动作 :n1,n2s/word1/word2/g 在n1与n2行之间寻找word1字符串，并用word2取代 :1,$s/word1/word2/g 或 :%s/word1/word2/g 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 :1,$s/word1/word2/gc 或 :%s/word1/word2/gc 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2，并显示提示字符确认  删除、复制、粘贴  x,X x相当于del，X相当于Backspace dd 删除光标所在行 ndd 删除光标所在向下n行 d1G 删除光标所在到第一行所有数据 dG 删除光标所在到最后一行所有数据 yy 复制光标所在行 nyy 复制光标所在的向下n行 p,P p为将已复制的数据在光标下一行粘贴，P为粘贴在上一行 u 撤销 [Ctrl]+r 重做 .</description>
    </item>
    
    <item>
      <title>Linux文件</title>
      <link>https://konosuba.xyz/blog/linux%E6%96%87%E4%BB%B6/</link>
      <pubDate>Tue, 25 Jun 2019 13:23:08 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/linux%E6%96%87%E4%BB%B6/</guid>
      <description>[toc]
Linux文件基本属性 在Linux中可以使用ll或者ls –l命令来显示一个文件的属性以及文件所属的用户和组，如：
[root@www /]# ls -l total 64 dr-xr-xr-x 2 root root 4096 Dec 14 2012 bin dr-xr-xr-x 4 root root 4096 Apr 19 2012 boot …… bin文件的第一个属性用d表示，d在Linux中代表该文件是一个目录文件 Linux中第一个字符代表这个文件时目录、文件、链接文件等
  当为[d]则是目录 当为[-]则是文件 若是[l]则表示为链接文档(link file) 若是[b]则表示为装置文件里面的可供储存的接口设备(可随机存取装置) 若是[c]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)   接下来的字符中，三个为一组，且均为『rwx』 的三个参数的组合。其中，[r]代表可读(read)、[w]代表可写(write)、[x]代表可执行(execute)。 要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[-]，如图
Linux链接 Linux链接分为硬链接（Hard Link）和软链接（Symbolic Link）。默认情况，ln命令创建硬链接
硬链接 硬连接指通过索引节点来进行连接，多个文件名可以指向同一索引节点，删除其中任何一个不会影响其余文件名的访问，只有当最后一个连接被删除时，文件的数据块及其目录的连接才被释放
软链接 即符号链接，类似于Windows中快捷方式。两个文件名指向两个不同的节点号，若被指向的文件删除，链接仍存在，但指向一个无效的链接
Linux文件属主和属组 Linux系统按文件所有者、文件所有者同组用户和其他用户来规定了不同的文件访问权限。
[root@www /]# ls -l total 64 drwxr-xr-x 2 root root 4096 Feb 15 14:46 cron drwxr-xr-x 3 mysql mysql 4096 Apr 21 2014 mysql …… mysql 文件是一个目录文件，属主和属组都为 mysql，属主有可读、可写、可执行的权限；与属主同组的其他用户有可读和可执行的权限；其他用户也有可读和可执行的权限。</description>
    </item>
    
    <item>
      <title>Linux操作学习 系统启动及目录</title>
      <link>https://konosuba.xyz/blog/linux%E6%93%8D%E4%BD%9C%E5%AD%A6%E4%B9%A0-%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E5%8F%8A%E7%9B%AE%E5%BD%95/</link>
      <pubDate>Mon, 24 Jun 2019 11:51:27 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/linux%E6%93%8D%E4%BD%9C%E5%AD%A6%E4%B9%A0-%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E5%8F%8A%E7%9B%AE%E5%BD%95/</guid>
      <description>Linux系统启动过程   内核的引导 运行init 系统初始化 建立终端 用户登录系统   内核的引导 计算机接通电源，BIOS开机自检，启动操作系统，操作系统接管硬件后，首先读入/boot目录下的内核文件
运行init init进程是所有进程的起点，没有它任何进程都不会启动。init程序首先需要读取配置文件/etc/inittab
运行级别 Linux允许为不同的场合，分配不同的开机启动程序，即“运行级别”(runlevel)。启动时根据运行级别，确定要运行哪些程序
Linux共7种运行级别:
  运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登陆后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动   系统初始化 init配置文件中有一行：si::sysinit:/etc/rc.d/rc.sysinit，它调用执行了/etc/rc.d/rc.sysinit，而rc.sysinit是一个bash shell的脚本，主要完成一些系统初始化的工作，rc.sysinit是每个运行级别都要首先运行的重要脚本。
主要完成的工作：激活交换分区，检查磁盘，加载硬件模块及其他一些需要优先执行的任务
另外一行：15:5:wait:/etc/rc.d/rc 5，表示以5为参数运行/etc/rc.d/rc，/etc/rc.d/rc是一个Shell脚本，接受5作为参数，执行/etc/rc.d/rc5.d/目录下所有rc启动脚本，/etc/rc.d/rc5.d/目录中的这些启动脚本实际上都是一些连接文件，而不是真正的rc启动脚本，真正的rc启动脚本实际上都是放在/etc/rc.d/init.d/目录下。而这些rc启动脚本有着类似的用法，它们一般能接受start、stop、restart、status等参数。/etc/rc.d/rc5.d/中的rc启动脚本通常是K或S开头的连接文件，对于以 S 开头的启动脚本，将以start参数来运行。
而如果发现存在相应的脚本也存在K打头的连接，而且已经处于运行态了(以/var/lock/subsys/下的文件作为标志)，则将首先以stop为参数停止这些已经启动了的守护进程，然后再重新运行。
这样做是为了保证是当init改变运行级别时，所有相关的守护进程都将重启。
至于在每个运行级中将运行哪些守护进程，用户可以通过chkconfig或setup中的&amp;quot;System Services&amp;quot;来自行设定。
建立终端 rc执行完毕，返回init。此时基本系统环境已设置好，各种守护进程已启动。
init接下来会打开6个终端，以便用户登录系统，即inittab中以下6行就是定义了6个终端：
1:2345:respawn:/sbin/mingetty tty1 2:2345:respawn:/sbin/mingetty tty2 3:2345:respawn:/sbin/mingetty tty3 4:2345:respawn:/sbin/mingetty tty4 5:2345:respawn:/sbin/mingetty tty5 6:2345:respawn:/sbin/mingetty tty6 2、3、4、5的运行级别中都将以respawn方式运行mingetty程序，mingetty程序能打开终端、设置模式，同时显示文本登陆界面
用户登录系统 常用三种登陆方式：
 命令行登陆 ssh登陆 图形界面登陆  命令行登陆 Linux的账号验证程序是login，login会接手mingetty传来的用户名作为用户名参数， 之后login对用户名进行分析：如果用户名不是 root，且存在/etc/nologin文件，login 将输出 nologin 文件的内容，然后退出。</description>
    </item>
    
    <item>
      <title>Python面向对象</title>
      <link>https://konosuba.xyz/blog/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/</link>
      <pubDate>Fri, 21 Jun 2019 15:23:06 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/</guid>
      <description>类和实例 定义类 使用class关键字
class Student(object): #class 类名(继承类) 无继承类则使用object,也可省略 &amp;#34;&amp;#34;&amp;#34;docstring for Student&amp;#34;&amp;#34;&amp;#34; def __init__(self, name, score): #初始属性，第一个参数永远是self，表示创建的实例本身 super (Student, self).__init__() self.name = name self.score = score def print_score(self) print(&amp;#39;%s: %s&amp;#39; % (self.name, self.score)) 实例化 类名+（）
&amp;gt;&amp;gt;&amp;gt; bob = Student(&amp;#39;Bob&amp;#39;, 98) &amp;gt;&amp;gt;&amp;gt; bob.print_score() Bob: 98 创建实例后，可以自由地给一个实例变量绑定属性，如
&amp;gt;&amp;gt;&amp;gt; bob.school = &amp;#39;SWUST&amp;#39; &amp;gt;&amp;gt;&amp;gt; bob.school &amp;#39;SWUST&amp;#39; 访问限制  private私有变量：变量名以__开头 注意：__name__外部可以访问，是特殊变量  继承和多态 基类：
class Animal(object): def run(self): print(&amp;#39;Animal is running...&amp;#39;) 子类：
class Dog(Animal) pass 子类调用父类方法：</description>
    </item>
    
    <item>
      <title>Python函数式编程</title>
      <link>https://konosuba.xyz/blog/python%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Fri, 21 Jun 2019 10:50:55 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/</guid>
      <description>[toc]
什么是函数式编程？ 函数式编程是一种抽象程度很高的编程范式，纯粹的函数式编程语言编写的函数没有变量，因此，任意一个函数，只要输入是确定的，输出就是确定的，这种纯函数我们称之为没有副作用。
而允许使用变量的程序设计语言，由于函数内部的变量状态不确定，同样的输入，可能得到不同的输出，因此，这种函数是有副作用的
函数式编程的一个特点就是，允许把函数本身作为参数传入另一个函数，还允许返回一个函数！
Python对函数式编程提供部分支持。由于Python允许使用变量，因此，Python不是纯函数式编程语言
高阶函数 Python中函数两个特性
 变量可以指向函数  函数本身可以赋值给变量，通过变量可以调用函数
&amp;gt;&amp;gt;&amp;gt; f = abs &amp;gt;&amp;gt;&amp;gt; f(-10) 10  函数名是变量  把函数名看作变量，可将其指向其他对象，则无法调用原函数
&amp;gt;&amp;gt;&amp;gt; abs = 10 &amp;gt;&amp;gt;&amp;gt; abs(-10) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; TypeError: &amp;#39;int&amp;#39; object is not callable 传入函数 由于变量可以指向函数，函数的参数能接收变量，那么一个函数就可以接收另一个函数作为参数，这种函数就称之为高阶函数
一个最简单的高阶函数：
def add(x, y, f) return f(x) + f(y) 当调用add(-5, -6, abs)时，函数计算abs(-5)+abs(-6)，返回11
 把函数作为参数传入，这样的函数称为高阶函数，函数式编程就是指这种高度抽象的编程范式
  Python内建高阶函数 map()函数 |map() 函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回
def f(x): return x * x &amp;gt;&amp;gt;&amp;gt; r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9]) &amp;gt;&amp;gt;&amp;gt; list(r) [1, 4, 9, 16, 25, 36, 49, 64, 81] reduce()函数 |reduce 把一个函数作用在一个序列[x1, x2, x3, .</description>
    </item>
    
    <item>
      <title>算法复杂度</title>
      <link>https://konosuba.xyz/blog/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/</link>
      <pubDate>Fri, 21 Jun 2019 10:40:29 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/</guid>
      <description>算法复杂度  总共N个数据 一次操作记为O(1) N次操作记为O(n) 在大部分oj判题系统中时间限制为10^6 =1s  冒泡排序  操作次数: n+(n-1)+(n-2)+&amp;hellip;+n(n-1)/2  快速排序   递归处理数组，每次将数组按照key值在其左右区分出来：比key小放左边，比key大放右边
  例: 5 6 2 4 3 8   取首位（5）为key值
  4 3 2 5 6 8
  4 3 2 5 6 8
  </description>
    </item>
    
    <item>
      <title>Python中set集合</title>
      <link>https://konosuba.xyz/blog/python%E4%B8%ADset%E9%9B%86%E5%90%88/</link>
      <pubDate>Thu, 20 Jun 2019 16:18:07 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E4%B8%ADset%E9%9B%86%E5%90%88/</guid>
      <description>set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。
创建set 传入一个list，重复元素会被自动过滤，显示的顺序并不表示set是有序的
&amp;gt;&amp;gt;&amp;gt; s = set([1, 1, 2, 2, 3, 3]) &amp;gt;&amp;gt;&amp;gt; s {1, 2, 3} 添加元素 &amp;gt;&amp;gt;&amp;gt; s.add(4) &amp;gt;&amp;gt;&amp;gt; s {1, 2, 3, 4} 删除元素 &amp;gt;&amp;gt;&amp;gt; s.remove(3) &amp;gt;&amp;gt;&amp;gt; s {1, 2, 4} 交并集 set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作
&amp;gt;&amp;gt;&amp;gt; s1 = set([1, 2, 3]) &amp;gt;&amp;gt;&amp;gt; s2 = set([2, 3, 4]) &amp;gt;&amp;gt;&amp;gt; s1 &amp;amp; s2 {2, 3} &amp;gt;&amp;gt;&amp;gt; s1 | s2 {1, 2, 3, 4} </description>
    </item>
    
    <item>
      <title>Python中dict字典</title>
      <link>https://konosuba.xyz/blog/python%E4%B8%ADdict%E5%AD%97%E5%85%B8/</link>
      <pubDate>Thu, 20 Jun 2019 15:15:34 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E4%B8%ADdict%E5%AD%97%E5%85%B8/</guid>
      <description>dict全称dictionary，在其他语言中也称为map，使用**键-值（key-value）**存储，具有极快的查找速度
创建dict &amp;gt;&amp;gt;&amp;gt; d = {&amp;#39;Michael&amp;#39;: 95, &amp;#39;Bob&amp;#39;: 75, &amp;#39;Tracy&amp;#39;: 85} &amp;gt;&amp;gt;&amp;gt; d[&amp;#39;Michael&amp;#39;] 95 内部实现方法 先在字典的索引表里（比如部首表）查这个字对应的页码，然后直接翻到该页，找到这个字。无论找哪个字，这种查找速度都非常快，不会随着字典大小的增加而变慢。
加入数据 把数据放入dict的方法，除了初始化时指定外，还可以通过key放入：
&amp;gt;&amp;gt;&amp;gt; d[&amp;#39;Tony&amp;#39;] = 99 &amp;gt;&amp;gt;&amp;gt; d {&amp;#39;Michael&amp;#39;: 95, &amp;#39;Bob&amp;#39;: 75, &amp;#39;Tracy&amp;#39;: 85, &amp;#39;Tony&amp;#39;: 99} 查询key是否存在 使用in &amp;gt;&amp;gt;&amp;gt; &amp;#39;Thomas&amp;#39; in d False &amp;gt;&amp;gt;&amp;gt; &amp;#39;Bob&amp;#39; in d True 使用get() 如果key不存在，返回None，或者自己指定的value
&amp;gt;&amp;gt;&amp;gt; d.get(&amp;#39;Thomas&amp;#39;) #返回None时Python交互环境不显示 &amp;gt;&amp;gt;&amp;gt; d.get(&amp;#39;Thomas&amp;#39;, -1) -1 删除key 删除一个key，用pop(key)方法，对应的value也会从dict中删除，返回删除的value
&amp;gt;&amp;gt;&amp;gt; d.pop(&amp;#39;Bob&amp;#39;) 75 &amp;gt;&amp;gt;&amp;gt; d {&amp;#39;Michael&amp;#39;: 95, &amp;#39;Tracy&amp;#39;: 85, &amp;#39;Tony&amp;#39;: 99} 注意 dict内部存放顺序与key放入顺序无关 dict的key必须是不可变对象 实质：哈希表</description>
    </item>
    
    <item>
      <title>Python常见数据类型——Tuple元组</title>
      <link>https://konosuba.xyz/blog/python%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8Btuple%E5%85%83%E7%BB%84/</link>
      <pubDate>Thu, 20 Jun 2019 13:46:10 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8Btuple%E5%85%83%E7%BB%84/</guid>
      <description>tuple和list非常类似，但是tuple一旦初始化就不能修改
[toc]
创建tuple &amp;gt;&amp;gt;&amp;gt; classmates = (&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;) 此时，classmates这个tuple不能改变，它也没有append()，insert()这样的方法。
其他获取元素的方法和list是一样的，你可以正常地使用classmates[0]，classmates[-1]，但不能将其赋值为另外的元素。
因为tuple不可变，所以代码更安全。如果可能，能用tuple代替list就尽量用tuple。
空tuple &amp;gt;&amp;gt;&amp;gt; t = () &amp;gt;&amp;gt;&amp;gt; t () 只有一个元素的tuple 错误写法 不能直接使用括号()!!!
&amp;gt;&amp;gt;&amp;gt; t = (1) &amp;gt;&amp;gt;&amp;gt; t 1 #定义的不是tuble，而是一个数 正解 加一个逗号，消除歧义
&amp;gt;&amp;gt;&amp;gt; t = (1,) &amp;gt;&amp;gt;&amp;gt; t (1,) &amp;ldquo;可变&amp;quot;的tuble 当tuble中包含list元素时，仍然可以对list进行修改，tuble仍指向该list
&amp;gt;&amp;gt;&amp;gt; t = (1, [&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;z&amp;#39;]) &amp;gt;&amp;gt;&amp;gt; t[1][2] = &amp;#39;a&amp;#39; &amp;gt;&amp;gt;&amp;gt; t (1, [&amp;#39;x&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;z&amp;#39;]) 个人理解：tuble相当于一个指针数组，指向每个元素，对元素本身的更改并不会影响tuble的指向</description>
    </item>
    
    <item>
      <title>Python常见数据类型——List列表</title>
      <link>https://konosuba.xyz/blog/python%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8Blist%E5%88%97%E8%A1%A8/</link>
      <pubDate>Thu, 20 Jun 2019 13:44:48 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/python%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8Blist%E5%88%97%E8%A1%A8/</guid>
      <description>Python常见数据类型——List列表 list是一种有序的集合，可随时增删元素
[toc]
创建list &amp;gt;&amp;gt;&amp;gt; classmates = [&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;] &amp;gt;&amp;gt;&amp;gt; classmates [&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;] &amp;gt;&amp;gt;&amp;gt; len(classmates) 3 访问某个位置元素 使用索引地址访问
&amp;gt;&amp;gt;&amp;gt; classmates[0] &amp;#39;A&amp;#39; &amp;gt;&amp;gt;&amp;gt; classmates[-1] #返回最后一项元素 &amp;#39;C&amp;#39; 追加元素到末尾 &amp;gt;&amp;gt;&amp;gt; classmates.append(&amp;#39;D&amp;#39;) &amp;gt;&amp;gt;&amp;gt; classmates [&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;D&amp;#39;] 插入元素到指定位置 &amp;gt;&amp;gt;&amp;gt; classmates.insert(1, &amp;#39;Here&amp;#39;) #在指定位置放入元素 &amp;gt;&amp;gt;&amp;gt; classmates [&amp;#39;A&amp;#39;, &amp;#39;Here&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;D&amp;#39;] 删除元素 使用pop 指定索引地址删除，返回删除的值
&amp;gt;&amp;gt;&amp;gt; classmates.pop(0) &amp;#39;A&amp;#39; &amp;gt;&amp;gt;&amp;gt; classmates [&amp;#39;Here&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;D&amp;#39;] 使用del 指定索引地址删除，无返回值
&amp;gt;&amp;gt;&amp;gt; del classmates[1] &amp;gt;&amp;gt;&amp;gt;classmates [&amp;#39;Here&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;D&amp;#39;] 使用remove 删除指定值的第一次出现，无返回值</description>
    </item>
    
    <item>
      <title>图像基础-图像矩阵</title>
      <link>https://konosuba.xyz/blog/%E5%9B%BE%E5%83%8F%E5%9F%BA%E7%A1%80-%E5%9B%BE%E5%83%8F%E7%9F%A9%E9%98%B5/</link>
      <pubDate>Thu, 06 Jun 2019 00:35:00 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E5%9B%BE%E5%83%8F%E5%9F%BA%E7%A1%80-%E5%9B%BE%E5%83%8F%E7%9F%A9%E9%98%B5/</guid>
      <description>数字图像数据可以用矩阵来表示，因此可以采用矩阵理论和矩阵算法对数字图像进行分析和处理。
在使用OpenCV时，要特别注意其坐标轴与普通x-y轴的转换，我在实际使用过程中就经常在这上面翻车，还是不熟练
图为坐标对照图，转自CSDN，具体忘了</description>
    </item>
    
    <item>
      <title>图像基础-图像分类</title>
      <link>https://konosuba.xyz/blog/%E5%9B%BE%E5%83%8F%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</link>
      <pubDate>Thu, 06 Jun 2019 00:00:49 +0800</pubDate>
      
      <guid>https://konosuba.xyz/blog/%E5%9B%BE%E5%83%8F%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</guid>
      <description> 部分内容引用 CSDN爬金字塔的人
 计算机中， 通常以矩阵形式存储图像，根据颜色和灰度多少可以分为灰度图像、二值图像、索引图像和RGB图像
灰度图像   矩阵元素取值范围为[0, 255] （0-黑，255-白），数据类型一般为8位无符号整数【unit8】
  某些领域（如医学成像）采用【unit16】和【int16】数据类型
  对于计算灰度的操作（如**傅里叶变换**），使用【double】和【single】类型；若图像是【double】或【single】，灰度图像的值通常被归一化标定位【0-1】范围内，**0代表黑色，1代表白色**，0到1之间的小数表示不同的灰度等级。
  二值图像可以看成是灰度图像的一个特例。
  二值图像   一幅二值图像的二维矩阵仅由0、1两个值构成，计算机中二值图像的数据类型通常为1个二进制位
  在MATLAB中，二值图像具有非常特殊的意义，只有逻辑数据类型【logical】才被认为是二值图像，就算是只包含0和1的数据类的数组（例如【uint8】），在MATLAB中都不认为是二值图像。可以使用logical将其他类型的数组转换为二值图像：B = logical（A）
  索引图像   包括一个数据矩阵X，一个颜色映像矩阵Map。Map是一个包含三列，若干行的数据阵列，其中每个元素的值均为[0，1]之间的双精度浮点型数据。每一行分别表示红， 绿，蓝的颜色值。
  在MATLAB中，索引图像是从像素值到颜色映射表值的“直接映射”。像素颜色由数据矩阵X作为索引指向矩阵Map进行索引，例如，值1指向矩阵Map中的第一行，值2指向第二行，以此类推。
  一般索引图像只能显示256种颜色（由数据矩阵X的取值范围决定），与灰度图像不同的是，灰度图像的颜色表的值是从0到255连续的值，所以灰度图像的数据我们即可以看成是实际的像素值，也可以看成是索引值。
  索引图的优点是存储所需容量小，且索引图像一般用于存放色彩要求比较简单的图像，如Windows中色彩构成比较简单的壁纸多采用索引图像存放，如果图像的色彩比较复杂，就要用到RGB真彩色图像。
  RGB图像   RGB图像每一个像素的颜色值（由RGB三原色表示）直接存放在图像矩阵中
  一副大小为MN的RGB图像需要3个MN大小的矩阵表示，每一个矩阵代表一个颜色通道。RGB图像的数据类型一般为【unit】（或【double】），通常用于表示和存放真彩色图像（2^24种颜色），也可存灰度图像（三个通道的值都一样）
  在MATLAB中用cat操作将3通道合成彩色图像：rab_image = cat(3, R, G, B);
  MATLAB中用下面这些命令可以提取出三个通道的图像：
  R = rgb_image（：，：，1）; G = rgb_image（：，：，2）; B = rgb_image（：，：，3）; </description>
    </item>
    
  </channel>
</rss>
