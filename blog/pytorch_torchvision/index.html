<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
    <title>Pytorch_torchvision - Tiiktak&#39;s</title>
    
    <meta name="description" content="torchvision.models torchvision不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用，或者在进行迁移学习 torchvision.models模块的 子模块中包含以下模型结构。 - AlexNet - VGG - ResNet - SqueezeNet - DenseNet
torchvision.datasets 这其中所有的数据集都是torch.utils.data.Dataset的子类，它们都具有__getitem__和__len__实现的方法。因此，它们都可以传递给torch.utils.data.DataLoader，它使用torch.multiprocessing并行加载多个样本。
torchvision.transforms 提供了一般的图像转换操作类，用作数据处理和数据增强
其中都是常见的图像转换，可以通过Compose将他们链接在一起
from torchvision import transforms as transforms transform = transforms.Compose([ transforms.RandomCrop(32, padding=4), #先四周填充0，在把图像随机裁剪成32*32 transforms.RandomHorizontalFlip(), #图像一半的概率翻转，一半的概率不翻转 transforms.RandomRotation((-45,45)), #随机旋转 transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.229, 0.224, 0.225)), #R,G,B每层的归一化用到的均值和方差 ])  此外还有torchvision.transforms.functional模块，可对转换进行细粒度控制，这对于要构建一个更复杂的 transformation pipeline（例如在segmentation tasks分段任务中）很有帮助
torchvision.transforms.Normalize(mean, std, inplace=False) 用均值和标准差对张量图像进行归一化。
给定n个通道的均值: (M1,...,Mn) 和标准差:(S1,..,Sn), 这个转换将归一化输入torch.*Tensor的每个通道。例如: input[channel] = (input[channel] - mean[channel]) / std[channel]
 Note: 这种变换的作用不适当，即它不会改变输入张量
 torchvision.utils torchvision.">
    <meta name="author" content="">
    
    <link href="https://konosuba.xyz/css/github-gist.min.css" rel="stylesheet">
    <link href="https://konosuba.xyz/css/style.css" rel="stylesheet">
    
    <link rel="apple-touch-icon" href="https://konosuba.xyz/img/apple-touch-icon.png">
    <link rel="icon" href="https://konosuba.xyz/img/favicon.ico">
    
    <meta name="generator" content="Hugo 0.55.6" />
    
    <link rel="alternate" type="application/atom+xml" href="https://konosuba.xyz/index.xml" title="Tiiktak&#39;s">
    
    
    
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-141514532-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());

      gtag('config', 'UA-141514532-1');
    </script>
    
    <script>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?0121c6813b611028681cd70e85594cb6";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>

  </head>
  <body class="single">
    <header class="header">
      <div class="wrap">
        
        <p class="logo"><a href="https://konosuba.xyz/">Tiiktak&#39;s</a></p>
        
        
        <button class="menu-toggle" type="button"></button>
        
      </div>
    </header>
    
    <nav class="nav">
      <ul class="menu">
        
        <li>
          <a href="/about/">About</a>
        </li>
        
      </ul>
    </nav>
    
    <main class="main">


<article class="post-single">
  <header class="post-header">
    <h1 class="post-title">Pytorch_torchvision</h1>
    <div class="post-meta">2020.2.14</div>
  </header>
  <div class="post-content">

<h1 id="torchvision-models">torchvision.models</h1>

<p>torchvision不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用，或者在进行迁移学习
torchvision.models模块的 子模块中包含以下模型结构。
- AlexNet
- VGG
- ResNet
- SqueezeNet
- DenseNet</p>

<h1 id="torchvision-datasets">torchvision.datasets</h1>

<p>这其中所有的数据集都是<code>torch.utils.data.Dataset</code>的子类，它们都具有<code>__getitem__</code>和<code>__len__</code>实现的方法。因此，它们都可以传递给<code>torch.utils.data.DataLoader</code>，它使用<code>torch.multiprocessing</code>并行加载多个样本。</p>

<h1 id="torchvision-transforms">torchvision.transforms</h1>

<p>提供了一般的图像转换操作类，用作数据处理和数据增强</p>

<p>其中都是常见的图像转换，可以通过<code>Compose</code>将他们链接在一起</p>

<pre><code class="language-python">from torchvision import transforms as transforms
transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),  #先四周填充0，在把图像随机裁剪成32*32
    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转
    transforms.RandomRotation((-45,45)), #随机旋转
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.229, 0.224, 0.225)), #R,G,B每层的归一化用到的均值和方差
])
</code></pre>

<p>此外还有<code>torchvision.transforms.functional</code>模块，可对转换进行细粒度控制，这对于要构建一个更复杂的 transformation pipeline（例如在segmentation tasks分段任务中）很有帮助</p>

<h2 id="torchvision-transforms-normalize-mean-std-inplace-false">torchvision.transforms.Normalize(mean, std, inplace=False)</h2>

<p>用均值和标准差对张量图像进行归一化。</p>

<p>给定<code>n</code>个通道的均值: <code>(M1,...,Mn)</code> 和标准差:<code>(S1,..,Sn)</code>, 这个转换将归一化输入<code>torch.*Tensor</code>的每个通道。例如: <code>input[channel] = (input[channel] - mean[channel]) / std[channel]</code></p>

<blockquote>
<p>Note: 这种变换的作用不适当，即它不会改变输入张量</p>
</blockquote>

<h1 id="torchvision-utils">torchvision.utils</h1>

<h2 id="torchvision-utils-make-grid-tensor-nrow-8-padding-2-normalize-false-range-none-scale-each-false-pad-value-0">torchvision.utils.make_grid(tensor, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)</h2>

<p>创建图像网格，即将若干幅图像拼成一幅图像</p>

<ul>
<li><p><code>tensor</code> (Tensor or list) – 四维 mini-batch Tensor 尺寸为 (B x C x H x W) 或一个所有图像大小相同的list</p></li>

<li><p><code>nrow</code> (python:int, optional) – 网格中每行展示图像的数量。最后一行size为 (B / nrow, nrow)</p></li>

<li><p><code>padding</code> (python:int, optional) – 填充量（多幅图像间距）</p></li>

<li><p><code>normalize</code> (bool, optional) – 若为<code>True</code>, 根据由range范围指定的最大最小值，将图像归一化到(0, 1)</p></li>

<li><p><code>range</code> (tuple, optional) – tuple (min, max) 用于归一化图像. min和max默认通过tensor计算</p></li>

<li><p><code>scale_each</code> (bool, optional) – 若为<code>True</code>, 分别缩放该批图像中的每个图像，而不是缩放所有图像的(min, max)</p></li>

<li><p><code>pad_value</code> (python:float, optional) – 填充值</p></li>
</ul>
</div>
  <footer class="post-footer">
    
  </footer>
  
  
  
  <div id="disqus_thread"></div>
  <script>
    var disqus_shortname = 'tiiktak';
    (function() {
      var d = document, s = d.createElement('script');
      s.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>
    Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
  
  
  
</article>

</main>
<footer class="footer">
  <span>&copy; 2020 <a href="https://konosuba.xyz/">Tiiktak&#39;s</a></span>
  <span>&middot;</span>
  <span>Powered by <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>️</span>
  <span>&middot;</span>
  <span>Theme️ <a href="https://github.com/nanxiaobei/hugo-paper" rel="noopener" target="_blank">Paper</a></span>
</footer>
<script src="https://konosuba.xyz/js/instantclick.min.js" data-no-instant></script>
<script data-no-instant>InstantClick.init();</script>
<script src="https://konosuba.xyz/js/highlight.min.js" data-no-instant></script>
<script data-no-instant>
  let body;
  function menuToggleListener() {
    body.classList.toggle('blur');
  }
  function setMenuToggleListener() {
    const menuToggle = document.querySelector('.menu-toggle');
    if (!menuToggle) return;
    body = document.querySelector('body');
    menuToggle.addEventListener('click', menuToggleListener);
  }

  hljs.initHighlightingOnLoad();
  setMenuToggleListener();

  InstantClick.on('change', function () {
    document.querySelectorAll('pre code').forEach((block) => {
      hljs.highlightBlock(block);
    });
    setMenuToggleListener();
  });
</script>
</body>
</html>

